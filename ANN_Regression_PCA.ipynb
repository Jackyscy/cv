{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVEUHX9c9AzIvLZPzoXQ+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jackyscy/cv/blob/main/ANN_Regression_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKE52MXN6PWJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as read_csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"2023_one hours__normal_on_state2_Selected_Feature.csv\",  parse_dates=[\"Date_Time\"],\n",
        "        index_col=[\"Date_Time\"],)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "8HNmwtyn6VLO",
        "outputId": "84696a92-b777-4171-dbdc-b610d200af97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Gt Exhaust Outlet Temp  GT Fuel Gas Mass Flow  \\\n",
              "Date_Time                                                            \n",
              "2023-01-20 17:00:00                 611.855                 13.760   \n",
              "2023-01-20 18:00:00                 604.004                 13.175   \n",
              "2023-01-20 19:00:00                 637.918                 11.979   \n",
              "2023-01-20 20:00:00                 636.447                 12.306   \n",
              "2023-01-20 21:00:00                 637.513                 11.290   \n",
              "\n",
              "                     GT Gross MW  GT Compres Inlet Temp  GT IGV Position  \\\n",
              "Date_Time                                                                  \n",
              "2023-01-20 17:00:00      231.782                 18.940           87.999   \n",
              "2023-01-20 18:00:00      226.570                 18.938           84.113   \n",
              "2023-01-20 19:00:00      207.629                 18.780           65.027   \n",
              "2023-01-20 20:00:00      212.659                 18.626           67.205   \n",
              "2023-01-20 21:00:00      193.451                 17.743           60.577   \n",
              "\n",
              "                     GT Turbine Inlet Temperature  GT Swirl Angle  \\\n",
              "Date_Time                                                           \n",
              "2023-01-20 17:00:00                      1255.732          14.534   \n",
              "2023-01-20 18:00:00                      1244.014          19.430   \n",
              "2023-01-20 19:00:00                      1284.943          38.101   \n",
              "2023-01-20 20:00:00                      1283.541          33.234   \n",
              "2023-01-20 21:00:00                      1270.635          51.623   \n",
              "\n",
              "                     GT Efficiency Actual (LHV)  \\\n",
              "Date_Time                                         \n",
              "2023-01-20 17:00:00                      34.919   \n",
              "2023-01-20 18:00:00                      35.239   \n",
              "2023-01-20 19:00:00                      35.913   \n",
              "2023-01-20 20:00:00                      35.783   \n",
              "2023-01-20 21:00:00                      35.513   \n",
              "\n",
              "                     Combust Monitor Actual Spread 2  \\\n",
              "Date_Time                                              \n",
              "2023-01-20 17:00:00                           31.110   \n",
              "2023-01-20 18:00:00                           24.820   \n",
              "2023-01-20 19:00:00                           27.752   \n",
              "2023-01-20 20:00:00                           28.361   \n",
              "2023-01-20 21:00:00                           15.186   \n",
              "\n",
              "                     GT Exhaust Gas Flow - HB  ...  Turb Exhaust T/C 23  \\\n",
              "Date_Time                                      ...                        \n",
              "2023-01-20 17:00:00                   650.398  ...              608.536   \n",
              "2023-01-20 18:00:00                   635.450  ...              606.971   \n",
              "2023-01-20 19:00:00                   531.246  ...              637.373   \n",
              "2023-01-20 20:00:00                   548.814  ...              632.764   \n",
              "2023-01-20 21:00:00                   504.648  ...              636.851   \n",
              "\n",
              "                     Turb Exhaust T/C 24  Turb Exhaust T/C 25  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              605.209              601.492   \n",
              "2023-01-20 18:00:00              595.928              589.052   \n",
              "2023-01-20 19:00:00              643.240              637.800   \n",
              "2023-01-20 20:00:00              648.446              627.277   \n",
              "2023-01-20 21:00:00              641.639              638.126   \n",
              "\n",
              "                     Turb Exhaust T/C 26  Turb Exhaust T/C 27  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              610.876              615.695   \n",
              "2023-01-20 18:00:00              595.202              609.593   \n",
              "2023-01-20 19:00:00              623.243              636.460   \n",
              "2023-01-20 20:00:00              618.795              641.789   \n",
              "2023-01-20 21:00:00              639.001              628.511   \n",
              "\n",
              "                     Turb Exhaust T/C 28  Turb Exhaust T/C 29  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              628.713              611.376   \n",
              "2023-01-20 18:00:00              616.492              608.235   \n",
              "2023-01-20 19:00:00              648.020              645.099   \n",
              "2023-01-20 20:00:00              640.982              649.530   \n",
              "2023-01-20 21:00:00              633.543              643.794   \n",
              "\n",
              "                     Turb Exhaust T/C 30  Turb Exhaust T/C 31  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              604.494              619.819   \n",
              "2023-01-20 18:00:00              600.413              600.202   \n",
              "2023-01-20 19:00:00              648.190              637.079   \n",
              "2023-01-20 20:00:00              641.044              630.275   \n",
              "2023-01-20 21:00:00              639.210              642.735   \n",
              "\n",
              "                     Combust Monitor Actual Spread 1  \n",
              "Date_Time                                             \n",
              "2023-01-20 17:00:00                           32.684  \n",
              "2023-01-20 18:00:00                           32.458  \n",
              "2023-01-20 19:00:00                           34.742  \n",
              "2023-01-20 20:00:00                           35.122  \n",
              "2023-01-20 21:00:00                           19.609  \n",
              "\n",
              "[5 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65c5d4d2-3fe2-4ce2-a49c-ded256d3789f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gt Exhaust Outlet Temp</th>\n",
              "      <th>GT Fuel Gas Mass Flow</th>\n",
              "      <th>GT Gross MW</th>\n",
              "      <th>GT Compres Inlet Temp</th>\n",
              "      <th>GT IGV Position</th>\n",
              "      <th>GT Turbine Inlet Temperature</th>\n",
              "      <th>GT Swirl Angle</th>\n",
              "      <th>GT Efficiency Actual (LHV)</th>\n",
              "      <th>Combust Monitor Actual Spread 2</th>\n",
              "      <th>GT Exhaust Gas Flow - HB</th>\n",
              "      <th>...</th>\n",
              "      <th>Turb Exhaust T/C 23</th>\n",
              "      <th>Turb Exhaust T/C 24</th>\n",
              "      <th>Turb Exhaust T/C 25</th>\n",
              "      <th>Turb Exhaust T/C 26</th>\n",
              "      <th>Turb Exhaust T/C 27</th>\n",
              "      <th>Turb Exhaust T/C 28</th>\n",
              "      <th>Turb Exhaust T/C 29</th>\n",
              "      <th>Turb Exhaust T/C 30</th>\n",
              "      <th>Turb Exhaust T/C 31</th>\n",
              "      <th>Combust Monitor Actual Spread 1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date_Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-20 17:00:00</th>\n",
              "      <td>611.855</td>\n",
              "      <td>13.760</td>\n",
              "      <td>231.782</td>\n",
              "      <td>18.940</td>\n",
              "      <td>87.999</td>\n",
              "      <td>1255.732</td>\n",
              "      <td>14.534</td>\n",
              "      <td>34.919</td>\n",
              "      <td>31.110</td>\n",
              "      <td>650.398</td>\n",
              "      <td>...</td>\n",
              "      <td>608.536</td>\n",
              "      <td>605.209</td>\n",
              "      <td>601.492</td>\n",
              "      <td>610.876</td>\n",
              "      <td>615.695</td>\n",
              "      <td>628.713</td>\n",
              "      <td>611.376</td>\n",
              "      <td>604.494</td>\n",
              "      <td>619.819</td>\n",
              "      <td>32.684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 18:00:00</th>\n",
              "      <td>604.004</td>\n",
              "      <td>13.175</td>\n",
              "      <td>226.570</td>\n",
              "      <td>18.938</td>\n",
              "      <td>84.113</td>\n",
              "      <td>1244.014</td>\n",
              "      <td>19.430</td>\n",
              "      <td>35.239</td>\n",
              "      <td>24.820</td>\n",
              "      <td>635.450</td>\n",
              "      <td>...</td>\n",
              "      <td>606.971</td>\n",
              "      <td>595.928</td>\n",
              "      <td>589.052</td>\n",
              "      <td>595.202</td>\n",
              "      <td>609.593</td>\n",
              "      <td>616.492</td>\n",
              "      <td>608.235</td>\n",
              "      <td>600.413</td>\n",
              "      <td>600.202</td>\n",
              "      <td>32.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 19:00:00</th>\n",
              "      <td>637.918</td>\n",
              "      <td>11.979</td>\n",
              "      <td>207.629</td>\n",
              "      <td>18.780</td>\n",
              "      <td>65.027</td>\n",
              "      <td>1284.943</td>\n",
              "      <td>38.101</td>\n",
              "      <td>35.913</td>\n",
              "      <td>27.752</td>\n",
              "      <td>531.246</td>\n",
              "      <td>...</td>\n",
              "      <td>637.373</td>\n",
              "      <td>643.240</td>\n",
              "      <td>637.800</td>\n",
              "      <td>623.243</td>\n",
              "      <td>636.460</td>\n",
              "      <td>648.020</td>\n",
              "      <td>645.099</td>\n",
              "      <td>648.190</td>\n",
              "      <td>637.079</td>\n",
              "      <td>34.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 20:00:00</th>\n",
              "      <td>636.447</td>\n",
              "      <td>12.306</td>\n",
              "      <td>212.659</td>\n",
              "      <td>18.626</td>\n",
              "      <td>67.205</td>\n",
              "      <td>1283.541</td>\n",
              "      <td>33.234</td>\n",
              "      <td>35.783</td>\n",
              "      <td>28.361</td>\n",
              "      <td>548.814</td>\n",
              "      <td>...</td>\n",
              "      <td>632.764</td>\n",
              "      <td>648.446</td>\n",
              "      <td>627.277</td>\n",
              "      <td>618.795</td>\n",
              "      <td>641.789</td>\n",
              "      <td>640.982</td>\n",
              "      <td>649.530</td>\n",
              "      <td>641.044</td>\n",
              "      <td>630.275</td>\n",
              "      <td>35.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 21:00:00</th>\n",
              "      <td>637.513</td>\n",
              "      <td>11.290</td>\n",
              "      <td>193.451</td>\n",
              "      <td>17.743</td>\n",
              "      <td>60.577</td>\n",
              "      <td>1270.635</td>\n",
              "      <td>51.623</td>\n",
              "      <td>35.513</td>\n",
              "      <td>15.186</td>\n",
              "      <td>504.648</td>\n",
              "      <td>...</td>\n",
              "      <td>636.851</td>\n",
              "      <td>641.639</td>\n",
              "      <td>638.126</td>\n",
              "      <td>639.001</td>\n",
              "      <td>628.511</td>\n",
              "      <td>633.543</td>\n",
              "      <td>643.794</td>\n",
              "      <td>639.210</td>\n",
              "      <td>642.735</td>\n",
              "      <td>19.609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65c5d4d2-3fe2-4ce2-a49c-ded256d3789f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65c5d4d2-3fe2-4ce2-a49c-ded256d3789f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65c5d4d2-3fe2-4ce2-a49c-ded256d3789f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1d4e500-fa42-4336-83e6-cfa08c6697fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1d4e500-fa42-4336-83e6-cfa08c6697fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1d4e500-fa42-4336-83e6-cfa08c6697fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "iOH_0t5Y6VNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75006472-4760-4721-cf63-f3378c0a6be0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2743 entries, 2023-01-20 17:00:00 to 2023-10-29 22:00:00\n",
            "Data columns (total 40 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   Gt Exhaust Outlet Temp           2743 non-null   float64\n",
            " 1   GT Fuel Gas Mass Flow            2743 non-null   float64\n",
            " 2   GT Gross MW                      2743 non-null   float64\n",
            " 3   GT Compres Inlet Temp            2743 non-null   float64\n",
            " 4   GT IGV Position                  2743 non-null   float64\n",
            " 5   GT Turbine Inlet Temperature     2743 non-null   float64\n",
            " 6   GT Swirl Angle                   2743 non-null   float64\n",
            " 7   GT Efficiency Actual (LHV)       2743 non-null   float64\n",
            " 8   Combust Monitor Actual Spread 2  2743 non-null   float64\n",
            " 9   GT Exhaust Gas Flow - HB         2743 non-null   float64\n",
            " 10  Combust Monitor Actual Spread 3  2743 non-null   float64\n",
            " 11  Turb Exhaust T/C 2               2743 non-null   float64\n",
            " 12  Turb Exhaust T/C 3               2743 non-null   float64\n",
            " 13  Turb Exhaust T/C 4               2743 non-null   float64\n",
            " 14  Turb Exhaust T/C 5               2743 non-null   float64\n",
            " 15  Turb Exhaust T/C 6               2743 non-null   float64\n",
            " 16  Turb Exhaust T/C 7               2743 non-null   float64\n",
            " 17  Turb Exhaust T/C 8               2743 non-null   float64\n",
            " 18  Turb Exhaust T/C 9               2743 non-null   float64\n",
            " 19  Turb Exhaust T/C 10              2743 non-null   float64\n",
            " 20  Turb Exhaust T/C 11              2743 non-null   float64\n",
            " 21  Turb Exhaust T/C 13              2743 non-null   float64\n",
            " 22  Turb Exhaust T/C 14              2743 non-null   float64\n",
            " 23  Turb Exhaust T/C 16              2743 non-null   float64\n",
            " 24  Turb Exhaust T/C 17              2743 non-null   float64\n",
            " 25  Turb Exhaust T/C 18              2743 non-null   float64\n",
            " 26  Turb Exhaust T/C 19              2743 non-null   float64\n",
            " 27  Turb Exhaust T/C 20              2743 non-null   float64\n",
            " 28  Turb Exhaust T/C 21              2743 non-null   float64\n",
            " 29  Turb Exhaust T/C 22              2743 non-null   float64\n",
            " 30  Turb Exhaust T/C 23              2743 non-null   float64\n",
            " 31  Turb Exhaust T/C 24              2743 non-null   float64\n",
            " 32  Turb Exhaust T/C 25              2743 non-null   float64\n",
            " 33  Turb Exhaust T/C 26              2743 non-null   float64\n",
            " 34  Turb Exhaust T/C 27              2743 non-null   float64\n",
            " 35  Turb Exhaust T/C 28              2743 non-null   float64\n",
            " 36  Turb Exhaust T/C 29              2743 non-null   float64\n",
            " 37  Turb Exhaust T/C 30              2743 non-null   float64\n",
            " 38  Turb Exhaust T/C 31              2743 non-null   float64\n",
            " 39  Combust Monitor Actual Spread 1  2743 non-null   float64\n",
            "dtypes: float64(40)\n",
            "memory usage: 878.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_object(obj , name):\n",
        "    pickle_obj = open(f\"{name}.pck\",\"wb\")\n",
        "    pickle.dump(obj, pickle_obj)\n",
        "    pickle_obj.close()"
      ],
      "metadata": {
        "id": "dlPH0K2L0z8n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_columns = list(data.columns)\n",
        "remaining_columns.remove(\"Combust Monitor Actual Spread 1\")"
      ],
      "metadata": {
        "id": "O3fEOAMI6VTi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[remaining_columns].values\n",
        "Y = data['Combust Monitor Actual Spread 1'].values"
      ],
      "metadata": {
        "id": "sIi0rAAHm7je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "QSSDnV4mGoIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acda3d73-88f1-4e60-cb95-6cc9c0c6958b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gt Exhaust Outlet Temp', 'GT Fuel Gas Mass Flow', 'GT Gross MW',\n",
              "       'GT Compres Inlet Temp', 'GT IGV Position',\n",
              "       'GT Turbine Inlet Temperature', 'GT Swirl Angle',\n",
              "       'GT Efficiency Actual (LHV)', 'Combust Monitor Actual Spread 2',\n",
              "       'GT Exhaust Gas Flow - HB', 'Combust Monitor Actual Spread 3',\n",
              "       'Turb Exhaust T/C 2', 'Turb Exhaust T/C 3', 'Turb Exhaust T/C 4',\n",
              "       'Turb Exhaust T/C 5', 'Turb Exhaust T/C 6', 'Turb Exhaust T/C 7',\n",
              "       'Turb Exhaust T/C 8', 'Turb Exhaust T/C 9', 'Turb Exhaust T/C 10',\n",
              "       'Turb Exhaust T/C 11', 'Turb Exhaust T/C 13', 'Turb Exhaust T/C 14',\n",
              "       'Turb Exhaust T/C 16', 'Turb Exhaust T/C 17', 'Turb Exhaust T/C 18',\n",
              "       'Turb Exhaust T/C 19', 'Turb Exhaust T/C 20', 'Turb Exhaust T/C 21',\n",
              "       'Turb Exhaust T/C 22', 'Turb Exhaust T/C 23', 'Turb Exhaust T/C 24',\n",
              "       'Turb Exhaust T/C 25', 'Turb Exhaust T/C 26', 'Turb Exhaust T/C 27',\n",
              "       'Turb Exhaust T/C 28', 'Turb Exhaust T/C 29', 'Turb Exhaust T/C 30',\n",
              "       'Turb Exhaust T/C 31', 'Combust Monitor Actual Spread 1'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain , Xtest , Ytrain , Ytest = train_test_split(X , Y , test_size = 0.2 , random_state = 4)"
      ],
      "metadata": {
        "id": "lKNlEbvl6VV4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(Xtrain)\n",
        "\n",
        "Xtrain_scaled = scaler.transform(Xtrain)\n",
        "Xtest_scaled = scaler.transform(Xtest)"
      ],
      "metadata": {
        "id": "97ydOg056VYs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_object(scaler,\"scaler\")"
      ],
      "metadata": {
        "id": "296OJsUw05TT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 28)\n",
        "Xtrain = pca.fit_transform(Xtrain)\n",
        "Xtest = pca.transform(Xtest)\n",
        "\n",
        "plt.plot(pca.explained_variance_ratio_.cumsum())"
      ],
      "metadata": {
        "id": "-zVoac3_3f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "cb7f98ca-0143-4cd4-9c09-3dab767568d7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x792c22c30be0>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "7MUlsr_NzPsW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression()"
      ],
      "metadata": {
        "id": "AQARVMap3f-R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Xtrain , Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "y5Yx9K1F3rHe",
        "outputId": "0c7e6d91-de15-49ac-d4e0-bdf9e730be58"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred = model.predict(Xtest)"
      ],
      "metadata": {
        "id": "kuhSOBXu3rKq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "mse_lr = mean_squared_error(Ytest,Ypred)\n",
        "mae_lr = mean_absolute_error(Ytest,Ypred)\n",
        "print(\" Mean squared error from linear regression : \" , mse_lr)\n",
        "print(\" Mean absolute error from linear regression : \" , mae_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72X5vCkE3rNj",
        "outputId": "9f98d905-5e28-48c6-9bf4-a834116d28c0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from linear regression :  1.8103323259252393\n",
            " Mean absolute error from linear regression :  1.0501973959209432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2Wugh4Y3rS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported Network designed in previous lesson\n",
        "\n",
        "# Start your model with Sequential Object\n",
        "model = tf.keras.models.Sequential()\n",
        "# Next add in your Input object and Specify the Dimension you want to pass in\n",
        "model.add(tf.keras.Input(shape=(20,)))\n",
        "# Add in your Neurons of 1st layer\n",
        "model.add(tf.keras.layers.Dense(1000, activation='sigmoid'))\n",
        "# 2nd layer\n",
        "model.add(tf.keras.layers.Dense(500, activation='sigmoid'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1 , activation='linear'))\n",
        "\n",
        "\n",
        "Optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(Optimizer, loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# print summary to undertstand your neural network flow\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eUu-P0lz6VbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b12c4d-e9dc-4dfe-8cdc-9045c53dae8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 1000)              21000     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 522001 (1.99 MB)\n",
            "Trainable params: 522001 (1.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xtrain , Ytrain , validation_data=(Xtest , Ytest) , epochs=1000)"
      ],
      "metadata": {
        "id": "arJHOFaJta5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f3cc3a-3399-463c-d45b-d18473fa8dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "69/69 [==============================] - 1s 5ms/step - loss: 122.4626 - mae: 9.2083 - val_loss: 21.5949 - val_mae: 4.0872\n",
            "Epoch 2/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 14.7861 - mae: 2.9814 - val_loss: 15.5154 - val_mae: 2.9200\n",
            "Epoch 3/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8349 - mae: 2.7481 - val_loss: 15.5078 - val_mae: 2.9166\n",
            "Epoch 4/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8507 - mae: 2.7445 - val_loss: 15.5369 - val_mae: 2.9334\n",
            "Epoch 5/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8289 - mae: 2.7446 - val_loss: 15.4548 - val_mae: 2.8804\n",
            "Epoch 6/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8249 - mae: 2.7349 - val_loss: 15.4795 - val_mae: 2.9037\n",
            "Epoch 7/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8316 - mae: 2.7453 - val_loss: 15.4850 - val_mae: 2.9099\n",
            "Epoch 8/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8191 - mae: 2.7354 - val_loss: 15.4875 - val_mae: 2.9145\n",
            "Epoch 9/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8200 - mae: 2.7514 - val_loss: 15.4268 - val_mae: 2.8723\n",
            "Epoch 10/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.8204 - mae: 2.7427 - val_loss: 15.4746 - val_mae: 2.9174\n",
            "Epoch 11/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.7713 - mae: 2.7458 - val_loss: 15.3996 - val_mae: 2.8321\n",
            "Epoch 12/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.7571 - mae: 2.7339 - val_loss: 15.3649 - val_mae: 2.8923\n",
            "Epoch 13/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.7004 - mae: 2.7363 - val_loss: 15.3079 - val_mae: 2.9337\n",
            "Epoch 14/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 12.9375 - mae: 2.6644 - val_loss: 13.3743 - val_mae: 2.7814\n",
            "Epoch 15/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 8.6907 - mae: 2.2156 - val_loss: 7.0842 - val_mae: 2.0201\n",
            "Epoch 16/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 4.7363 - mae: 1.6848 - val_loss: 4.6146 - val_mae: 1.6579\n",
            "Epoch 17/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 3.4222 - mae: 1.4229 - val_loss: 3.6266 - val_mae: 1.4445\n",
            "Epoch 18/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 3.0550 - mae: 1.3427 - val_loss: 3.7138 - val_mae: 1.4199\n",
            "Epoch 19/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.9604 - mae: 1.2947 - val_loss: 3.2094 - val_mae: 1.2969\n",
            "Epoch 20/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.7934 - mae: 1.2553 - val_loss: 3.2220 - val_mae: 1.3011\n",
            "Epoch 21/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.8926 - mae: 1.2841 - val_loss: 3.1006 - val_mae: 1.2705\n",
            "Epoch 22/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.7605 - mae: 1.2429 - val_loss: 2.9863 - val_mae: 1.2432\n",
            "Epoch 23/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.7468 - mae: 1.2361 - val_loss: 2.9277 - val_mae: 1.2389\n",
            "Epoch 24/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6858 - mae: 1.2218 - val_loss: 2.9776 - val_mae: 1.2548\n",
            "Epoch 25/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6646 - mae: 1.2132 - val_loss: 2.9525 - val_mae: 1.2448\n",
            "Epoch 26/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6874 - mae: 1.2328 - val_loss: 3.0739 - val_mae: 1.2786\n",
            "Epoch 27/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.8128 - mae: 1.2615 - val_loss: 2.8949 - val_mae: 1.2288\n",
            "Epoch 28/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.7672 - mae: 1.2411 - val_loss: 2.9444 - val_mae: 1.2305\n",
            "Epoch 29/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6812 - mae: 1.2226 - val_loss: 2.9014 - val_mae: 1.2269\n",
            "Epoch 30/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.7072 - mae: 1.2268 - val_loss: 2.9552 - val_mae: 1.2437\n",
            "Epoch 31/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6559 - mae: 1.2128 - val_loss: 2.9273 - val_mae: 1.2415\n",
            "Epoch 32/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.7066 - mae: 1.2239 - val_loss: 2.9347 - val_mae: 1.2416\n",
            "Epoch 33/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.7234 - mae: 1.2332 - val_loss: 2.9387 - val_mae: 1.2401\n",
            "Epoch 34/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6339 - mae: 1.2168 - val_loss: 2.8171 - val_mae: 1.2105\n",
            "Epoch 35/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6428 - mae: 1.2100 - val_loss: 3.0992 - val_mae: 1.2791\n",
            "Epoch 36/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6313 - mae: 1.2059 - val_loss: 2.9187 - val_mae: 1.2423\n",
            "Epoch 37/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6881 - mae: 1.2129 - val_loss: 2.8280 - val_mae: 1.2181\n",
            "Epoch 38/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6114 - mae: 1.1997 - val_loss: 2.8545 - val_mae: 1.2273\n",
            "Epoch 39/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6245 - mae: 1.2064 - val_loss: 2.8253 - val_mae: 1.2111\n",
            "Epoch 40/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6430 - mae: 1.2128 - val_loss: 2.8352 - val_mae: 1.2174\n",
            "Epoch 41/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6242 - mae: 1.1963 - val_loss: 2.8852 - val_mae: 1.2282\n",
            "Epoch 42/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6076 - mae: 1.1987 - val_loss: 2.8397 - val_mae: 1.2130\n",
            "Epoch 43/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5978 - mae: 1.1967 - val_loss: 2.9216 - val_mae: 1.2404\n",
            "Epoch 44/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6080 - mae: 1.1998 - val_loss: 2.9352 - val_mae: 1.2465\n",
            "Epoch 45/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.7162 - mae: 1.2205 - val_loss: 2.8896 - val_mae: 1.2328\n",
            "Epoch 46/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6340 - mae: 1.2083 - val_loss: 2.8676 - val_mae: 1.2302\n",
            "Epoch 47/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6163 - mae: 1.2029 - val_loss: 2.8165 - val_mae: 1.2124\n",
            "Epoch 48/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6150 - mae: 1.1983 - val_loss: 2.9430 - val_mae: 1.2719\n",
            "Epoch 49/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5983 - mae: 1.1997 - val_loss: 2.7591 - val_mae: 1.1976\n",
            "Epoch 50/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6754 - mae: 1.2176 - val_loss: 2.8930 - val_mae: 1.2559\n",
            "Epoch 51/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5950 - mae: 1.2023 - val_loss: 2.8764 - val_mae: 1.2291\n",
            "Epoch 52/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5977 - mae: 1.1933 - val_loss: 2.9861 - val_mae: 1.2584\n",
            "Epoch 53/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5701 - mae: 1.1915 - val_loss: 2.7945 - val_mae: 1.2135\n",
            "Epoch 54/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6156 - mae: 1.2024 - val_loss: 2.8101 - val_mae: 1.2248\n",
            "Epoch 55/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5408 - mae: 1.1848 - val_loss: 2.7545 - val_mae: 1.2055\n",
            "Epoch 56/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5933 - mae: 1.2031 - val_loss: 2.8783 - val_mae: 1.2346\n",
            "Epoch 57/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6267 - mae: 1.1968 - val_loss: 2.9326 - val_mae: 1.2697\n",
            "Epoch 58/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6543 - mae: 1.2129 - val_loss: 2.9135 - val_mae: 1.2486\n",
            "Epoch 59/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5544 - mae: 1.1847 - val_loss: 3.0733 - val_mae: 1.2999\n",
            "Epoch 60/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5854 - mae: 1.1892 - val_loss: 2.8399 - val_mae: 1.2319\n",
            "Epoch 61/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5614 - mae: 1.1902 - val_loss: 2.7729 - val_mae: 1.2027\n",
            "Epoch 62/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5890 - mae: 1.2044 - val_loss: 2.8592 - val_mae: 1.2368\n",
            "Epoch 63/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6591 - mae: 1.2185 - val_loss: 2.9826 - val_mae: 1.2680\n",
            "Epoch 64/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5835 - mae: 1.1976 - val_loss: 2.7734 - val_mae: 1.2092\n",
            "Epoch 65/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5942 - mae: 1.1930 - val_loss: 2.7910 - val_mae: 1.2161\n",
            "Epoch 66/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5636 - mae: 1.1943 - val_loss: 3.0827 - val_mae: 1.2888\n",
            "Epoch 67/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5461 - mae: 1.1862 - val_loss: 2.9301 - val_mae: 1.2434\n",
            "Epoch 68/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.6125 - mae: 1.1946 - val_loss: 2.7623 - val_mae: 1.2165\n",
            "Epoch 69/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5451 - mae: 1.1811 - val_loss: 2.7222 - val_mae: 1.1981\n",
            "Epoch 70/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5267 - mae: 1.1867 - val_loss: 2.9054 - val_mae: 1.2672\n",
            "Epoch 71/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5655 - mae: 1.1909 - val_loss: 2.8073 - val_mae: 1.2163\n",
            "Epoch 72/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5530 - mae: 1.1879 - val_loss: 2.7908 - val_mae: 1.2226\n",
            "Epoch 73/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5933 - mae: 1.1964 - val_loss: 2.7890 - val_mae: 1.2157\n",
            "Epoch 74/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5040 - mae: 1.1719 - val_loss: 2.8516 - val_mae: 1.2335\n",
            "Epoch 75/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5352 - mae: 1.1743 - val_loss: 2.6995 - val_mae: 1.1990\n",
            "Epoch 76/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5504 - mae: 1.1874 - val_loss: 3.0365 - val_mae: 1.3016\n",
            "Epoch 77/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5839 - mae: 1.1969 - val_loss: 2.7787 - val_mae: 1.1994\n",
            "Epoch 78/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5374 - mae: 1.1827 - val_loss: 2.7280 - val_mae: 1.1934\n",
            "Epoch 79/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5531 - mae: 1.1791 - val_loss: 2.7408 - val_mae: 1.2081\n",
            "Epoch 80/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5427 - mae: 1.1855 - val_loss: 2.9388 - val_mae: 1.2514\n",
            "Epoch 81/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5140 - mae: 1.1770 - val_loss: 2.8075 - val_mae: 1.2292\n",
            "Epoch 82/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5401 - mae: 1.1837 - val_loss: 2.7320 - val_mae: 1.2127\n",
            "Epoch 83/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5765 - mae: 1.1903 - val_loss: 3.1950 - val_mae: 1.3680\n",
            "Epoch 84/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5483 - mae: 1.1877 - val_loss: 2.8698 - val_mae: 1.2487\n",
            "Epoch 85/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5165 - mae: 1.1757 - val_loss: 2.6820 - val_mae: 1.2059\n",
            "Epoch 86/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5455 - mae: 1.1881 - val_loss: 2.7490 - val_mae: 1.1900\n",
            "Epoch 87/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5157 - mae: 1.1772 - val_loss: 2.7573 - val_mae: 1.1970\n",
            "Epoch 88/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5151 - mae: 1.1773 - val_loss: 2.8844 - val_mae: 1.2334\n",
            "Epoch 89/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5854 - mae: 1.2016 - val_loss: 2.9518 - val_mae: 1.2680\n",
            "Epoch 90/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5019 - mae: 1.1746 - val_loss: 2.6621 - val_mae: 1.1769\n",
            "Epoch 91/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5160 - mae: 1.1770 - val_loss: 2.7188 - val_mae: 1.2033\n",
            "Epoch 92/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5091 - mae: 1.1730 - val_loss: 2.8895 - val_mae: 1.2835\n",
            "Epoch 93/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4978 - mae: 1.1799 - val_loss: 2.8502 - val_mae: 1.2163\n",
            "Epoch 94/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5243 - mae: 1.1783 - val_loss: 2.6463 - val_mae: 1.1899\n",
            "Epoch 95/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4707 - mae: 1.1736 - val_loss: 2.7808 - val_mae: 1.2059\n",
            "Epoch 96/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4752 - mae: 1.1586 - val_loss: 2.8492 - val_mae: 1.2458\n",
            "Epoch 97/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4936 - mae: 1.1702 - val_loss: 2.7799 - val_mae: 1.2147\n",
            "Epoch 98/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4672 - mae: 1.1670 - val_loss: 2.7105 - val_mae: 1.2193\n",
            "Epoch 99/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5010 - mae: 1.1784 - val_loss: 2.7172 - val_mae: 1.2059\n",
            "Epoch 100/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4882 - mae: 1.1697 - val_loss: 2.8177 - val_mae: 1.2097\n",
            "Epoch 101/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4713 - mae: 1.1627 - val_loss: 2.7210 - val_mae: 1.2157\n",
            "Epoch 102/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4654 - mae: 1.1672 - val_loss: 2.8869 - val_mae: 1.2450\n",
            "Epoch 103/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5194 - mae: 1.1837 - val_loss: 2.8404 - val_mae: 1.2514\n",
            "Epoch 104/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5143 - mae: 1.1789 - val_loss: 2.6571 - val_mae: 1.2065\n",
            "Epoch 105/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5630 - mae: 1.1963 - val_loss: 2.7859 - val_mae: 1.2324\n",
            "Epoch 106/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5140 - mae: 1.1768 - val_loss: 2.6768 - val_mae: 1.1819\n",
            "Epoch 107/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4675 - mae: 1.1632 - val_loss: 2.6552 - val_mae: 1.1915\n",
            "Epoch 108/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4699 - mae: 1.1634 - val_loss: 2.7092 - val_mae: 1.1838\n",
            "Epoch 109/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4587 - mae: 1.1635 - val_loss: 2.7221 - val_mae: 1.2111\n",
            "Epoch 110/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4930 - mae: 1.1805 - val_loss: 2.6244 - val_mae: 1.1681\n",
            "Epoch 111/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4463 - mae: 1.1600 - val_loss: 2.6329 - val_mae: 1.1874\n",
            "Epoch 112/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4516 - mae: 1.1640 - val_loss: 2.6645 - val_mae: 1.1855\n",
            "Epoch 113/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4442 - mae: 1.1588 - val_loss: 2.6463 - val_mae: 1.1799\n",
            "Epoch 114/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5415 - mae: 1.1871 - val_loss: 2.8164 - val_mae: 1.2652\n",
            "Epoch 115/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5269 - mae: 1.1832 - val_loss: 2.7922 - val_mae: 1.2539\n",
            "Epoch 116/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.5268 - mae: 1.1917 - val_loss: 2.6809 - val_mae: 1.1952\n",
            "Epoch 117/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4342 - mae: 1.1546 - val_loss: 2.6682 - val_mae: 1.1929\n",
            "Epoch 118/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4940 - mae: 1.1785 - val_loss: 2.6318 - val_mae: 1.1727\n",
            "Epoch 119/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4527 - mae: 1.1629 - val_loss: 2.6852 - val_mae: 1.2196\n",
            "Epoch 120/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4692 - mae: 1.1650 - val_loss: 2.5960 - val_mae: 1.1768\n",
            "Epoch 121/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4887 - mae: 1.1774 - val_loss: 2.7662 - val_mae: 1.2134\n",
            "Epoch 122/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4373 - mae: 1.1634 - val_loss: 2.6286 - val_mae: 1.1873\n",
            "Epoch 123/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4315 - mae: 1.1614 - val_loss: 2.8860 - val_mae: 1.2624\n",
            "Epoch 124/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4761 - mae: 1.1741 - val_loss: 2.5972 - val_mae: 1.1596\n",
            "Epoch 125/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4567 - mae: 1.1612 - val_loss: 2.6456 - val_mae: 1.1880\n",
            "Epoch 126/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5218 - mae: 1.1805 - val_loss: 2.7523 - val_mae: 1.2184\n",
            "Epoch 127/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4463 - mae: 1.1660 - val_loss: 2.6681 - val_mae: 1.1856\n",
            "Epoch 128/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4356 - mae: 1.1610 - val_loss: 2.5733 - val_mae: 1.1624\n",
            "Epoch 129/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4289 - mae: 1.1594 - val_loss: 2.5994 - val_mae: 1.1754\n",
            "Epoch 130/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4405 - mae: 1.1630 - val_loss: 2.5853 - val_mae: 1.1802\n",
            "Epoch 131/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4469 - mae: 1.1553 - val_loss: 2.6306 - val_mae: 1.2006\n",
            "Epoch 132/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5068 - mae: 1.1772 - val_loss: 2.6055 - val_mae: 1.1640\n",
            "Epoch 133/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4331 - mae: 1.1552 - val_loss: 2.5970 - val_mae: 1.1602\n",
            "Epoch 134/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4372 - mae: 1.1645 - val_loss: 2.8702 - val_mae: 1.2327\n",
            "Epoch 135/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4643 - mae: 1.1566 - val_loss: 2.7609 - val_mae: 1.2448\n",
            "Epoch 136/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4211 - mae: 1.1490 - val_loss: 2.5784 - val_mae: 1.1714\n",
            "Epoch 137/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4632 - mae: 1.1616 - val_loss: 2.6744 - val_mae: 1.1764\n",
            "Epoch 138/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4583 - mae: 1.1678 - val_loss: 2.6888 - val_mae: 1.1836\n",
            "Epoch 139/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4270 - mae: 1.1543 - val_loss: 2.6488 - val_mae: 1.2074\n",
            "Epoch 140/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4435 - mae: 1.1558 - val_loss: 2.6009 - val_mae: 1.1739\n",
            "Epoch 141/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4142 - mae: 1.1553 - val_loss: 2.5952 - val_mae: 1.1573\n",
            "Epoch 142/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4200 - mae: 1.1441 - val_loss: 2.5981 - val_mae: 1.1779\n",
            "Epoch 143/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4255 - mae: 1.1599 - val_loss: 2.5817 - val_mae: 1.1550\n",
            "Epoch 144/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4229 - mae: 1.1532 - val_loss: 2.6914 - val_mae: 1.1913\n",
            "Epoch 145/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4167 - mae: 1.1474 - val_loss: 2.6184 - val_mae: 1.2069\n",
            "Epoch 146/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4987 - mae: 1.1732 - val_loss: 2.5820 - val_mae: 1.1882\n",
            "Epoch 147/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4085 - mae: 1.1509 - val_loss: 2.6931 - val_mae: 1.2079\n",
            "Epoch 148/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4106 - mae: 1.1451 - val_loss: 2.6627 - val_mae: 1.1859\n",
            "Epoch 149/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4023 - mae: 1.1513 - val_loss: 2.5736 - val_mae: 1.1526\n",
            "Epoch 150/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4026 - mae: 1.1444 - val_loss: 2.5946 - val_mae: 1.1579\n",
            "Epoch 151/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4243 - mae: 1.1581 - val_loss: 2.7486 - val_mae: 1.1998\n",
            "Epoch 152/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4953 - mae: 1.1794 - val_loss: 2.5802 - val_mae: 1.1583\n",
            "Epoch 153/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3786 - mae: 1.1379 - val_loss: 2.5539 - val_mae: 1.1584\n",
            "Epoch 154/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4065 - mae: 1.1518 - val_loss: 2.7257 - val_mae: 1.2057\n",
            "Epoch 155/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4070 - mae: 1.1470 - val_loss: 2.6077 - val_mae: 1.1599\n",
            "Epoch 156/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4260 - mae: 1.1424 - val_loss: 2.7481 - val_mae: 1.2319\n",
            "Epoch 157/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4584 - mae: 1.1651 - val_loss: 2.5937 - val_mae: 1.1516\n",
            "Epoch 158/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3623 - mae: 1.1387 - val_loss: 2.6197 - val_mae: 1.1670\n",
            "Epoch 159/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4049 - mae: 1.1507 - val_loss: 2.6704 - val_mae: 1.1862\n",
            "Epoch 160/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3952 - mae: 1.1459 - val_loss: 2.5327 - val_mae: 1.1448\n",
            "Epoch 161/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3977 - mae: 1.1463 - val_loss: 2.6397 - val_mae: 1.1990\n",
            "Epoch 162/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3825 - mae: 1.1385 - val_loss: 2.6178 - val_mae: 1.1897\n",
            "Epoch 163/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4383 - mae: 1.1689 - val_loss: 2.5769 - val_mae: 1.1606\n",
            "Epoch 164/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3982 - mae: 1.1529 - val_loss: 2.6711 - val_mae: 1.2129\n",
            "Epoch 165/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3896 - mae: 1.1495 - val_loss: 2.7193 - val_mae: 1.1836\n",
            "Epoch 166/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3934 - mae: 1.1500 - val_loss: 2.5854 - val_mae: 1.1623\n",
            "Epoch 167/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4297 - mae: 1.1498 - val_loss: 2.5033 - val_mae: 1.1614\n",
            "Epoch 168/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4193 - mae: 1.1599 - val_loss: 2.6127 - val_mae: 1.1667\n",
            "Epoch 169/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4011 - mae: 1.1502 - val_loss: 2.5640 - val_mae: 1.1914\n",
            "Epoch 170/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3863 - mae: 1.1471 - val_loss: 2.6350 - val_mae: 1.1997\n",
            "Epoch 171/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3866 - mae: 1.1391 - val_loss: 2.6578 - val_mae: 1.1743\n",
            "Epoch 172/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3723 - mae: 1.1397 - val_loss: 2.6577 - val_mae: 1.1790\n",
            "Epoch 173/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3790 - mae: 1.1367 - val_loss: 2.5109 - val_mae: 1.1361\n",
            "Epoch 174/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4133 - mae: 1.1493 - val_loss: 2.5758 - val_mae: 1.1808\n",
            "Epoch 175/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4142 - mae: 1.1488 - val_loss: 2.5137 - val_mae: 1.1707\n",
            "Epoch 176/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3821 - mae: 1.1387 - val_loss: 2.6584 - val_mae: 1.1856\n",
            "Epoch 177/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4087 - mae: 1.1506 - val_loss: 2.4937 - val_mae: 1.1449\n",
            "Epoch 178/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4665 - mae: 1.1684 - val_loss: 2.8264 - val_mae: 1.1988\n",
            "Epoch 179/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4326 - mae: 1.1573 - val_loss: 2.4480 - val_mae: 1.1352\n",
            "Epoch 180/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4225 - mae: 1.1532 - val_loss: 2.5378 - val_mae: 1.1621\n",
            "Epoch 181/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3843 - mae: 1.1439 - val_loss: 2.5279 - val_mae: 1.1516\n",
            "Epoch 182/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3770 - mae: 1.1394 - val_loss: 2.4558 - val_mae: 1.1379\n",
            "Epoch 183/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3778 - mae: 1.1416 - val_loss: 2.5467 - val_mae: 1.1622\n",
            "Epoch 184/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3688 - mae: 1.1355 - val_loss: 2.4927 - val_mae: 1.1344\n",
            "Epoch 185/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3654 - mae: 1.1336 - val_loss: 2.6081 - val_mae: 1.1657\n",
            "Epoch 186/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3951 - mae: 1.1479 - val_loss: 2.5607 - val_mae: 1.1826\n",
            "Epoch 187/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3752 - mae: 1.1430 - val_loss: 2.5525 - val_mae: 1.1635\n",
            "Epoch 188/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3800 - mae: 1.1381 - val_loss: 2.7686 - val_mae: 1.2114\n",
            "Epoch 189/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4751 - mae: 1.1726 - val_loss: 2.5762 - val_mae: 1.1643\n",
            "Epoch 190/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4209 - mae: 1.1565 - val_loss: 2.4996 - val_mae: 1.1413\n",
            "Epoch 191/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3382 - mae: 1.1278 - val_loss: 2.7246 - val_mae: 1.1823\n",
            "Epoch 192/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3710 - mae: 1.1438 - val_loss: 2.6354 - val_mae: 1.1800\n",
            "Epoch 193/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3916 - mae: 1.1397 - val_loss: 2.5517 - val_mae: 1.1641\n",
            "Epoch 194/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3543 - mae: 1.1376 - val_loss: 2.4314 - val_mae: 1.1294\n",
            "Epoch 195/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3887 - mae: 1.1473 - val_loss: 2.5122 - val_mae: 1.1374\n",
            "Epoch 196/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3863 - mae: 1.1411 - val_loss: 2.7347 - val_mae: 1.2226\n",
            "Epoch 197/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3762 - mae: 1.1403 - val_loss: 2.4519 - val_mae: 1.1300\n",
            "Epoch 198/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3879 - mae: 1.1460 - val_loss: 2.5127 - val_mae: 1.1480\n",
            "Epoch 199/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3549 - mae: 1.1279 - val_loss: 2.6094 - val_mae: 1.1603\n",
            "Epoch 200/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3870 - mae: 1.1440 - val_loss: 2.7142 - val_mae: 1.1818\n",
            "Epoch 201/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3821 - mae: 1.1395 - val_loss: 2.4413 - val_mae: 1.1288\n",
            "Epoch 202/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3550 - mae: 1.1264 - val_loss: 2.5900 - val_mae: 1.1612\n",
            "Epoch 203/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3494 - mae: 1.1308 - val_loss: 2.5257 - val_mae: 1.1522\n",
            "Epoch 204/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3665 - mae: 1.1371 - val_loss: 2.4662 - val_mae: 1.1288\n",
            "Epoch 205/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3856 - mae: 1.1374 - val_loss: 2.4980 - val_mae: 1.1592\n",
            "Epoch 206/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3705 - mae: 1.1391 - val_loss: 2.7959 - val_mae: 1.2102\n",
            "Epoch 207/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3454 - mae: 1.1290 - val_loss: 2.6882 - val_mae: 1.1639\n",
            "Epoch 208/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4190 - mae: 1.1486 - val_loss: 2.6393 - val_mae: 1.1802\n",
            "Epoch 209/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3934 - mae: 1.1396 - val_loss: 2.5020 - val_mae: 1.1484\n",
            "Epoch 210/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4021 - mae: 1.1489 - val_loss: 2.5633 - val_mae: 1.1528\n",
            "Epoch 211/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3568 - mae: 1.1305 - val_loss: 2.4620 - val_mae: 1.1527\n",
            "Epoch 212/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3598 - mae: 1.1377 - val_loss: 2.4574 - val_mae: 1.1237\n",
            "Epoch 213/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3469 - mae: 1.1211 - val_loss: 2.4469 - val_mae: 1.1421\n",
            "Epoch 214/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3568 - mae: 1.1340 - val_loss: 2.5159 - val_mae: 1.1412\n",
            "Epoch 215/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3261 - mae: 1.1239 - val_loss: 2.4673 - val_mae: 1.1286\n",
            "Epoch 216/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3836 - mae: 1.1448 - val_loss: 2.5660 - val_mae: 1.1565\n",
            "Epoch 217/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3407 - mae: 1.1259 - val_loss: 2.5656 - val_mae: 1.1530\n",
            "Epoch 218/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3549 - mae: 1.1297 - val_loss: 2.5450 - val_mae: 1.1567\n",
            "Epoch 219/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3395 - mae: 1.1266 - val_loss: 2.4604 - val_mae: 1.1332\n",
            "Epoch 220/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3429 - mae: 1.1287 - val_loss: 2.5048 - val_mae: 1.1566\n",
            "Epoch 221/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3488 - mae: 1.1363 - val_loss: 2.6038 - val_mae: 1.1652\n",
            "Epoch 222/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3311 - mae: 1.1242 - val_loss: 2.5674 - val_mae: 1.1707\n",
            "Epoch 223/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3561 - mae: 1.1363 - val_loss: 2.6212 - val_mae: 1.2049\n",
            "Epoch 224/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4130 - mae: 1.1492 - val_loss: 2.5677 - val_mae: 1.1526\n",
            "Epoch 225/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3714 - mae: 1.1472 - val_loss: 2.4306 - val_mae: 1.1377\n",
            "Epoch 226/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.4445 - mae: 1.1586 - val_loss: 2.4925 - val_mae: 1.1392\n",
            "Epoch 227/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3886 - mae: 1.1470 - val_loss: 2.6602 - val_mae: 1.1748\n",
            "Epoch 228/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3884 - mae: 1.1463 - val_loss: 2.5011 - val_mae: 1.1318\n",
            "Epoch 229/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3187 - mae: 1.1222 - val_loss: 2.4700 - val_mae: 1.1422\n",
            "Epoch 230/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3285 - mae: 1.1155 - val_loss: 2.4795 - val_mae: 1.1403\n",
            "Epoch 231/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3578 - mae: 1.1338 - val_loss: 2.5194 - val_mae: 1.1433\n",
            "Epoch 232/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3287 - mae: 1.1248 - val_loss: 2.5960 - val_mae: 1.1588\n",
            "Epoch 233/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3751 - mae: 1.1436 - val_loss: 2.5299 - val_mae: 1.1477\n",
            "Epoch 234/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3810 - mae: 1.1417 - val_loss: 2.5045 - val_mae: 1.1531\n",
            "Epoch 235/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3356 - mae: 1.1300 - val_loss: 2.4562 - val_mae: 1.1315\n",
            "Epoch 236/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3242 - mae: 1.1262 - val_loss: 2.4575 - val_mae: 1.1385\n",
            "Epoch 237/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3435 - mae: 1.1271 - val_loss: 2.4143 - val_mae: 1.1258\n",
            "Epoch 238/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3176 - mae: 1.1221 - val_loss: 2.4494 - val_mae: 1.1334\n",
            "Epoch 239/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3312 - mae: 1.1266 - val_loss: 2.4554 - val_mae: 1.1390\n",
            "Epoch 240/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3791 - mae: 1.1400 - val_loss: 2.5423 - val_mae: 1.1856\n",
            "Epoch 241/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3772 - mae: 1.1363 - val_loss: 2.4500 - val_mae: 1.1341\n",
            "Epoch 242/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3304 - mae: 1.1244 - val_loss: 2.5399 - val_mae: 1.1410\n",
            "Epoch 243/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3497 - mae: 1.1271 - val_loss: 2.4638 - val_mae: 1.1451\n",
            "Epoch 244/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3157 - mae: 1.1195 - val_loss: 2.4493 - val_mae: 1.1297\n",
            "Epoch 245/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3278 - mae: 1.1291 - val_loss: 2.4577 - val_mae: 1.1195\n",
            "Epoch 246/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3307 - mae: 1.1297 - val_loss: 2.5280 - val_mae: 1.1835\n",
            "Epoch 247/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3270 - mae: 1.1196 - val_loss: 2.5122 - val_mae: 1.1326\n",
            "Epoch 248/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3608 - mae: 1.1278 - val_loss: 2.4330 - val_mae: 1.1186\n",
            "Epoch 249/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3246 - mae: 1.1249 - val_loss: 2.5391 - val_mae: 1.1762\n",
            "Epoch 250/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3271 - mae: 1.1267 - val_loss: 2.5610 - val_mae: 1.1428\n",
            "Epoch 251/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3309 - mae: 1.1253 - val_loss: 2.5113 - val_mae: 1.1392\n",
            "Epoch 252/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3040 - mae: 1.1187 - val_loss: 2.4424 - val_mae: 1.1360\n",
            "Epoch 253/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3182 - mae: 1.1234 - val_loss: 2.4576 - val_mae: 1.1507\n",
            "Epoch 254/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3338 - mae: 1.1338 - val_loss: 2.7310 - val_mae: 1.2057\n",
            "Epoch 255/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3417 - mae: 1.1225 - val_loss: 2.4909 - val_mae: 1.1340\n",
            "Epoch 256/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3024 - mae: 1.1182 - val_loss: 2.5295 - val_mae: 1.1440\n",
            "Epoch 257/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3126 - mae: 1.1210 - val_loss: 2.4481 - val_mae: 1.1299\n",
            "Epoch 258/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3278 - mae: 1.1234 - val_loss: 2.5015 - val_mae: 1.1391\n",
            "Epoch 259/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3150 - mae: 1.1282 - val_loss: 2.4379 - val_mae: 1.1480\n",
            "Epoch 260/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.4670 - mae: 1.1698 - val_loss: 2.4308 - val_mae: 1.1455\n",
            "Epoch 261/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3776 - mae: 1.1386 - val_loss: 2.5720 - val_mae: 1.1629\n",
            "Epoch 262/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2994 - mae: 1.1173 - val_loss: 2.4795 - val_mae: 1.1534\n",
            "Epoch 263/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3111 - mae: 1.1181 - val_loss: 2.4758 - val_mae: 1.1339\n",
            "Epoch 264/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3162 - mae: 1.1258 - val_loss: 2.4897 - val_mae: 1.1396\n",
            "Epoch 265/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3185 - mae: 1.1180 - val_loss: 2.4077 - val_mae: 1.1321\n",
            "Epoch 266/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3200 - mae: 1.1217 - val_loss: 2.4936 - val_mae: 1.1386\n",
            "Epoch 267/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3343 - mae: 1.1309 - val_loss: 2.6103 - val_mae: 1.1738\n",
            "Epoch 268/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3378 - mae: 1.1299 - val_loss: 2.5562 - val_mae: 1.1447\n",
            "Epoch 269/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3111 - mae: 1.1223 - val_loss: 2.3917 - val_mae: 1.1274\n",
            "Epoch 270/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3843 - mae: 1.1437 - val_loss: 2.5913 - val_mae: 1.2041\n",
            "Epoch 271/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3167 - mae: 1.1256 - val_loss: 2.5240 - val_mae: 1.1358\n",
            "Epoch 272/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2766 - mae: 1.1213 - val_loss: 2.4287 - val_mae: 1.1469\n",
            "Epoch 273/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3146 - mae: 1.1214 - val_loss: 2.3868 - val_mae: 1.1152\n",
            "Epoch 274/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3588 - mae: 1.1313 - val_loss: 2.7399 - val_mae: 1.2177\n",
            "Epoch 275/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3249 - mae: 1.1249 - val_loss: 2.4363 - val_mae: 1.1225\n",
            "Epoch 276/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3112 - mae: 1.1214 - val_loss: 2.4566 - val_mae: 1.1387\n",
            "Epoch 277/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2917 - mae: 1.1150 - val_loss: 2.3605 - val_mae: 1.1201\n",
            "Epoch 278/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2930 - mae: 1.1203 - val_loss: 2.4247 - val_mae: 1.1283\n",
            "Epoch 279/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3388 - mae: 1.1398 - val_loss: 2.4343 - val_mae: 1.1312\n",
            "Epoch 280/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2896 - mae: 1.1200 - val_loss: 2.6367 - val_mae: 1.1705\n",
            "Epoch 281/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3471 - mae: 1.1207 - val_loss: 2.3855 - val_mae: 1.1215\n",
            "Epoch 282/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3007 - mae: 1.1209 - val_loss: 2.4861 - val_mae: 1.1392\n",
            "Epoch 283/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2604 - mae: 1.1079 - val_loss: 2.5193 - val_mae: 1.1485\n",
            "Epoch 284/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2805 - mae: 1.1183 - val_loss: 2.3668 - val_mae: 1.1184\n",
            "Epoch 285/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3128 - mae: 1.1230 - val_loss: 2.4975 - val_mae: 1.1313\n",
            "Epoch 286/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2750 - mae: 1.1152 - val_loss: 2.3854 - val_mae: 1.1231\n",
            "Epoch 287/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3184 - mae: 1.1246 - val_loss: 2.4935 - val_mae: 1.1284\n",
            "Epoch 288/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3112 - mae: 1.1257 - val_loss: 2.4173 - val_mae: 1.1178\n",
            "Epoch 289/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2973 - mae: 1.1220 - val_loss: 2.4337 - val_mae: 1.1286\n",
            "Epoch 290/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2649 - mae: 1.1163 - val_loss: 2.6309 - val_mae: 1.1736\n",
            "Epoch 291/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2948 - mae: 1.1178 - val_loss: 2.5260 - val_mae: 1.1800\n",
            "Epoch 292/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3012 - mae: 1.1181 - val_loss: 2.4280 - val_mae: 1.1380\n",
            "Epoch 293/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2654 - mae: 1.1225 - val_loss: 2.4621 - val_mae: 1.1251\n",
            "Epoch 294/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3389 - mae: 1.1360 - val_loss: 2.4376 - val_mae: 1.1155\n",
            "Epoch 295/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2972 - mae: 1.1137 - val_loss: 2.5606 - val_mae: 1.1415\n",
            "Epoch 296/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3026 - mae: 1.1177 - val_loss: 2.6259 - val_mae: 1.1596\n",
            "Epoch 297/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2510 - mae: 1.1116 - val_loss: 2.5238 - val_mae: 1.1516\n",
            "Epoch 298/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2927 - mae: 1.1166 - val_loss: 2.3809 - val_mae: 1.1334\n",
            "Epoch 299/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3005 - mae: 1.1162 - val_loss: 2.5178 - val_mae: 1.1576\n",
            "Epoch 300/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3028 - mae: 1.1246 - val_loss: 2.4216 - val_mae: 1.1216\n",
            "Epoch 301/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3060 - mae: 1.1190 - val_loss: 2.5106 - val_mae: 1.1303\n",
            "Epoch 302/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2506 - mae: 1.1015 - val_loss: 2.4821 - val_mae: 1.1372\n",
            "Epoch 303/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2575 - mae: 1.1112 - val_loss: 2.5025 - val_mae: 1.1324\n",
            "Epoch 304/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2552 - mae: 1.1095 - val_loss: 2.4860 - val_mae: 1.1358\n",
            "Epoch 305/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2636 - mae: 1.1123 - val_loss: 2.3954 - val_mae: 1.1165\n",
            "Epoch 306/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2445 - mae: 1.1053 - val_loss: 2.5042 - val_mae: 1.1701\n",
            "Epoch 307/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2701 - mae: 1.1162 - val_loss: 2.4070 - val_mae: 1.1208\n",
            "Epoch 308/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2727 - mae: 1.1124 - val_loss: 2.5190 - val_mae: 1.1483\n",
            "Epoch 309/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2593 - mae: 1.1137 - val_loss: 2.6441 - val_mae: 1.2051\n",
            "Epoch 310/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3022 - mae: 1.1241 - val_loss: 2.3762 - val_mae: 1.1143\n",
            "Epoch 311/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2787 - mae: 1.1226 - val_loss: 2.4917 - val_mae: 1.1316\n",
            "Epoch 312/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3215 - mae: 1.1271 - val_loss: 2.6232 - val_mae: 1.2192\n",
            "Epoch 313/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3271 - mae: 1.1303 - val_loss: 2.3972 - val_mae: 1.1228\n",
            "Epoch 314/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2482 - mae: 1.1105 - val_loss: 2.3733 - val_mae: 1.1151\n",
            "Epoch 315/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2861 - mae: 1.1203 - val_loss: 2.5267 - val_mae: 1.1354\n",
            "Epoch 316/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2519 - mae: 1.1072 - val_loss: 2.4209 - val_mae: 1.1305\n",
            "Epoch 317/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2828 - mae: 1.1150 - val_loss: 2.4697 - val_mae: 1.1310\n",
            "Epoch 318/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2890 - mae: 1.1146 - val_loss: 2.5150 - val_mae: 1.1344\n",
            "Epoch 319/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2281 - mae: 1.1012 - val_loss: 2.5401 - val_mae: 1.1691\n",
            "Epoch 320/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2535 - mae: 1.1061 - val_loss: 2.3767 - val_mae: 1.1159\n",
            "Epoch 321/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2296 - mae: 1.1081 - val_loss: 2.4073 - val_mae: 1.1200\n",
            "Epoch 322/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2582 - mae: 1.1109 - val_loss: 2.4283 - val_mae: 1.1220\n",
            "Epoch 323/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2780 - mae: 1.1202 - val_loss: 2.4256 - val_mae: 1.1480\n",
            "Epoch 324/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3042 - mae: 1.1245 - val_loss: 2.5710 - val_mae: 1.1522\n",
            "Epoch 325/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2489 - mae: 1.1087 - val_loss: 2.3880 - val_mae: 1.1184\n",
            "Epoch 326/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2549 - mae: 1.1068 - val_loss: 2.3697 - val_mae: 1.1126\n",
            "Epoch 327/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2437 - mae: 1.1104 - val_loss: 2.4781 - val_mae: 1.1410\n",
            "Epoch 328/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2767 - mae: 1.1183 - val_loss: 2.4510 - val_mae: 1.1350\n",
            "Epoch 329/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2796 - mae: 1.1151 - val_loss: 2.3281 - val_mae: 1.1072\n",
            "Epoch 330/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2388 - mae: 1.0990 - val_loss: 2.4136 - val_mae: 1.1329\n",
            "Epoch 331/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2293 - mae: 1.1058 - val_loss: 2.3915 - val_mae: 1.1303\n",
            "Epoch 332/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2247 - mae: 1.0990 - val_loss: 2.3672 - val_mae: 1.1151\n",
            "Epoch 333/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2254 - mae: 1.0980 - val_loss: 2.4199 - val_mae: 1.1226\n",
            "Epoch 334/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2319 - mae: 1.1102 - val_loss: 2.4192 - val_mae: 1.1263\n",
            "Epoch 335/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2250 - mae: 1.1013 - val_loss: 2.3531 - val_mae: 1.1133\n",
            "Epoch 336/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2643 - mae: 1.1103 - val_loss: 2.5278 - val_mae: 1.1435\n",
            "Epoch 337/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2402 - mae: 1.1093 - val_loss: 2.4239 - val_mae: 1.1567\n",
            "Epoch 338/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2202 - mae: 1.1008 - val_loss: 2.5422 - val_mae: 1.1947\n",
            "Epoch 339/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2541 - mae: 1.1129 - val_loss: 2.3468 - val_mae: 1.1114\n",
            "Epoch 340/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2577 - mae: 1.1182 - val_loss: 2.4360 - val_mae: 1.1509\n",
            "Epoch 341/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2448 - mae: 1.1094 - val_loss: 2.3860 - val_mae: 1.1291\n",
            "Epoch 342/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2085 - mae: 1.0965 - val_loss: 2.3946 - val_mae: 1.1265\n",
            "Epoch 343/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2947 - mae: 1.1156 - val_loss: 2.3447 - val_mae: 1.1128\n",
            "Epoch 344/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2716 - mae: 1.1205 - val_loss: 2.4322 - val_mae: 1.1462\n",
            "Epoch 345/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2096 - mae: 1.1047 - val_loss: 2.3539 - val_mae: 1.1368\n",
            "Epoch 346/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2557 - mae: 1.1081 - val_loss: 2.3043 - val_mae: 1.1106\n",
            "Epoch 347/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2270 - mae: 1.1047 - val_loss: 2.3614 - val_mae: 1.1206\n",
            "Epoch 348/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2047 - mae: 1.0925 - val_loss: 2.4074 - val_mae: 1.1235\n",
            "Epoch 349/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1919 - mae: 1.1049 - val_loss: 2.3906 - val_mae: 1.1304\n",
            "Epoch 350/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2026 - mae: 1.1040 - val_loss: 2.5901 - val_mae: 1.1527\n",
            "Epoch 351/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2117 - mae: 1.0932 - val_loss: 2.4299 - val_mae: 1.1348\n",
            "Epoch 352/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2413 - mae: 1.1095 - val_loss: 2.3439 - val_mae: 1.1193\n",
            "Epoch 353/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2575 - mae: 1.1163 - val_loss: 2.5748 - val_mae: 1.1706\n",
            "Epoch 354/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2481 - mae: 1.1110 - val_loss: 2.3596 - val_mae: 1.1356\n",
            "Epoch 355/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2087 - mae: 1.0993 - val_loss: 2.2783 - val_mae: 1.1129\n",
            "Epoch 356/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2431 - mae: 1.1085 - val_loss: 2.4151 - val_mae: 1.1366\n",
            "Epoch 357/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2047 - mae: 1.1014 - val_loss: 2.3162 - val_mae: 1.1173\n",
            "Epoch 358/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1966 - mae: 1.0941 - val_loss: 2.3416 - val_mae: 1.1111\n",
            "Epoch 359/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2437 - mae: 1.1115 - val_loss: 2.3782 - val_mae: 1.1360\n",
            "Epoch 360/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2379 - mae: 1.1145 - val_loss: 2.3514 - val_mae: 1.1110\n",
            "Epoch 361/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2152 - mae: 1.1054 - val_loss: 2.5657 - val_mae: 1.1933\n",
            "Epoch 362/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2441 - mae: 1.1125 - val_loss: 2.5700 - val_mae: 1.1614\n",
            "Epoch 363/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2103 - mae: 1.0985 - val_loss: 2.3576 - val_mae: 1.1154\n",
            "Epoch 364/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1956 - mae: 1.0919 - val_loss: 2.4389 - val_mae: 1.1389\n",
            "Epoch 365/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2191 - mae: 1.1039 - val_loss: 2.4561 - val_mae: 1.1682\n",
            "Epoch 366/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1834 - mae: 1.0987 - val_loss: 2.3737 - val_mae: 1.1310\n",
            "Epoch 367/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2239 - mae: 1.1088 - val_loss: 2.4386 - val_mae: 1.1356\n",
            "Epoch 368/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2143 - mae: 1.0990 - val_loss: 2.3725 - val_mae: 1.1332\n",
            "Epoch 369/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1734 - mae: 1.0925 - val_loss: 2.5005 - val_mae: 1.1697\n",
            "Epoch 370/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2031 - mae: 1.0973 - val_loss: 2.3961 - val_mae: 1.1248\n",
            "Epoch 371/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1942 - mae: 1.1030 - val_loss: 2.3487 - val_mae: 1.1158\n",
            "Epoch 372/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1663 - mae: 1.0922 - val_loss: 2.3810 - val_mae: 1.1374\n",
            "Epoch 373/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2159 - mae: 1.1043 - val_loss: 2.3746 - val_mae: 1.1326\n",
            "Epoch 374/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2244 - mae: 1.1032 - val_loss: 2.3251 - val_mae: 1.1138\n",
            "Epoch 375/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2907 - mae: 1.1293 - val_loss: 2.3199 - val_mae: 1.1138\n",
            "Epoch 376/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2351 - mae: 1.1055 - val_loss: 2.3632 - val_mae: 1.1270\n",
            "Epoch 377/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1978 - mae: 1.0991 - val_loss: 2.3995 - val_mae: 1.1362\n",
            "Epoch 378/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2128 - mae: 1.1002 - val_loss: 2.4412 - val_mae: 1.1723\n",
            "Epoch 379/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2315 - mae: 1.1040 - val_loss: 2.3402 - val_mae: 1.1203\n",
            "Epoch 380/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1933 - mae: 1.0961 - val_loss: 2.3888 - val_mae: 1.1406\n",
            "Epoch 381/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2017 - mae: 1.1004 - val_loss: 2.3163 - val_mae: 1.1266\n",
            "Epoch 382/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1930 - mae: 1.1052 - val_loss: 2.4138 - val_mae: 1.1264\n",
            "Epoch 383/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1895 - mae: 1.0912 - val_loss: 2.4427 - val_mae: 1.1589\n",
            "Epoch 384/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.2030 - mae: 1.1026 - val_loss: 2.5364 - val_mae: 1.2120\n",
            "Epoch 385/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1922 - mae: 1.0986 - val_loss: 2.3144 - val_mae: 1.1152\n",
            "Epoch 386/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1680 - mae: 1.0956 - val_loss: 2.3192 - val_mae: 1.1129\n",
            "Epoch 387/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1594 - mae: 1.0932 - val_loss: 2.3112 - val_mae: 1.1174\n",
            "Epoch 388/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1516 - mae: 1.0893 - val_loss: 2.3702 - val_mae: 1.1252\n",
            "Epoch 389/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1662 - mae: 1.0848 - val_loss: 2.3652 - val_mae: 1.1258\n",
            "Epoch 390/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1969 - mae: 1.0953 - val_loss: 2.3286 - val_mae: 1.1191\n",
            "Epoch 391/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1402 - mae: 1.0871 - val_loss: 2.5240 - val_mae: 1.1755\n",
            "Epoch 392/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1892 - mae: 1.0971 - val_loss: 2.3323 - val_mae: 1.1178\n",
            "Epoch 393/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1534 - mae: 1.0868 - val_loss: 2.4245 - val_mae: 1.1412\n",
            "Epoch 394/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1717 - mae: 1.0907 - val_loss: 2.3923 - val_mae: 1.1232\n",
            "Epoch 395/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1757 - mae: 1.0930 - val_loss: 2.4871 - val_mae: 1.1378\n",
            "Epoch 396/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1979 - mae: 1.1036 - val_loss: 2.3105 - val_mae: 1.1316\n",
            "Epoch 397/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2011 - mae: 1.0908 - val_loss: 2.3261 - val_mae: 1.1132\n",
            "Epoch 398/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2109 - mae: 1.1032 - val_loss: 2.3805 - val_mae: 1.1312\n",
            "Epoch 399/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1512 - mae: 1.0881 - val_loss: 2.3657 - val_mae: 1.1275\n",
            "Epoch 400/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1543 - mae: 1.0880 - val_loss: 2.5082 - val_mae: 1.1585\n",
            "Epoch 401/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1839 - mae: 1.0977 - val_loss: 2.3890 - val_mae: 1.1299\n",
            "Epoch 402/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1871 - mae: 1.0994 - val_loss: 2.2967 - val_mae: 1.1169\n",
            "Epoch 403/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1436 - mae: 1.0825 - val_loss: 2.3174 - val_mae: 1.1110\n",
            "Epoch 404/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2509 - mae: 1.1236 - val_loss: 2.3574 - val_mae: 1.1199\n",
            "Epoch 405/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2626 - mae: 1.1241 - val_loss: 2.3016 - val_mae: 1.1099\n",
            "Epoch 406/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1643 - mae: 1.0964 - val_loss: 2.3930 - val_mae: 1.1285\n",
            "Epoch 407/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1507 - mae: 1.0848 - val_loss: 2.3132 - val_mae: 1.1097\n",
            "Epoch 408/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1377 - mae: 1.0893 - val_loss: 2.4148 - val_mae: 1.1341\n",
            "Epoch 409/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1566 - mae: 1.0888 - val_loss: 2.2933 - val_mae: 1.1039\n",
            "Epoch 410/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1821 - mae: 1.0972 - val_loss: 2.3631 - val_mae: 1.1155\n",
            "Epoch 411/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1667 - mae: 1.0963 - val_loss: 2.4086 - val_mae: 1.1319\n",
            "Epoch 412/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1709 - mae: 1.0957 - val_loss: 2.3950 - val_mae: 1.1418\n",
            "Epoch 413/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1989 - mae: 1.1096 - val_loss: 2.3914 - val_mae: 1.1434\n",
            "Epoch 414/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1449 - mae: 1.0910 - val_loss: 2.2928 - val_mae: 1.1128\n",
            "Epoch 415/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1533 - mae: 1.0884 - val_loss: 2.3804 - val_mae: 1.1208\n",
            "Epoch 416/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1622 - mae: 1.0889 - val_loss: 2.3303 - val_mae: 1.1201\n",
            "Epoch 417/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1372 - mae: 1.0884 - val_loss: 2.2962 - val_mae: 1.1244\n",
            "Epoch 418/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1520 - mae: 1.0914 - val_loss: 2.3520 - val_mae: 1.1248\n",
            "Epoch 419/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1304 - mae: 1.0739 - val_loss: 2.3559 - val_mae: 1.1421\n",
            "Epoch 420/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1417 - mae: 1.0883 - val_loss: 2.4437 - val_mae: 1.1360\n",
            "Epoch 421/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1792 - mae: 1.0939 - val_loss: 2.4447 - val_mae: 1.1384\n",
            "Epoch 422/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1400 - mae: 1.0839 - val_loss: 2.3271 - val_mae: 1.1200\n",
            "Epoch 423/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1471 - mae: 1.0900 - val_loss: 2.3185 - val_mae: 1.1156\n",
            "Epoch 424/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1535 - mae: 1.0910 - val_loss: 2.3004 - val_mae: 1.1176\n",
            "Epoch 425/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1603 - mae: 1.0871 - val_loss: 2.2920 - val_mae: 1.1081\n",
            "Epoch 426/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1617 - mae: 1.0964 - val_loss: 2.4683 - val_mae: 1.1514\n",
            "Epoch 427/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1388 - mae: 1.0850 - val_loss: 2.3039 - val_mae: 1.1219\n",
            "Epoch 428/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1420 - mae: 1.0813 - val_loss: 2.3099 - val_mae: 1.1182\n",
            "Epoch 429/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1310 - mae: 1.0860 - val_loss: 2.3134 - val_mae: 1.1341\n",
            "Epoch 430/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1576 - mae: 1.0935 - val_loss: 2.4183 - val_mae: 1.1382\n",
            "Epoch 431/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1460 - mae: 1.0892 - val_loss: 2.3335 - val_mae: 1.1330\n",
            "Epoch 432/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1290 - mae: 1.0818 - val_loss: 2.4105 - val_mae: 1.1453\n",
            "Epoch 433/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1366 - mae: 1.0838 - val_loss: 2.3563 - val_mae: 1.1338\n",
            "Epoch 434/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1399 - mae: 1.0879 - val_loss: 2.3052 - val_mae: 1.1183\n",
            "Epoch 435/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1063 - mae: 1.0741 - val_loss: 2.4086 - val_mae: 1.1419\n",
            "Epoch 436/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1433 - mae: 1.0870 - val_loss: 2.5059 - val_mae: 1.1659\n",
            "Epoch 437/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1980 - mae: 1.1048 - val_loss: 2.3481 - val_mae: 1.1383\n",
            "Epoch 438/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1201 - mae: 1.0791 - val_loss: 2.3287 - val_mae: 1.1253\n",
            "Epoch 439/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1567 - mae: 1.0926 - val_loss: 2.3316 - val_mae: 1.1323\n",
            "Epoch 440/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2329 - mae: 1.1116 - val_loss: 2.2934 - val_mae: 1.1151\n",
            "Epoch 441/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1411 - mae: 1.0806 - val_loss: 2.3503 - val_mae: 1.1268\n",
            "Epoch 442/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1214 - mae: 1.0846 - val_loss: 2.2972 - val_mae: 1.1193\n",
            "Epoch 443/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1473 - mae: 1.0890 - val_loss: 2.3723 - val_mae: 1.1356\n",
            "Epoch 444/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1197 - mae: 1.0811 - val_loss: 2.3543 - val_mae: 1.1409\n",
            "Epoch 445/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1092 - mae: 1.0821 - val_loss: 2.3023 - val_mae: 1.1158\n",
            "Epoch 446/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1258 - mae: 1.0831 - val_loss: 2.4971 - val_mae: 1.1595\n",
            "Epoch 447/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1217 - mae: 1.0826 - val_loss: 2.3423 - val_mae: 1.1369\n",
            "Epoch 448/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1216 - mae: 1.0835 - val_loss: 2.3281 - val_mae: 1.1248\n",
            "Epoch 449/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1675 - mae: 1.0946 - val_loss: 2.3523 - val_mae: 1.1219\n",
            "Epoch 450/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1458 - mae: 1.0816 - val_loss: 2.2732 - val_mae: 1.1138\n",
            "Epoch 451/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1578 - mae: 1.0860 - val_loss: 2.3525 - val_mae: 1.1333\n",
            "Epoch 452/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1194 - mae: 1.0811 - val_loss: 2.3656 - val_mae: 1.1351\n",
            "Epoch 453/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1455 - mae: 1.0866 - val_loss: 2.3568 - val_mae: 1.1580\n",
            "Epoch 454/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1294 - mae: 1.0885 - val_loss: 2.4238 - val_mae: 1.1370\n",
            "Epoch 455/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1234 - mae: 1.0848 - val_loss: 2.3247 - val_mae: 1.1314\n",
            "Epoch 456/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1382 - mae: 1.0904 - val_loss: 2.4007 - val_mae: 1.1428\n",
            "Epoch 457/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1002 - mae: 1.0771 - val_loss: 2.3450 - val_mae: 1.1377\n",
            "Epoch 458/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1361 - mae: 1.0885 - val_loss: 2.3480 - val_mae: 1.1291\n",
            "Epoch 459/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1527 - mae: 1.0928 - val_loss: 2.3536 - val_mae: 1.1430\n",
            "Epoch 460/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1267 - mae: 1.0831 - val_loss: 2.3542 - val_mae: 1.1272\n",
            "Epoch 461/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1222 - mae: 1.0809 - val_loss: 2.3152 - val_mae: 1.1315\n",
            "Epoch 462/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1182 - mae: 1.0878 - val_loss: 2.3315 - val_mae: 1.1421\n",
            "Epoch 463/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1254 - mae: 1.0872 - val_loss: 2.3352 - val_mae: 1.1223\n",
            "Epoch 464/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1060 - mae: 1.0813 - val_loss: 2.3418 - val_mae: 1.1252\n",
            "Epoch 465/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1109 - mae: 1.0816 - val_loss: 2.3067 - val_mae: 1.1225\n",
            "Epoch 466/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0864 - mae: 1.0728 - val_loss: 2.3000 - val_mae: 1.1363\n",
            "Epoch 467/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1179 - mae: 1.0866 - val_loss: 2.3027 - val_mae: 1.1310\n",
            "Epoch 468/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1442 - mae: 1.0855 - val_loss: 2.3718 - val_mae: 1.1393\n",
            "Epoch 469/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1050 - mae: 1.0810 - val_loss: 2.2861 - val_mae: 1.1148\n",
            "Epoch 470/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1056 - mae: 1.0798 - val_loss: 2.3064 - val_mae: 1.1246\n",
            "Epoch 471/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1310 - mae: 1.0912 - val_loss: 2.4508 - val_mae: 1.1488\n",
            "Epoch 472/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1184 - mae: 1.0822 - val_loss: 2.3099 - val_mae: 1.1315\n",
            "Epoch 473/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1140 - mae: 1.0827 - val_loss: 2.3388 - val_mae: 1.1483\n",
            "Epoch 474/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1028 - mae: 1.0795 - val_loss: 2.5596 - val_mae: 1.2140\n",
            "Epoch 475/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1434 - mae: 1.0944 - val_loss: 2.3453 - val_mae: 1.1252\n",
            "Epoch 476/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1262 - mae: 1.0839 - val_loss: 2.3332 - val_mae: 1.1214\n",
            "Epoch 477/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1044 - mae: 1.0777 - val_loss: 2.3484 - val_mae: 1.1567\n",
            "Epoch 478/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0864 - mae: 1.0703 - val_loss: 2.3437 - val_mae: 1.1389\n",
            "Epoch 479/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0798 - mae: 1.0721 - val_loss: 2.4029 - val_mae: 1.1777\n",
            "Epoch 480/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.1564 - mae: 1.1036 - val_loss: 2.3476 - val_mae: 1.1284\n",
            "Epoch 481/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1125 - mae: 1.0802 - val_loss: 2.3226 - val_mae: 1.1214\n",
            "Epoch 482/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1028 - mae: 1.0752 - val_loss: 2.3699 - val_mae: 1.1469\n",
            "Epoch 483/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1137 - mae: 1.0810 - val_loss: 2.3602 - val_mae: 1.1350\n",
            "Epoch 484/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1472 - mae: 1.0914 - val_loss: 2.3699 - val_mae: 1.1535\n",
            "Epoch 485/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1172 - mae: 1.0846 - val_loss: 2.2976 - val_mae: 1.1389\n",
            "Epoch 486/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0859 - mae: 1.0771 - val_loss: 2.2976 - val_mae: 1.1278\n",
            "Epoch 487/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0961 - mae: 1.0821 - val_loss: 2.3478 - val_mae: 1.1317\n",
            "Epoch 488/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0687 - mae: 1.0685 - val_loss: 2.3432 - val_mae: 1.1333\n",
            "Epoch 489/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0968 - mae: 1.0759 - val_loss: 2.4234 - val_mae: 1.1715\n",
            "Epoch 490/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1340 - mae: 1.0871 - val_loss: 2.3154 - val_mae: 1.1277\n",
            "Epoch 491/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1918 - mae: 1.1086 - val_loss: 2.2795 - val_mae: 1.1323\n",
            "Epoch 492/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0826 - mae: 1.0803 - val_loss: 2.4169 - val_mae: 1.1512\n",
            "Epoch 493/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0844 - mae: 1.0706 - val_loss: 2.2914 - val_mae: 1.1210\n",
            "Epoch 494/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1070 - mae: 1.0817 - val_loss: 2.4459 - val_mae: 1.1515\n",
            "Epoch 495/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0795 - mae: 1.0740 - val_loss: 2.4029 - val_mae: 1.1473\n",
            "Epoch 496/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0823 - mae: 1.0707 - val_loss: 2.3077 - val_mae: 1.1389\n",
            "Epoch 497/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0997 - mae: 1.0797 - val_loss: 2.2838 - val_mae: 1.1222\n",
            "Epoch 498/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0584 - mae: 1.0666 - val_loss: 2.3001 - val_mae: 1.1354\n",
            "Epoch 499/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0962 - mae: 1.0752 - val_loss: 2.2867 - val_mae: 1.1202\n",
            "Epoch 500/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0844 - mae: 1.0739 - val_loss: 2.2895 - val_mae: 1.1196\n",
            "Epoch 501/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0879 - mae: 1.0797 - val_loss: 2.3007 - val_mae: 1.1248\n",
            "Epoch 502/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0791 - mae: 1.0766 - val_loss: 2.4251 - val_mae: 1.1457\n",
            "Epoch 503/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0882 - mae: 1.0748 - val_loss: 2.3951 - val_mae: 1.1449\n",
            "Epoch 504/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0518 - mae: 1.0631 - val_loss: 2.3062 - val_mae: 1.1193\n",
            "Epoch 505/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0494 - mae: 1.0657 - val_loss: 2.3618 - val_mae: 1.1356\n",
            "Epoch 506/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0866 - mae: 1.0702 - val_loss: 2.3006 - val_mae: 1.1225\n",
            "Epoch 507/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0622 - mae: 1.0658 - val_loss: 2.3591 - val_mae: 1.1432\n",
            "Epoch 508/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1107 - mae: 1.0828 - val_loss: 2.3847 - val_mae: 1.1365\n",
            "Epoch 509/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1116 - mae: 1.0911 - val_loss: 2.3036 - val_mae: 1.1213\n",
            "Epoch 510/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0617 - mae: 1.0702 - val_loss: 2.3249 - val_mae: 1.1333\n",
            "Epoch 511/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0789 - mae: 1.0717 - val_loss: 2.3055 - val_mae: 1.1298\n",
            "Epoch 512/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0641 - mae: 1.0659 - val_loss: 2.3379 - val_mae: 1.1502\n",
            "Epoch 513/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0633 - mae: 1.0716 - val_loss: 2.3285 - val_mae: 1.1257\n",
            "Epoch 514/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0794 - mae: 1.0750 - val_loss: 2.2633 - val_mae: 1.1199\n",
            "Epoch 515/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0858 - mae: 1.0720 - val_loss: 2.3153 - val_mae: 1.1292\n",
            "Epoch 516/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0975 - mae: 1.0759 - val_loss: 2.4018 - val_mae: 1.1583\n",
            "Epoch 517/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0694 - mae: 1.0702 - val_loss: 2.3009 - val_mae: 1.1394\n",
            "Epoch 518/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0640 - mae: 1.0706 - val_loss: 2.5067 - val_mae: 1.2051\n",
            "Epoch 519/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0859 - mae: 1.0760 - val_loss: 2.3482 - val_mae: 1.1626\n",
            "Epoch 520/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0479 - mae: 1.0628 - val_loss: 2.2993 - val_mae: 1.1348\n",
            "Epoch 521/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0657 - mae: 1.0691 - val_loss: 2.3284 - val_mae: 1.1407\n",
            "Epoch 522/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0722 - mae: 1.0687 - val_loss: 2.3315 - val_mae: 1.1362\n",
            "Epoch 523/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0823 - mae: 1.0761 - val_loss: 2.3524 - val_mae: 1.1480\n",
            "Epoch 524/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0827 - mae: 1.0702 - val_loss: 2.2564 - val_mae: 1.1280\n",
            "Epoch 525/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1084 - mae: 1.0787 - val_loss: 2.2725 - val_mae: 1.1232\n",
            "Epoch 526/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0669 - mae: 1.0708 - val_loss: 2.3205 - val_mae: 1.1485\n",
            "Epoch 527/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0622 - mae: 1.0676 - val_loss: 2.2876 - val_mae: 1.1259\n",
            "Epoch 528/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0632 - mae: 1.0680 - val_loss: 2.3747 - val_mae: 1.1421\n",
            "Epoch 529/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0741 - mae: 1.0757 - val_loss: 2.3319 - val_mae: 1.1460\n",
            "Epoch 530/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0839 - mae: 1.0847 - val_loss: 2.4179 - val_mae: 1.1864\n",
            "Epoch 531/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1160 - mae: 1.0867 - val_loss: 2.3384 - val_mae: 1.1351\n",
            "Epoch 532/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0837 - mae: 1.0739 - val_loss: 2.3084 - val_mae: 1.1216\n",
            "Epoch 533/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0716 - mae: 1.0785 - val_loss: 2.2894 - val_mae: 1.1336\n",
            "Epoch 534/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0845 - mae: 1.0771 - val_loss: 2.3298 - val_mae: 1.1500\n",
            "Epoch 535/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0666 - mae: 1.0721 - val_loss: 2.3362 - val_mae: 1.1550\n",
            "Epoch 536/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0668 - mae: 1.0688 - val_loss: 2.3162 - val_mae: 1.1413\n",
            "Epoch 537/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0458 - mae: 1.0632 - val_loss: 2.3136 - val_mae: 1.1438\n",
            "Epoch 538/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0724 - mae: 1.0718 - val_loss: 2.3349 - val_mae: 1.1302\n",
            "Epoch 539/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0573 - mae: 1.0696 - val_loss: 2.3006 - val_mae: 1.1257\n",
            "Epoch 540/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0264 - mae: 1.0584 - val_loss: 2.2739 - val_mae: 1.1248\n",
            "Epoch 541/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0727 - mae: 1.0703 - val_loss: 2.4561 - val_mae: 1.1991\n",
            "Epoch 542/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0521 - mae: 1.0684 - val_loss: 2.2986 - val_mae: 1.1261\n",
            "Epoch 543/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0409 - mae: 1.0668 - val_loss: 2.2991 - val_mae: 1.1283\n",
            "Epoch 544/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0704 - mae: 1.0762 - val_loss: 2.2918 - val_mae: 1.1374\n",
            "Epoch 545/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0705 - mae: 1.0730 - val_loss: 2.3491 - val_mae: 1.1344\n",
            "Epoch 546/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0541 - mae: 1.0660 - val_loss: 2.2871 - val_mae: 1.1309\n",
            "Epoch 547/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0700 - mae: 1.0707 - val_loss: 2.3004 - val_mae: 1.1301\n",
            "Epoch 548/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1010 - mae: 1.0884 - val_loss: 2.2680 - val_mae: 1.1282\n",
            "Epoch 549/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0649 - mae: 1.0696 - val_loss: 2.3002 - val_mae: 1.1288\n",
            "Epoch 550/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0546 - mae: 1.0706 - val_loss: 2.3583 - val_mae: 1.1457\n",
            "Epoch 551/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0443 - mae: 1.0695 - val_loss: 2.2974 - val_mae: 1.1321\n",
            "Epoch 552/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0557 - mae: 1.0660 - val_loss: 2.3972 - val_mae: 1.1505\n",
            "Epoch 553/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0881 - mae: 1.0777 - val_loss: 2.2751 - val_mae: 1.1281\n",
            "Epoch 554/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0604 - mae: 1.0708 - val_loss: 2.3613 - val_mae: 1.1712\n",
            "Epoch 555/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0364 - mae: 1.0638 - val_loss: 2.2859 - val_mae: 1.1284\n",
            "Epoch 556/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0537 - mae: 1.0697 - val_loss: 2.3215 - val_mae: 1.1564\n",
            "Epoch 557/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0562 - mae: 1.0708 - val_loss: 2.2905 - val_mae: 1.1251\n",
            "Epoch 558/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0744 - mae: 1.0764 - val_loss: 2.4460 - val_mae: 1.1584\n",
            "Epoch 559/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0608 - mae: 1.0661 - val_loss: 2.3081 - val_mae: 1.1263\n",
            "Epoch 560/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0321 - mae: 1.0582 - val_loss: 2.3682 - val_mae: 1.1424\n",
            "Epoch 561/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0806 - mae: 1.0768 - val_loss: 2.2569 - val_mae: 1.1336\n",
            "Epoch 562/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0566 - mae: 1.0701 - val_loss: 2.3092 - val_mae: 1.1390\n",
            "Epoch 563/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0356 - mae: 1.0636 - val_loss: 2.2989 - val_mae: 1.1297\n",
            "Epoch 564/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0480 - mae: 1.0667 - val_loss: 2.2923 - val_mae: 1.1249\n",
            "Epoch 565/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0754 - mae: 1.0749 - val_loss: 2.3967 - val_mae: 1.1475\n",
            "Epoch 566/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0634 - mae: 1.0770 - val_loss: 2.3560 - val_mae: 1.1386\n",
            "Epoch 567/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0433 - mae: 1.0595 - val_loss: 2.3029 - val_mae: 1.1305\n",
            "Epoch 568/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0348 - mae: 1.0665 - val_loss: 2.3780 - val_mae: 1.1471\n",
            "Epoch 569/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0597 - mae: 1.0667 - val_loss: 2.3348 - val_mae: 1.1355\n",
            "Epoch 570/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0918 - mae: 1.0752 - val_loss: 2.3750 - val_mae: 1.1708\n",
            "Epoch 571/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0527 - mae: 1.0707 - val_loss: 2.4132 - val_mae: 1.1595\n",
            "Epoch 572/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0522 - mae: 1.0672 - val_loss: 2.2926 - val_mae: 1.1313\n",
            "Epoch 573/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0380 - mae: 1.0679 - val_loss: 2.4423 - val_mae: 1.1615\n",
            "Epoch 574/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0430 - mae: 1.0653 - val_loss: 2.3103 - val_mae: 1.1280\n",
            "Epoch 575/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0252 - mae: 1.0604 - val_loss: 2.3082 - val_mae: 1.1349\n",
            "Epoch 576/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0712 - mae: 1.0758 - val_loss: 2.3158 - val_mae: 1.1297\n",
            "Epoch 577/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0209 - mae: 1.0604 - val_loss: 2.2634 - val_mae: 1.1242\n",
            "Epoch 578/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0256 - mae: 1.0585 - val_loss: 2.2923 - val_mae: 1.1340\n",
            "Epoch 579/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0330 - mae: 1.0629 - val_loss: 2.2659 - val_mae: 1.1295\n",
            "Epoch 580/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0128 - mae: 1.0583 - val_loss: 2.3278 - val_mae: 1.1326\n",
            "Epoch 581/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0275 - mae: 1.0619 - val_loss: 2.3428 - val_mae: 1.1384\n",
            "Epoch 582/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0444 - mae: 1.0679 - val_loss: 2.2880 - val_mae: 1.1270\n",
            "Epoch 583/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0416 - mae: 1.0658 - val_loss: 2.2556 - val_mae: 1.1329\n",
            "Epoch 584/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0237 - mae: 1.0636 - val_loss: 2.3310 - val_mae: 1.1594\n",
            "Epoch 585/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0166 - mae: 1.0634 - val_loss: 2.2948 - val_mae: 1.1302\n",
            "Epoch 586/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0200 - mae: 1.0583 - val_loss: 2.2675 - val_mae: 1.1284\n",
            "Epoch 587/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0333 - mae: 1.0640 - val_loss: 2.3824 - val_mae: 1.1534\n",
            "Epoch 588/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0526 - mae: 1.0710 - val_loss: 2.3347 - val_mae: 1.1634\n",
            "Epoch 589/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0867 - mae: 1.0773 - val_loss: 2.2676 - val_mae: 1.1404\n",
            "Epoch 590/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0316 - mae: 1.0607 - val_loss: 2.3337 - val_mae: 1.1337\n",
            "Epoch 591/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0179 - mae: 1.0576 - val_loss: 2.3100 - val_mae: 1.1313\n",
            "Epoch 592/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0253 - mae: 1.0573 - val_loss: 2.3103 - val_mae: 1.1410\n",
            "Epoch 593/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0257 - mae: 1.0616 - val_loss: 2.2468 - val_mae: 1.1252\n",
            "Epoch 594/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0603 - mae: 1.0693 - val_loss: 2.3340 - val_mae: 1.1348\n",
            "Epoch 595/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0681 - mae: 1.0758 - val_loss: 2.3385 - val_mae: 1.1518\n",
            "Epoch 596/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0289 - mae: 1.0595 - val_loss: 2.2809 - val_mae: 1.1306\n",
            "Epoch 597/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0213 - mae: 1.0617 - val_loss: 2.3093 - val_mae: 1.1325\n",
            "Epoch 598/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0636 - mae: 1.0720 - val_loss: 2.2788 - val_mae: 1.1288\n",
            "Epoch 599/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0194 - mae: 1.0585 - val_loss: 2.2971 - val_mae: 1.1309\n",
            "Epoch 600/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0173 - mae: 1.0616 - val_loss: 2.2551 - val_mae: 1.1309\n",
            "Epoch 601/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0306 - mae: 1.0635 - val_loss: 2.2979 - val_mae: 1.1250\n",
            "Epoch 602/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0437 - mae: 1.0709 - val_loss: 2.3524 - val_mae: 1.1428\n",
            "Epoch 603/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0056 - mae: 1.0589 - val_loss: 2.2944 - val_mae: 1.1288\n",
            "Epoch 604/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0605 - mae: 1.0700 - val_loss: 2.2639 - val_mae: 1.1237\n",
            "Epoch 605/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0227 - mae: 1.0620 - val_loss: 2.3642 - val_mae: 1.1700\n",
            "Epoch 606/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1422 - mae: 1.0993 - val_loss: 2.5003 - val_mae: 1.1799\n",
            "Epoch 607/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0450 - mae: 1.0704 - val_loss: 2.3332 - val_mae: 1.1360\n",
            "Epoch 608/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0245 - mae: 1.0604 - val_loss: 2.2635 - val_mae: 1.1349\n",
            "Epoch 609/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0022 - mae: 1.0563 - val_loss: 2.3472 - val_mae: 1.1560\n",
            "Epoch 610/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0290 - mae: 1.0603 - val_loss: 2.3535 - val_mae: 1.1622\n",
            "Epoch 611/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0483 - mae: 1.0701 - val_loss: 2.2804 - val_mae: 1.1270\n",
            "Epoch 612/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0931 - mae: 1.0773 - val_loss: 2.4181 - val_mae: 1.1600\n",
            "Epoch 613/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9855 - mae: 1.0493 - val_loss: 2.3127 - val_mae: 1.1468\n",
            "Epoch 614/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0135 - mae: 1.0543 - val_loss: 2.2571 - val_mae: 1.1241\n",
            "Epoch 615/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0188 - mae: 1.0629 - val_loss: 2.4138 - val_mae: 1.1808\n",
            "Epoch 616/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0166 - mae: 1.0569 - val_loss: 2.2932 - val_mae: 1.1403\n",
            "Epoch 617/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0072 - mae: 1.0585 - val_loss: 2.3779 - val_mae: 1.1436\n",
            "Epoch 618/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0462 - mae: 1.0691 - val_loss: 2.3534 - val_mae: 1.1544\n",
            "Epoch 619/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0458 - mae: 1.0674 - val_loss: 2.4773 - val_mae: 1.2145\n",
            "Epoch 620/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0340 - mae: 1.0747 - val_loss: 2.2704 - val_mae: 1.1301\n",
            "Epoch 621/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0488 - mae: 1.0689 - val_loss: 2.2930 - val_mae: 1.1250\n",
            "Epoch 622/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0132 - mae: 1.0586 - val_loss: 2.2908 - val_mae: 1.1317\n",
            "Epoch 623/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0176 - mae: 1.0625 - val_loss: 2.2932 - val_mae: 1.1296\n",
            "Epoch 624/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0016 - mae: 1.0535 - val_loss: 2.3299 - val_mae: 1.1592\n",
            "Epoch 625/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0328 - mae: 1.0662 - val_loss: 2.3325 - val_mae: 1.1597\n",
            "Epoch 626/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9944 - mae: 1.0502 - val_loss: 2.3567 - val_mae: 1.1752\n",
            "Epoch 627/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0539 - mae: 1.0735 - val_loss: 2.2884 - val_mae: 1.1445\n",
            "Epoch 628/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0201 - mae: 1.0612 - val_loss: 2.2707 - val_mae: 1.1287\n",
            "Epoch 629/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0095 - mae: 1.0600 - val_loss: 2.3278 - val_mae: 1.1362\n",
            "Epoch 630/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0617 - mae: 1.0751 - val_loss: 2.3506 - val_mae: 1.1682\n",
            "Epoch 631/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9990 - mae: 1.0474 - val_loss: 2.3428 - val_mae: 1.1467\n",
            "Epoch 632/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0014 - mae: 1.0543 - val_loss: 2.3109 - val_mae: 1.1472\n",
            "Epoch 633/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0079 - mae: 1.0576 - val_loss: 2.3591 - val_mae: 1.1428\n",
            "Epoch 634/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0430 - mae: 1.0627 - val_loss: 2.3229 - val_mae: 1.1535\n",
            "Epoch 635/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0006 - mae: 1.0522 - val_loss: 2.2615 - val_mae: 1.1201\n",
            "Epoch 636/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9868 - mae: 1.0481 - val_loss: 2.2930 - val_mae: 1.1251\n",
            "Epoch 637/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0089 - mae: 1.0573 - val_loss: 2.2709 - val_mae: 1.1309\n",
            "Epoch 638/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0159 - mae: 1.0577 - val_loss: 2.3143 - val_mae: 1.1369\n",
            "Epoch 639/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9927 - mae: 1.0501 - val_loss: 2.3986 - val_mae: 1.1576\n",
            "Epoch 640/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0284 - mae: 1.0635 - val_loss: 2.3621 - val_mae: 1.1428\n",
            "Epoch 641/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9996 - mae: 1.0553 - val_loss: 2.2870 - val_mae: 1.1245\n",
            "Epoch 642/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9939 - mae: 1.0507 - val_loss: 2.3464 - val_mae: 1.1505\n",
            "Epoch 643/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0205 - mae: 1.0610 - val_loss: 2.2735 - val_mae: 1.1408\n",
            "Epoch 644/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0240 - mae: 1.0623 - val_loss: 2.3255 - val_mae: 1.1654\n",
            "Epoch 645/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0139 - mae: 1.0574 - val_loss: 2.2391 - val_mae: 1.1236\n",
            "Epoch 646/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0113 - mae: 1.0567 - val_loss: 2.2719 - val_mae: 1.1305\n",
            "Epoch 647/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0183 - mae: 1.0561 - val_loss: 2.2833 - val_mae: 1.1248\n",
            "Epoch 648/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9998 - mae: 1.0525 - val_loss: 2.2841 - val_mae: 1.1277\n",
            "Epoch 649/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9987 - mae: 1.0530 - val_loss: 2.3323 - val_mae: 1.1411\n",
            "Epoch 650/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9955 - mae: 1.0525 - val_loss: 2.2694 - val_mae: 1.1342\n",
            "Epoch 651/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0222 - mae: 1.0609 - val_loss: 2.4492 - val_mae: 1.1592\n",
            "Epoch 652/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0637 - mae: 1.0791 - val_loss: 2.3051 - val_mae: 1.1425\n",
            "Epoch 653/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9993 - mae: 1.0521 - val_loss: 2.2817 - val_mae: 1.1285\n",
            "Epoch 654/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0104 - mae: 1.0593 - val_loss: 2.4230 - val_mae: 1.1993\n",
            "Epoch 655/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0254 - mae: 1.0607 - val_loss: 2.2899 - val_mae: 1.1336\n",
            "Epoch 656/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9798 - mae: 1.0471 - val_loss: 2.3082 - val_mae: 1.1487\n",
            "Epoch 657/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0080 - mae: 1.0511 - val_loss: 2.3533 - val_mae: 1.1391\n",
            "Epoch 658/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9792 - mae: 1.0456 - val_loss: 2.2878 - val_mae: 1.1547\n",
            "Epoch 659/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9815 - mae: 1.0467 - val_loss: 2.2591 - val_mae: 1.1374\n",
            "Epoch 660/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0014 - mae: 1.0575 - val_loss: 2.3183 - val_mae: 1.1350\n",
            "Epoch 661/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9878 - mae: 1.0543 - val_loss: 2.3068 - val_mae: 1.1577\n",
            "Epoch 662/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9952 - mae: 1.0536 - val_loss: 2.2585 - val_mae: 1.1343\n",
            "Epoch 663/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0002 - mae: 1.0562 - val_loss: 2.2692 - val_mae: 1.1282\n",
            "Epoch 664/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0043 - mae: 1.0537 - val_loss: 2.2326 - val_mae: 1.1245\n",
            "Epoch 665/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0421 - mae: 1.0640 - val_loss: 2.2818 - val_mae: 1.1324\n",
            "Epoch 666/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9960 - mae: 1.0574 - val_loss: 2.2881 - val_mae: 1.1448\n",
            "Epoch 667/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0132 - mae: 1.0589 - val_loss: 2.2880 - val_mae: 1.1441\n",
            "Epoch 668/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0065 - mae: 1.0548 - val_loss: 2.3516 - val_mae: 1.1514\n",
            "Epoch 669/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0034 - mae: 1.0559 - val_loss: 2.2671 - val_mae: 1.1320\n",
            "Epoch 670/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0108 - mae: 1.0595 - val_loss: 2.2800 - val_mae: 1.1332\n",
            "Epoch 671/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9897 - mae: 1.0510 - val_loss: 2.3113 - val_mae: 1.1383\n",
            "Epoch 672/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9885 - mae: 1.0519 - val_loss: 2.2760 - val_mae: 1.1298\n",
            "Epoch 673/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0000 - mae: 1.0560 - val_loss: 2.2813 - val_mae: 1.1240\n",
            "Epoch 674/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9872 - mae: 1.0578 - val_loss: 2.2437 - val_mae: 1.1292\n",
            "Epoch 675/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0174 - mae: 1.0597 - val_loss: 2.3063 - val_mae: 1.1359\n",
            "Epoch 676/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9806 - mae: 1.0491 - val_loss: 2.2472 - val_mae: 1.1234\n",
            "Epoch 677/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9814 - mae: 1.0491 - val_loss: 2.3765 - val_mae: 1.1767\n",
            "Epoch 678/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9837 - mae: 1.0501 - val_loss: 2.2875 - val_mae: 1.1479\n",
            "Epoch 679/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9823 - mae: 1.0512 - val_loss: 2.3405 - val_mae: 1.1408\n",
            "Epoch 680/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0029 - mae: 1.0560 - val_loss: 2.2805 - val_mae: 1.1435\n",
            "Epoch 681/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9796 - mae: 1.0476 - val_loss: 2.3245 - val_mae: 1.1474\n",
            "Epoch 682/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0241 - mae: 1.0676 - val_loss: 2.2679 - val_mae: 1.1406\n",
            "Epoch 683/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0145 - mae: 1.0598 - val_loss: 2.2739 - val_mae: 1.1473\n",
            "Epoch 684/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9803 - mae: 1.0519 - val_loss: 2.2541 - val_mae: 1.1274\n",
            "Epoch 685/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0004 - mae: 1.0521 - val_loss: 2.2887 - val_mae: 1.1298\n",
            "Epoch 686/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9609 - mae: 1.0404 - val_loss: 2.3106 - val_mae: 1.1407\n",
            "Epoch 687/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0179 - mae: 1.0572 - val_loss: 2.3219 - val_mae: 1.1579\n",
            "Epoch 688/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9903 - mae: 1.0561 - val_loss: 2.3987 - val_mae: 1.1514\n",
            "Epoch 689/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0243 - mae: 1.0672 - val_loss: 2.2710 - val_mae: 1.1339\n",
            "Epoch 690/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9718 - mae: 1.0467 - val_loss: 2.2822 - val_mae: 1.1453\n",
            "Epoch 691/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9687 - mae: 1.0415 - val_loss: 2.3544 - val_mae: 1.1429\n",
            "Epoch 692/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9954 - mae: 1.0544 - val_loss: 2.2773 - val_mae: 1.1527\n",
            "Epoch 693/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0064 - mae: 1.0605 - val_loss: 2.3464 - val_mae: 1.1435\n",
            "Epoch 694/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9788 - mae: 1.0500 - val_loss: 2.2865 - val_mae: 1.1424\n",
            "Epoch 695/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.0000 - mae: 1.0561 - val_loss: 2.3822 - val_mae: 1.1509\n",
            "Epoch 696/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9941 - mae: 1.0513 - val_loss: 2.3152 - val_mae: 1.1473\n",
            "Epoch 697/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9914 - mae: 1.0544 - val_loss: 2.2755 - val_mae: 1.1386\n",
            "Epoch 698/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9648 - mae: 1.0445 - val_loss: 2.3151 - val_mae: 1.1410\n",
            "Epoch 699/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9712 - mae: 1.0516 - val_loss: 2.2789 - val_mae: 1.1346\n",
            "Epoch 700/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9789 - mae: 1.0504 - val_loss: 2.3169 - val_mae: 1.1327\n",
            "Epoch 701/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9869 - mae: 1.0492 - val_loss: 2.2789 - val_mae: 1.1400\n",
            "Epoch 702/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9923 - mae: 1.0529 - val_loss: 2.2593 - val_mae: 1.1283\n",
            "Epoch 703/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9586 - mae: 1.0453 - val_loss: 2.2578 - val_mae: 1.1278\n",
            "Epoch 704/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0280 - mae: 1.0637 - val_loss: 2.3957 - val_mae: 1.1572\n",
            "Epoch 705/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9555 - mae: 1.0412 - val_loss: 2.3199 - val_mae: 1.1535\n",
            "Epoch 706/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9752 - mae: 1.0458 - val_loss: 2.2571 - val_mae: 1.1317\n",
            "Epoch 707/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9671 - mae: 1.0468 - val_loss: 2.3254 - val_mae: 1.1538\n",
            "Epoch 708/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0123 - mae: 1.0603 - val_loss: 2.2665 - val_mae: 1.1425\n",
            "Epoch 709/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9628 - mae: 1.0420 - val_loss: 2.3561 - val_mae: 1.1611\n",
            "Epoch 710/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9670 - mae: 1.0489 - val_loss: 2.3078 - val_mae: 1.1386\n",
            "Epoch 711/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9747 - mae: 1.0454 - val_loss: 2.2988 - val_mae: 1.1566\n",
            "Epoch 712/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0011 - mae: 1.0581 - val_loss: 2.2781 - val_mae: 1.1378\n",
            "Epoch 713/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9594 - mae: 1.0414 - val_loss: 2.2863 - val_mae: 1.1291\n",
            "Epoch 714/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9728 - mae: 1.0497 - val_loss: 2.2990 - val_mae: 1.1317\n",
            "Epoch 715/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9552 - mae: 1.0402 - val_loss: 2.2845 - val_mae: 1.1472\n",
            "Epoch 716/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9881 - mae: 1.0532 - val_loss: 2.2821 - val_mae: 1.1366\n",
            "Epoch 717/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9553 - mae: 1.0411 - val_loss: 2.2834 - val_mae: 1.1531\n",
            "Epoch 718/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9515 - mae: 1.0433 - val_loss: 2.3066 - val_mae: 1.1514\n",
            "Epoch 719/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9893 - mae: 1.0492 - val_loss: 2.2954 - val_mae: 1.1307\n",
            "Epoch 720/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9591 - mae: 1.0424 - val_loss: 2.2891 - val_mae: 1.1532\n",
            "Epoch 721/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9621 - mae: 1.0436 - val_loss: 2.2847 - val_mae: 1.1297\n",
            "Epoch 722/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9663 - mae: 1.0458 - val_loss: 2.3717 - val_mae: 1.1493\n",
            "Epoch 723/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9520 - mae: 1.0444 - val_loss: 2.3247 - val_mae: 1.1360\n",
            "Epoch 724/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9440 - mae: 1.0389 - val_loss: 2.2613 - val_mae: 1.1437\n",
            "Epoch 725/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9873 - mae: 1.0497 - val_loss: 2.3966 - val_mae: 1.1509\n",
            "Epoch 726/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9963 - mae: 1.0552 - val_loss: 2.2479 - val_mae: 1.1256\n",
            "Epoch 727/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9421 - mae: 1.0328 - val_loss: 2.2465 - val_mae: 1.1247\n",
            "Epoch 728/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9396 - mae: 1.0356 - val_loss: 2.2592 - val_mae: 1.1253\n",
            "Epoch 729/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9332 - mae: 1.0385 - val_loss: 2.3228 - val_mae: 1.1401\n",
            "Epoch 730/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9455 - mae: 1.0359 - val_loss: 2.2942 - val_mae: 1.1264\n",
            "Epoch 731/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9281 - mae: 1.0382 - val_loss: 2.2420 - val_mae: 1.1373\n",
            "Epoch 732/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9388 - mae: 1.0356 - val_loss: 2.3317 - val_mae: 1.1756\n",
            "Epoch 733/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9463 - mae: 1.0396 - val_loss: 2.2677 - val_mae: 1.1525\n",
            "Epoch 734/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9581 - mae: 1.0419 - val_loss: 2.2504 - val_mae: 1.1351\n",
            "Epoch 735/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9497 - mae: 1.0398 - val_loss: 2.3337 - val_mae: 1.1410\n",
            "Epoch 736/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9305 - mae: 1.0365 - val_loss: 2.2687 - val_mae: 1.1282\n",
            "Epoch 737/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9370 - mae: 1.0374 - val_loss: 2.3161 - val_mae: 1.1343\n",
            "Epoch 738/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9308 - mae: 1.0371 - val_loss: 2.2803 - val_mae: 1.1328\n",
            "Epoch 739/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9451 - mae: 1.0387 - val_loss: 2.2875 - val_mae: 1.1466\n",
            "Epoch 740/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9510 - mae: 1.0431 - val_loss: 2.3181 - val_mae: 1.1419\n",
            "Epoch 741/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9403 - mae: 1.0364 - val_loss: 2.4415 - val_mae: 1.1738\n",
            "Epoch 742/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9456 - mae: 1.0417 - val_loss: 2.2710 - val_mae: 1.1375\n",
            "Epoch 743/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9217 - mae: 1.0371 - val_loss: 2.2942 - val_mae: 1.1672\n",
            "Epoch 744/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9237 - mae: 1.0311 - val_loss: 2.2370 - val_mae: 1.1240\n",
            "Epoch 745/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9356 - mae: 1.0377 - val_loss: 2.2401 - val_mae: 1.1367\n",
            "Epoch 746/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9213 - mae: 1.0353 - val_loss: 2.2622 - val_mae: 1.1325\n",
            "Epoch 747/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9283 - mae: 1.0338 - val_loss: 2.2178 - val_mae: 1.1259\n",
            "Epoch 748/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9341 - mae: 1.0387 - val_loss: 2.3252 - val_mae: 1.1468\n",
            "Epoch 749/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9383 - mae: 1.0397 - val_loss: 2.2299 - val_mae: 1.1214\n",
            "Epoch 750/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9507 - mae: 1.0405 - val_loss: 2.2334 - val_mae: 1.1387\n",
            "Epoch 751/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9287 - mae: 1.0356 - val_loss: 2.2234 - val_mae: 1.1238\n",
            "Epoch 752/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9172 - mae: 1.0299 - val_loss: 2.2526 - val_mae: 1.1417\n",
            "Epoch 753/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9196 - mae: 1.0332 - val_loss: 2.2997 - val_mae: 1.1520\n",
            "Epoch 754/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9341 - mae: 1.0381 - val_loss: 2.3574 - val_mae: 1.1867\n",
            "Epoch 755/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9269 - mae: 1.0336 - val_loss: 2.3377 - val_mae: 1.1461\n",
            "Epoch 756/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9234 - mae: 1.0400 - val_loss: 2.2416 - val_mae: 1.1244\n",
            "Epoch 757/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9064 - mae: 1.0269 - val_loss: 2.2637 - val_mae: 1.1508\n",
            "Epoch 758/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9124 - mae: 1.0325 - val_loss: 2.2216 - val_mae: 1.1200\n",
            "Epoch 759/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8939 - mae: 1.0222 - val_loss: 2.3398 - val_mae: 1.1410\n",
            "Epoch 760/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8990 - mae: 1.0296 - val_loss: 2.2370 - val_mae: 1.1249\n",
            "Epoch 761/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8974 - mae: 1.0244 - val_loss: 2.2794 - val_mae: 1.1258\n",
            "Epoch 762/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9078 - mae: 1.0278 - val_loss: 2.2838 - val_mae: 1.1282\n",
            "Epoch 763/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9112 - mae: 1.0313 - val_loss: 2.2937 - val_mae: 1.1528\n",
            "Epoch 764/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9032 - mae: 1.0274 - val_loss: 2.2556 - val_mae: 1.1413\n",
            "Epoch 765/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9092 - mae: 1.0318 - val_loss: 2.2712 - val_mae: 1.1412\n",
            "Epoch 766/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8991 - mae: 1.0285 - val_loss: 2.2105 - val_mae: 1.1227\n",
            "Epoch 767/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9318 - mae: 1.0426 - val_loss: 2.5029 - val_mae: 1.1735\n",
            "Epoch 768/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8959 - mae: 1.0294 - val_loss: 2.2395 - val_mae: 1.1277\n",
            "Epoch 769/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8900 - mae: 1.0240 - val_loss: 2.2155 - val_mae: 1.1309\n",
            "Epoch 770/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9000 - mae: 1.0249 - val_loss: 2.2762 - val_mae: 1.1557\n",
            "Epoch 771/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8994 - mae: 1.0285 - val_loss: 2.2715 - val_mae: 1.1274\n",
            "Epoch 772/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9098 - mae: 1.0288 - val_loss: 2.2918 - val_mae: 1.1466\n",
            "Epoch 773/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9106 - mae: 1.0325 - val_loss: 2.2317 - val_mae: 1.1370\n",
            "Epoch 774/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8894 - mae: 1.0261 - val_loss: 2.2036 - val_mae: 1.1153\n",
            "Epoch 775/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8984 - mae: 1.0243 - val_loss: 2.2593 - val_mae: 1.1281\n",
            "Epoch 776/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8965 - mae: 1.0285 - val_loss: 2.2936 - val_mae: 1.1232\n",
            "Epoch 777/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9148 - mae: 1.0338 - val_loss: 2.2409 - val_mae: 1.1252\n",
            "Epoch 778/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8779 - mae: 1.0216 - val_loss: 2.2529 - val_mae: 1.1265\n",
            "Epoch 779/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8968 - mae: 1.0300 - val_loss: 2.2723 - val_mae: 1.1236\n",
            "Epoch 780/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8644 - mae: 1.0139 - val_loss: 2.2404 - val_mae: 1.1243\n",
            "Epoch 781/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8844 - mae: 1.0247 - val_loss: 2.2592 - val_mae: 1.1213\n",
            "Epoch 782/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9213 - mae: 1.0394 - val_loss: 2.1944 - val_mae: 1.1162\n",
            "Epoch 783/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8844 - mae: 1.0237 - val_loss: 2.2847 - val_mae: 1.1552\n",
            "Epoch 784/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8828 - mae: 1.0206 - val_loss: 2.2621 - val_mae: 1.1528\n",
            "Epoch 785/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8738 - mae: 1.0188 - val_loss: 2.2008 - val_mae: 1.1197\n",
            "Epoch 786/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8799 - mae: 1.0206 - val_loss: 2.1890 - val_mae: 1.1185\n",
            "Epoch 787/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8884 - mae: 1.0180 - val_loss: 2.2524 - val_mae: 1.1223\n",
            "Epoch 788/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9240 - mae: 1.0388 - val_loss: 2.2334 - val_mae: 1.1278\n",
            "Epoch 789/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8825 - mae: 1.0257 - val_loss: 2.2375 - val_mae: 1.1170\n",
            "Epoch 790/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8679 - mae: 1.0135 - val_loss: 2.2721 - val_mae: 1.1546\n",
            "Epoch 791/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8874 - mae: 1.0224 - val_loss: 2.2962 - val_mae: 1.1575\n",
            "Epoch 792/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8580 - mae: 1.0189 - val_loss: 2.2526 - val_mae: 1.1226\n",
            "Epoch 793/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8710 - mae: 1.0127 - val_loss: 2.2418 - val_mae: 1.1193\n",
            "Epoch 794/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8868 - mae: 1.0256 - val_loss: 2.2060 - val_mae: 1.1180\n",
            "Epoch 795/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8771 - mae: 1.0164 - val_loss: 2.2382 - val_mae: 1.1337\n",
            "Epoch 796/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8703 - mae: 1.0156 - val_loss: 2.2635 - val_mae: 1.1273\n",
            "Epoch 797/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8755 - mae: 1.0205 - val_loss: 2.2120 - val_mae: 1.1175\n",
            "Epoch 798/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8845 - mae: 1.0268 - val_loss: 2.2540 - val_mae: 1.1238\n",
            "Epoch 799/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8625 - mae: 1.0165 - val_loss: 2.3020 - val_mae: 1.1339\n",
            "Epoch 800/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8870 - mae: 1.0253 - val_loss: 2.2019 - val_mae: 1.1156\n",
            "Epoch 801/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.9025 - mae: 1.0303 - val_loss: 2.2031 - val_mae: 1.1202\n",
            "Epoch 802/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8754 - mae: 1.0161 - val_loss: 2.2732 - val_mae: 1.1301\n",
            "Epoch 803/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8659 - mae: 1.0178 - val_loss: 2.2585 - val_mae: 1.1296\n",
            "Epoch 804/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8526 - mae: 1.0095 - val_loss: 2.2798 - val_mae: 1.1233\n",
            "Epoch 805/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8752 - mae: 1.0194 - val_loss: 2.2350 - val_mae: 1.1241\n",
            "Epoch 806/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8694 - mae: 1.0196 - val_loss: 2.2088 - val_mae: 1.1137\n",
            "Epoch 807/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8559 - mae: 1.0131 - val_loss: 2.2108 - val_mae: 1.1122\n",
            "Epoch 808/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8697 - mae: 1.0164 - val_loss: 2.2082 - val_mae: 1.1252\n",
            "Epoch 809/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8655 - mae: 1.0146 - val_loss: 2.1903 - val_mae: 1.1201\n",
            "Epoch 810/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8590 - mae: 1.0118 - val_loss: 2.2868 - val_mae: 1.1430\n",
            "Epoch 811/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8678 - mae: 1.0177 - val_loss: 2.2891 - val_mae: 1.1627\n",
            "Epoch 812/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8588 - mae: 1.0189 - val_loss: 2.2427 - val_mae: 1.1387\n",
            "Epoch 813/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8583 - mae: 1.0133 - val_loss: 2.2936 - val_mae: 1.1634\n",
            "Epoch 814/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8317 - mae: 1.0045 - val_loss: 2.2026 - val_mae: 1.1143\n",
            "Epoch 815/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8606 - mae: 1.0175 - val_loss: 2.2293 - val_mae: 1.1253\n",
            "Epoch 816/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8524 - mae: 1.0166 - val_loss: 2.2109 - val_mae: 1.1167\n",
            "Epoch 817/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8352 - mae: 1.0094 - val_loss: 2.2199 - val_mae: 1.1145\n",
            "Epoch 818/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8289 - mae: 1.0055 - val_loss: 2.2337 - val_mae: 1.1201\n",
            "Epoch 819/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8332 - mae: 1.0104 - val_loss: 2.1764 - val_mae: 1.1104\n",
            "Epoch 820/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8229 - mae: 1.0044 - val_loss: 2.2203 - val_mae: 1.1270\n",
            "Epoch 821/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8429 - mae: 1.0094 - val_loss: 2.2170 - val_mae: 1.1329\n",
            "Epoch 822/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8409 - mae: 1.0102 - val_loss: 2.3401 - val_mae: 1.1467\n",
            "Epoch 823/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8660 - mae: 1.0212 - val_loss: 2.2366 - val_mae: 1.1441\n",
            "Epoch 824/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8159 - mae: 0.9979 - val_loss: 2.2551 - val_mae: 1.1244\n",
            "Epoch 825/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8499 - mae: 1.0145 - val_loss: 2.2356 - val_mae: 1.1174\n",
            "Epoch 826/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8401 - mae: 1.0060 - val_loss: 2.3096 - val_mae: 1.1396\n",
            "Epoch 827/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8212 - mae: 1.0018 - val_loss: 2.2441 - val_mae: 1.1424\n",
            "Epoch 828/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8122 - mae: 1.0048 - val_loss: 2.2307 - val_mae: 1.1170\n",
            "Epoch 829/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8311 - mae: 1.0083 - val_loss: 2.3092 - val_mae: 1.1603\n",
            "Epoch 830/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8554 - mae: 1.0181 - val_loss: 2.2430 - val_mae: 1.1248\n",
            "Epoch 831/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8229 - mae: 1.0038 - val_loss: 2.2007 - val_mae: 1.1229\n",
            "Epoch 832/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8419 - mae: 1.0069 - val_loss: 2.3271 - val_mae: 1.1753\n",
            "Epoch 833/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8237 - mae: 1.0037 - val_loss: 2.2313 - val_mae: 1.1421\n",
            "Epoch 834/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8102 - mae: 1.0001 - val_loss: 2.2678 - val_mae: 1.1543\n",
            "Epoch 835/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8089 - mae: 1.0009 - val_loss: 2.2047 - val_mae: 1.1238\n",
            "Epoch 836/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8174 - mae: 1.0004 - val_loss: 2.3123 - val_mae: 1.1354\n",
            "Epoch 837/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8103 - mae: 0.9978 - val_loss: 2.2168 - val_mae: 1.1167\n",
            "Epoch 838/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8146 - mae: 1.0028 - val_loss: 2.2190 - val_mae: 1.1295\n",
            "Epoch 839/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8029 - mae: 0.9979 - val_loss: 2.2340 - val_mae: 1.1303\n",
            "Epoch 840/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8226 - mae: 1.0085 - val_loss: 2.3191 - val_mae: 1.1436\n",
            "Epoch 841/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8064 - mae: 0.9960 - val_loss: 2.2270 - val_mae: 1.1436\n",
            "Epoch 842/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8148 - mae: 0.9973 - val_loss: 2.1908 - val_mae: 1.1295\n",
            "Epoch 843/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8072 - mae: 1.0002 - val_loss: 2.1881 - val_mae: 1.1197\n",
            "Epoch 844/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8003 - mae: 0.9986 - val_loss: 2.2032 - val_mae: 1.1251\n",
            "Epoch 845/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8055 - mae: 1.0046 - val_loss: 2.1809 - val_mae: 1.1207\n",
            "Epoch 846/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8201 - mae: 1.0074 - val_loss: 2.3609 - val_mae: 1.1540\n",
            "Epoch 847/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8255 - mae: 1.0042 - val_loss: 2.2477 - val_mae: 1.1473\n",
            "Epoch 848/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7986 - mae: 0.9964 - val_loss: 2.1742 - val_mae: 1.1120\n",
            "Epoch 849/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8751 - mae: 1.0234 - val_loss: 2.2500 - val_mae: 1.1333\n",
            "Epoch 850/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8128 - mae: 0.9966 - val_loss: 2.1814 - val_mae: 1.1178\n",
            "Epoch 851/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8029 - mae: 0.9993 - val_loss: 2.1813 - val_mae: 1.1184\n",
            "Epoch 852/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7705 - mae: 0.9868 - val_loss: 2.2621 - val_mae: 1.1473\n",
            "Epoch 853/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7849 - mae: 0.9915 - val_loss: 2.2524 - val_mae: 1.1512\n",
            "Epoch 854/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7814 - mae: 0.9910 - val_loss: 2.2311 - val_mae: 1.1231\n",
            "Epoch 855/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7938 - mae: 0.9968 - val_loss: 2.1700 - val_mae: 1.1110\n",
            "Epoch 856/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7765 - mae: 0.9881 - val_loss: 2.1862 - val_mae: 1.1221\n",
            "Epoch 857/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8055 - mae: 1.0018 - val_loss: 2.2129 - val_mae: 1.1213\n",
            "Epoch 858/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7848 - mae: 0.9896 - val_loss: 2.2034 - val_mae: 1.1291\n",
            "Epoch 859/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7821 - mae: 0.9968 - val_loss: 2.2102 - val_mae: 1.1312\n",
            "Epoch 860/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7803 - mae: 0.9883 - val_loss: 2.1812 - val_mae: 1.1099\n",
            "Epoch 861/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8041 - mae: 1.0020 - val_loss: 2.2659 - val_mae: 1.1551\n",
            "Epoch 862/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7713 - mae: 0.9841 - val_loss: 2.2339 - val_mae: 1.1194\n",
            "Epoch 863/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7777 - mae: 0.9885 - val_loss: 2.1759 - val_mae: 1.1225\n",
            "Epoch 864/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7833 - mae: 0.9977 - val_loss: 2.1806 - val_mae: 1.1190\n",
            "Epoch 865/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7878 - mae: 0.9914 - val_loss: 2.2505 - val_mae: 1.1216\n",
            "Epoch 866/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7627 - mae: 0.9877 - val_loss: 2.1743 - val_mae: 1.1152\n",
            "Epoch 867/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7643 - mae: 0.9841 - val_loss: 2.2216 - val_mae: 1.1158\n",
            "Epoch 868/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7844 - mae: 0.9908 - val_loss: 2.1710 - val_mae: 1.1129\n",
            "Epoch 869/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7704 - mae: 0.9897 - val_loss: 2.1677 - val_mae: 1.1280\n",
            "Epoch 870/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7450 - mae: 0.9780 - val_loss: 2.2437 - val_mae: 1.1519\n",
            "Epoch 871/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7992 - mae: 0.9923 - val_loss: 2.1692 - val_mae: 1.1016\n",
            "Epoch 872/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7545 - mae: 0.9811 - val_loss: 2.1997 - val_mae: 1.1130\n",
            "Epoch 873/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8026 - mae: 0.9934 - val_loss: 2.1809 - val_mae: 1.1133\n",
            "Epoch 874/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7524 - mae: 0.9792 - val_loss: 2.1851 - val_mae: 1.1096\n",
            "Epoch 875/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7690 - mae: 0.9860 - val_loss: 2.1889 - val_mae: 1.1167\n",
            "Epoch 876/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7719 - mae: 0.9861 - val_loss: 2.2176 - val_mae: 1.1363\n",
            "Epoch 877/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7749 - mae: 0.9881 - val_loss: 2.1508 - val_mae: 1.1146\n",
            "Epoch 878/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7560 - mae: 0.9810 - val_loss: 2.1670 - val_mae: 1.1089\n",
            "Epoch 879/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7626 - mae: 0.9846 - val_loss: 2.1489 - val_mae: 1.1168\n",
            "Epoch 880/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7472 - mae: 0.9803 - val_loss: 2.2102 - val_mae: 1.1347\n",
            "Epoch 881/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7550 - mae: 0.9844 - val_loss: 2.1603 - val_mae: 1.1094\n",
            "Epoch 882/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7584 - mae: 0.9849 - val_loss: 2.2773 - val_mae: 1.1349\n",
            "Epoch 883/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7559 - mae: 0.9805 - val_loss: 2.2446 - val_mae: 1.1448\n",
            "Epoch 884/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7670 - mae: 0.9844 - val_loss: 2.1832 - val_mae: 1.1201\n",
            "Epoch 885/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7547 - mae: 0.9833 - val_loss: 2.1543 - val_mae: 1.1045\n",
            "Epoch 886/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7351 - mae: 0.9726 - val_loss: 2.1603 - val_mae: 1.1121\n",
            "Epoch 887/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7471 - mae: 0.9731 - val_loss: 2.1445 - val_mae: 1.1045\n",
            "Epoch 888/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7471 - mae: 0.9753 - val_loss: 2.1448 - val_mae: 1.1106\n",
            "Epoch 889/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7609 - mae: 0.9854 - val_loss: 2.1769 - val_mae: 1.1249\n",
            "Epoch 890/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7334 - mae: 0.9737 - val_loss: 2.1507 - val_mae: 1.1122\n",
            "Epoch 891/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7615 - mae: 0.9866 - val_loss: 2.1743 - val_mae: 1.1235\n",
            "Epoch 892/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7442 - mae: 0.9799 - val_loss: 2.1563 - val_mae: 1.1060\n",
            "Epoch 893/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7456 - mae: 0.9774 - val_loss: 2.2043 - val_mae: 1.1233\n",
            "Epoch 894/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7581 - mae: 0.9812 - val_loss: 2.2004 - val_mae: 1.1142\n",
            "Epoch 895/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7378 - mae: 0.9764 - val_loss: 2.1741 - val_mae: 1.1139\n",
            "Epoch 896/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7247 - mae: 0.9678 - val_loss: 2.1646 - val_mae: 1.1101\n",
            "Epoch 897/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7387 - mae: 0.9778 - val_loss: 2.1645 - val_mae: 1.1162\n",
            "Epoch 898/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7308 - mae: 0.9741 - val_loss: 2.1539 - val_mae: 1.1044\n",
            "Epoch 899/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7309 - mae: 0.9711 - val_loss: 2.1557 - val_mae: 1.1093\n",
            "Epoch 900/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7365 - mae: 0.9730 - val_loss: 2.1432 - val_mae: 1.1037\n",
            "Epoch 901/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7258 - mae: 0.9701 - val_loss: 2.2100 - val_mae: 1.1157\n",
            "Epoch 902/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7324 - mae: 0.9733 - val_loss: 2.1328 - val_mae: 1.1053\n",
            "Epoch 903/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7207 - mae: 0.9714 - val_loss: 2.2291 - val_mae: 1.1241\n",
            "Epoch 904/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7465 - mae: 0.9827 - val_loss: 2.1498 - val_mae: 1.1098\n",
            "Epoch 905/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7152 - mae: 0.9669 - val_loss: 2.1572 - val_mae: 1.1146\n",
            "Epoch 906/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7262 - mae: 0.9736 - val_loss: 2.2471 - val_mae: 1.1332\n",
            "Epoch 907/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7707 - mae: 0.9901 - val_loss: 2.1177 - val_mae: 1.1087\n",
            "Epoch 908/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7052 - mae: 0.9661 - val_loss: 2.1406 - val_mae: 1.1071\n",
            "Epoch 909/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7306 - mae: 0.9724 - val_loss: 2.1403 - val_mae: 1.1092\n",
            "Epoch 910/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7214 - mae: 0.9722 - val_loss: 2.1377 - val_mae: 1.1103\n",
            "Epoch 911/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7278 - mae: 0.9709 - val_loss: 2.1108 - val_mae: 1.1058\n",
            "Epoch 912/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7226 - mae: 0.9714 - val_loss: 2.2177 - val_mae: 1.1237\n",
            "Epoch 913/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7050 - mae: 0.9647 - val_loss: 2.1478 - val_mae: 1.1133\n",
            "Epoch 914/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7153 - mae: 0.9680 - val_loss: 2.1058 - val_mae: 1.1076\n",
            "Epoch 915/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7113 - mae: 0.9672 - val_loss: 2.1721 - val_mae: 1.1125\n",
            "Epoch 916/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7209 - mae: 0.9745 - val_loss: 2.2238 - val_mae: 1.1274\n",
            "Epoch 917/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7361 - mae: 0.9765 - val_loss: 2.1923 - val_mae: 1.1265\n",
            "Epoch 918/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7204 - mae: 0.9697 - val_loss: 2.2167 - val_mae: 1.1329\n",
            "Epoch 919/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7314 - mae: 0.9714 - val_loss: 2.1556 - val_mae: 1.1092\n",
            "Epoch 920/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7231 - mae: 0.9726 - val_loss: 2.1342 - val_mae: 1.1091\n",
            "Epoch 921/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7010 - mae: 0.9638 - val_loss: 2.1691 - val_mae: 1.1189\n",
            "Epoch 922/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7022 - mae: 0.9657 - val_loss: 2.1277 - val_mae: 1.1072\n",
            "Epoch 923/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6974 - mae: 0.9634 - val_loss: 2.1933 - val_mae: 1.1307\n",
            "Epoch 924/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6909 - mae: 0.9611 - val_loss: 2.1552 - val_mae: 1.1080\n",
            "Epoch 925/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6935 - mae: 0.9625 - val_loss: 2.1713 - val_mae: 1.1157\n",
            "Epoch 926/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6914 - mae: 0.9648 - val_loss: 2.1691 - val_mae: 1.1157\n",
            "Epoch 927/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7085 - mae: 0.9648 - val_loss: 2.1587 - val_mae: 1.1141\n",
            "Epoch 928/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7013 - mae: 0.9662 - val_loss: 2.1619 - val_mae: 1.1108\n",
            "Epoch 929/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6943 - mae: 0.9628 - val_loss: 2.1990 - val_mae: 1.1181\n",
            "Epoch 930/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7086 - mae: 0.9690 - val_loss: 2.1184 - val_mae: 1.1062\n",
            "Epoch 931/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7085 - mae: 0.9678 - val_loss: 2.2355 - val_mae: 1.1318\n",
            "Epoch 932/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7012 - mae: 0.9624 - val_loss: 2.2407 - val_mae: 1.1542\n",
            "Epoch 933/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7037 - mae: 0.9705 - val_loss: 2.1091 - val_mae: 1.1053\n",
            "Epoch 934/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7124 - mae: 0.9703 - val_loss: 2.1400 - val_mae: 1.1147\n",
            "Epoch 935/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6735 - mae: 0.9564 - val_loss: 2.1425 - val_mae: 1.1099\n",
            "Epoch 936/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6731 - mae: 0.9547 - val_loss: 2.1140 - val_mae: 1.1026\n",
            "Epoch 937/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6995 - mae: 0.9609 - val_loss: 2.1490 - val_mae: 1.1166\n",
            "Epoch 938/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6750 - mae: 0.9568 - val_loss: 2.1950 - val_mae: 1.1189\n",
            "Epoch 939/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6750 - mae: 0.9543 - val_loss: 2.1257 - val_mae: 1.1098\n",
            "Epoch 940/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6687 - mae: 0.9539 - val_loss: 2.1623 - val_mae: 1.1223\n",
            "Epoch 941/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6777 - mae: 0.9647 - val_loss: 2.1193 - val_mae: 1.1074\n",
            "Epoch 942/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6862 - mae: 0.9614 - val_loss: 2.1320 - val_mae: 1.1075\n",
            "Epoch 943/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6803 - mae: 0.9566 - val_loss: 2.1716 - val_mae: 1.1223\n",
            "Epoch 944/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6731 - mae: 0.9557 - val_loss: 2.1361 - val_mae: 1.1107\n",
            "Epoch 945/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6869 - mae: 0.9613 - val_loss: 2.1790 - val_mae: 1.1179\n",
            "Epoch 946/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6874 - mae: 0.9619 - val_loss: 2.1152 - val_mae: 1.1084\n",
            "Epoch 947/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6806 - mae: 0.9639 - val_loss: 2.1524 - val_mae: 1.1137\n",
            "Epoch 948/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6825 - mae: 0.9624 - val_loss: 2.1283 - val_mae: 1.1119\n",
            "Epoch 949/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6617 - mae: 0.9514 - val_loss: 2.1241 - val_mae: 1.1075\n",
            "Epoch 950/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7049 - mae: 0.9635 - val_loss: 2.1573 - val_mae: 1.1195\n",
            "Epoch 951/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6824 - mae: 0.9635 - val_loss: 2.1361 - val_mae: 1.1140\n",
            "Epoch 952/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6809 - mae: 0.9598 - val_loss: 2.1481 - val_mae: 1.1167\n",
            "Epoch 953/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6703 - mae: 0.9554 - val_loss: 2.1501 - val_mae: 1.1172\n",
            "Epoch 954/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6699 - mae: 0.9562 - val_loss: 2.1822 - val_mae: 1.1216\n",
            "Epoch 955/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7182 - mae: 0.9721 - val_loss: 2.1713 - val_mae: 1.1181\n",
            "Epoch 956/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6551 - mae: 0.9516 - val_loss: 2.2309 - val_mae: 1.1455\n",
            "Epoch 957/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6529 - mae: 0.9484 - val_loss: 2.1122 - val_mae: 1.1035\n",
            "Epoch 958/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6641 - mae: 0.9520 - val_loss: 2.3389 - val_mae: 1.1872\n",
            "Epoch 959/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6816 - mae: 0.9614 - val_loss: 2.2336 - val_mae: 1.1337\n",
            "Epoch 960/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6860 - mae: 0.9569 - val_loss: 2.1170 - val_mae: 1.1111\n",
            "Epoch 961/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6503 - mae: 0.9458 - val_loss: 2.1596 - val_mae: 1.1268\n",
            "Epoch 962/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6596 - mae: 0.9535 - val_loss: 2.1312 - val_mae: 1.1089\n",
            "Epoch 963/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6492 - mae: 0.9467 - val_loss: 2.1125 - val_mae: 1.1017\n",
            "Epoch 964/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6608 - mae: 0.9512 - val_loss: 2.1916 - val_mae: 1.1270\n",
            "Epoch 965/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6560 - mae: 0.9501 - val_loss: 2.1494 - val_mae: 1.1085\n",
            "Epoch 966/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6833 - mae: 0.9665 - val_loss: 2.1036 - val_mae: 1.1022\n",
            "Epoch 967/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6384 - mae: 0.9536 - val_loss: 2.1399 - val_mae: 1.1054\n",
            "Epoch 968/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6384 - mae: 0.9484 - val_loss: 2.1784 - val_mae: 1.1356\n",
            "Epoch 969/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6674 - mae: 0.9562 - val_loss: 2.1315 - val_mae: 1.1140\n",
            "Epoch 970/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6368 - mae: 0.9476 - val_loss: 2.1400 - val_mae: 1.1147\n",
            "Epoch 971/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6429 - mae: 0.9467 - val_loss: 2.1048 - val_mae: 1.1090\n",
            "Epoch 972/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6393 - mae: 0.9509 - val_loss: 2.1171 - val_mae: 1.1203\n",
            "Epoch 973/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6513 - mae: 0.9528 - val_loss: 2.0811 - val_mae: 1.0986\n",
            "Epoch 974/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6697 - mae: 0.9552 - val_loss: 2.0893 - val_mae: 1.1010\n",
            "Epoch 975/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6194 - mae: 0.9410 - val_loss: 2.0788 - val_mae: 1.1002\n",
            "Epoch 976/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6568 - mae: 0.9530 - val_loss: 2.0842 - val_mae: 1.1079\n",
            "Epoch 977/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6321 - mae: 0.9421 - val_loss: 2.0653 - val_mae: 1.0980\n",
            "Epoch 978/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6615 - mae: 0.9515 - val_loss: 2.2256 - val_mae: 1.1600\n",
            "Epoch 979/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6475 - mae: 0.9510 - val_loss: 2.1444 - val_mae: 1.1177\n",
            "Epoch 980/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6469 - mae: 0.9528 - val_loss: 2.0912 - val_mae: 1.1013\n",
            "Epoch 981/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6586 - mae: 0.9526 - val_loss: 2.0769 - val_mae: 1.1003\n",
            "Epoch 982/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6363 - mae: 0.9479 - val_loss: 2.1176 - val_mae: 1.1076\n",
            "Epoch 983/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6355 - mae: 0.9431 - val_loss: 2.0488 - val_mae: 1.0964\n",
            "Epoch 984/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6314 - mae: 0.9407 - val_loss: 2.1680 - val_mae: 1.1258\n",
            "Epoch 985/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6210 - mae: 0.9474 - val_loss: 2.0556 - val_mae: 1.0981\n",
            "Epoch 986/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6336 - mae: 0.9427 - val_loss: 2.0945 - val_mae: 1.1102\n",
            "Epoch 987/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6140 - mae: 0.9386 - val_loss: 2.0613 - val_mae: 1.0951\n",
            "Epoch 988/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6236 - mae: 0.9456 - val_loss: 2.0775 - val_mae: 1.1001\n",
            "Epoch 989/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6499 - mae: 0.9527 - val_loss: 2.0951 - val_mae: 1.1046\n",
            "Epoch 990/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6248 - mae: 0.9426 - val_loss: 2.2134 - val_mae: 1.1323\n",
            "Epoch 991/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6285 - mae: 0.9464 - val_loss: 2.1966 - val_mae: 1.1345\n",
            "Epoch 992/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6508 - mae: 0.9549 - val_loss: 2.0835 - val_mae: 1.1114\n",
            "Epoch 993/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6241 - mae: 0.9454 - val_loss: 2.0826 - val_mae: 1.1036\n",
            "Epoch 994/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6132 - mae: 0.9360 - val_loss: 2.0971 - val_mae: 1.1094\n",
            "Epoch 995/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6373 - mae: 0.9488 - val_loss: 2.0792 - val_mae: 1.0976\n",
            "Epoch 996/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6185 - mae: 0.9422 - val_loss: 2.0768 - val_mae: 1.1025\n",
            "Epoch 997/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6204 - mae: 0.9419 - val_loss: 2.0557 - val_mae: 1.0990\n",
            "Epoch 998/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6076 - mae: 0.9393 - val_loss: 2.0537 - val_mae: 1.0918\n",
            "Epoch 999/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6164 - mae: 0.9377 - val_loss: 2.1303 - val_mae: 1.1191\n",
            "Epoch 1000/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.6136 - mae: 0.9374 - val_loss: 2.0399 - val_mae: 1.0974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  \"Accuracy Plot\"\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# \"Loss Plot\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TlaVtTQ06VeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "daa30063-1326-42d0-8c34-dc65b81f37fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_neural,mae_neural = model.evaluate(Xtest,Ytest)\n",
        "print(\"Mean squared error from neural net:\", mse_neural)\n",
        "print(\"Mean absolute error from neural net \", mae_neural)"
      ],
      "metadata": {
        "id": "3v6uKT8nue-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075a57d3-2b47-499d-a782-dd49fa5d2daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step - loss: 2.0399 - mae: 1.0974\n",
            "Mean squared error from neural net: 2.039907693862915\n",
            "Mean absolute error from neural net  1.0973572731018066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "yG4lkH-2ufBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression"
      ],
      "metadata": {
        "id": "RIDdkXS8-G4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear = linear_model.LinearRegression()\n",
        "lr_model_linear.fit(Xtrain , Ytrain)\n",
        "Ypred_lr = model.predict(Xtest)\n",
        "\n",
        "mse_lr = mean_squared_error(Ytest,Ypred)\n",
        "mae_lr = mean_absolute_error(Ytest,Ypred)\n",
        "print(\" Mean squared error from linear regression : \" , mse_lr)\n",
        "print(\" Mean absolute error from linear regression : \" , mae_lr)"
      ],
      "metadata": {
        "id": "mhtjhaKpufF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cc2ba3-d930-469d-f315-0364a3424fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 1ms/step\n",
            " Mean squared error from linear regression :  2.991381958542688\n",
            " Mean absolute error from linear regression :  1.229401430901856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now plot the feature's importance\n",
        "# according to the linear model.\n",
        "\n",
        "# Create series with feature importance.\n",
        "tmp = pd.Series(lr_model_linear.coef_)\n",
        "\n",
        "# Let's add the variable names.\n",
        "Xtrain = pd.DataFrame(Xtrain)\n",
        "tmp.index = Xtrain.columns\n",
        "\n",
        "# Let's make a bar plot.\n",
        "tmp.plot.bar(figsize=(15, 6))\n",
        "plt.title(\"Feature importance\")\n",
        "plt.ylabel(\"Importance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "u0--6ueQUStO",
        "outputId": "a6e8770c-6a1a-4c33-d290-2416080f024c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-21ddec0af4f0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create series with feature importance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_model_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Let's add the variable names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "L7CWJVy1-K98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "tree.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_tree = tree.predict(Xtest_scaled)\n",
        "mse_dt = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_dt = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using decision tree : \" , mse_dt)\n",
        "print(\" Mean absolute error useing decision tree : \" , mae_dt)"
      ],
      "metadata": {
        "id": "UZv8pZbHufP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0e5b9c-632a-4c3e-9591-2b9dabe9263d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using decision tree :  3.248896801457195\n",
            " Mean absolute error useing decision tree :  1.3526885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest"
      ],
      "metadata": {
        "id": "V3Ml1OxKCFk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor(n_estimators=30, random_state=30)\n",
        "model_rf.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_rf = model_rf.predict(Xtest_scaled)\n",
        "mse_rf = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_rf = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using Random Forest : \" , mse_rf)\n",
        "print(\" Mean absolute error using Random Forest : \" , mae_rf)"
      ],
      "metadata": {
        "id": "7rbI7HHQufS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad3632e-e3e0-4458-fbfd-ca28fd5270e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using Random Forest :  3.248896801457195\n",
            " Mean absolute error using Random Forest :  1.3526885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature randking"
      ],
      "metadata": {
        "id": "UL8F17I-FBVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now plot the feature's importance\n",
        "# according to the linear model.\n",
        "\n",
        "# Create series with feature importance.\n",
        "tmp = pd.Series(np.abs(model_rf.feature_importances_))\n",
        "\n",
        "# Let's add the variable names.\n",
        "Xtrain = pd.DataFrame(Xtrain)\n",
        "tmp.index = Xtrain.columns\n",
        "\n",
        "# Let's make a bar plot.\n",
        "tmp.plot.bar(figsize=(15, 6))\n",
        "plt.title(\"Feature importance\")\n",
        "plt.ylabel(\"Importance\")"
      ],
      "metadata": {
        "id": "gfB0T5GIufVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "146ad9a6-f3a9-4c7a-94bb-aa3427aaeac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Importance')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure to import all of our modules\n",
        "# sklearn package\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# dataframes\n",
        "import pandas as pd\n",
        "# computation\n",
        "import numpy as np\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dataset\n",
        "# https://www.kaggle.com/datasets/ciphernine/brooklyn-real-estate-listings\n",
        "# place it in the same folder as this workbook\n",
        "#df = pd.read_csv('brooklyn_listings.csv')\n",
        "\n",
        "# for this example, we're going to estimate the price with sqft, bathroom, and bedrooms\n",
        "#df = df[['price','bathrooms','sqft']].dropna()\n",
        "\n",
        "# show some random lines from our data\n",
        "#print(df.sample(n=15)"
      ],
      "metadata": {
        "id": "9B4C-caKFHHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our polynomial model, with whatever degree we want\n",
        "degree=2\n",
        "\n",
        "# PolynomialFeatures will create a new matrix consisting of all polynomial combinations\n",
        "# of the features with a degree less than or equal to the degree we just gave the model (2)\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "# transform out polynomial features\n",
        "poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "\n",
        "# should be in the form [1, a, b, a^2, ab, b^2]\n",
        "print(f'initial values {Xtrain_scaled[0]}\\nMapped to {poly_x_values[0]}')\n",
        "\n",
        "# [1, a=5, b=2940, a^2=25, 5*2940=14700, b^2=8643600]"
      ],
      "metadata": {
        "id": "9iKrfrOBFHJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3060b91-ff94-46e3-d60a-f4e8923098eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial values [ 1.19511602 -1.49906108 -0.93295852 -1.20240406 -1.6638147   0.58971247\n",
            "  0.97886613  0.95910281 -2.31186148 -1.58497443 -1.57611082  0.92176546\n",
            "  0.92489579  0.55786513  0.20146035  1.06313119  0.63012796  0.95515212\n",
            "  1.27895312  1.74418194  2.24778212  0.83765488  0.90264358  0.94509406\n",
            "  0.72988846  0.23921987  0.35142359  0.9048538   1.65575797  1.78157834\n",
            "  1.19563771  1.37595614  1.69347943  1.74532185  0.76319455 -0.23190983\n",
            "  0.8161398   0.87841272  1.07563665]\n",
            "Mapped to [ 1.          1.19511602 -1.49906108 -0.93295852 -1.20240406 -1.6638147\n",
            "  0.58971247  0.97886613  0.95910281 -2.31186148 -1.58497443 -1.57611082\n",
            "  0.92176546  0.92489579  0.55786513  0.20146035  1.06313119  0.63012796\n",
            "  0.95515212  1.27895312  1.74418194  2.24778212  0.83765488  0.90264358\n",
            "  0.94509406  0.72988846  0.23921987  0.35142359  0.9048538   1.65575797\n",
            "  1.78157834  1.19563771  1.37595614  1.69347943  1.74532185  0.76319455\n",
            " -0.23190983  0.8161398   0.87841272  1.07563665  1.4283023  -1.79155191\n",
            " -1.11499367 -1.43701235 -1.9884516   0.70477482  1.16985859  1.14623913\n",
            " -2.76294269 -1.89422833 -1.88363528  1.10161667  1.10535777  0.66671355\n",
            "  0.24076849  1.27056511  0.75307602  1.1415176   1.52849736  2.08449977\n",
            "  2.68636042  1.00109477  1.0787638   1.12949705  0.87230139  0.2858955\n",
            "  0.41999197  1.08140527  1.97882287  2.12919281  1.42892578  1.64442722\n",
            "  2.02390439  2.0858621   0.91210603 -0.27715915  0.97538175  1.04980511\n",
            "  1.28551059  2.24718411  1.3985618   1.80247712  2.49415986 -0.88401502\n",
            " -1.46738011 -1.43775369  3.46562156  2.37597347  2.36268638 -1.38178273\n",
            " -1.38647527 -0.8362739  -0.30200137 -1.59369858 -0.94460031 -1.43183137\n",
            " -1.91722884 -2.61463525 -3.36956269 -1.25569583 -1.35311785 -1.41675372\n",
            " -1.09414738 -0.3586052  -0.52680543 -1.35643111 -2.48208232 -2.67069474\n",
            " -1.79233395 -2.06264229 -2.53862909 -2.61634406 -1.14407524  0.347647\n",
            " -1.22344341 -1.31679431 -1.61244503  0.87041159  1.1217931   1.5522701\n",
            " -0.55017728 -0.91324149 -0.89480313  2.15687086  1.47871539  1.47044601\n",
            " -0.85996894 -0.8628894  -0.52046502 -0.18795415 -0.9918573  -0.58788325\n",
            " -0.89111731 -1.19321021 -1.62724939 -2.09708747 -0.78149726 -0.84212901\n",
            " -0.88173355 -0.68095566 -0.22318222 -0.32786363 -0.84419105 -1.5447535\n",
            " -1.66213868 -1.11548038 -1.28371    -1.57994605 -1.62831289 -0.71202885\n",
            "  0.21636225 -0.76142458 -0.81952262 -1.00352437  1.44577552  2.00057755\n",
            " -0.70907267 -1.1769926  -1.15322911  2.77979162  1.90577968  1.89512204\n",
            " -1.10833453 -1.11209844 -0.67077929 -0.24223674 -1.27831325 -0.75766842\n",
            " -1.14847879 -1.53781842 -2.09721143 -2.70274234 -1.00719963 -1.0853423\n",
            " -1.13638493 -0.87762085 -0.28763895 -0.42255315 -1.08799987 -1.99089009\n",
            " -2.14217702 -1.43763963 -1.65445524 -2.03624653 -2.09858208 -0.91766822\n",
            "  0.27884932 -0.98132981 -1.05620701 -1.29334987  2.76827936 -0.98117229\n",
            " -1.62865185 -1.59576935  3.84650912  2.63710376  2.62235635 -1.53364693\n",
            " -1.53885521 -0.9281842  -0.33519269 -1.7688533  -1.04841617 -1.58919615\n",
            " -2.127941   -2.90199555 -3.73989294 -1.39370251 -1.50183166 -1.57246139\n",
            " -1.21439915 -0.39801754 -0.58470374 -1.50550905 -2.75487445 -2.96421623\n",
            " -1.9893196  -2.28933605 -2.81763597 -2.90389216 -1.26981431  0.38585498\n",
            " -1.35790541 -1.46151599 -1.78966007  0.3477608   0.57724957  0.56559489\n",
            " -1.36333355 -0.93467919 -0.92945221  0.54357659  0.54542258  0.32898002\n",
            "  0.11880368  0.62694172  0.37159432  0.56326512  0.75421461  1.02856585\n",
            "  1.32554516  0.49397553  0.53230018  0.55733376  0.43042433  0.14107094\n",
            "  0.20723888  0.53360357  0.97642113  1.05061897  0.70508247  0.8114185\n",
            "  0.99866594  1.02923807  0.45006535 -0.13676012  0.48128782  0.51801094\n",
            "  0.63431635  0.9581789   0.93883325 -2.2630029  -1.55147778 -1.54280149\n",
            "  0.90228499  0.90534916  0.54607528  0.19720271  1.04066311  0.61681092\n",
            "  0.93496606  1.25192389  1.70732062  2.20027778  0.81995199  0.88356722\n",
            "  0.92512056  0.71446309  0.23416423  0.34399665  0.88573073  1.62076539\n",
            "  1.74392669  1.17036925  1.34687685  1.65768965  1.70843644  0.74706529\n",
            " -0.22700868  0.79889161  0.85984845  1.05290428  0.91987819 -2.21731283\n",
            " -1.52015342 -1.51165231  0.88406784  0.88707014  0.53505001  0.19322119\n",
            "  1.01965211  0.6043575   0.91608908  1.22664753  1.67284979  2.15585414\n",
            "  0.80339715  0.86572799  0.90644237  0.70003807  0.22943645  0.33705135\n",
            "  0.86784781  1.58804211  1.70871679  1.14673948  1.31968339  1.62422087\n",
            "  1.67394309  0.73198203 -0.22242537  0.78276198  0.8424881   1.03164613\n",
            "  5.34470351  3.66424133  3.64374988 -2.13099407 -2.13823094 -1.2897069\n",
            " -0.46574842 -2.45781204 -1.45676857 -2.20817941 -2.95676245 -4.03230703\n",
            " -5.1965609  -1.93654206 -2.08678692 -2.18492656 -1.68740102 -0.55304321\n",
            " -0.81244267 -2.09189664 -3.82788306 -4.11876234 -2.76414876 -3.18101999\n",
            " -3.91508985 -4.03494236 -1.76440008  0.5361434  -1.88680218 -2.03076852\n",
            " -2.48672294  2.51214394  2.49809534 -1.46097469 -1.46593617 -0.88420196\n",
            " -0.3193095  -1.68503575 -0.99873671 -1.51389169 -2.02710799 -2.76448377\n",
            " -3.56267718 -1.32766157 -1.43066699 -1.49794992 -1.15685455 -0.37915738\n",
            " -0.55699741 -1.43417013 -2.62433404 -2.82375611 -1.8950552  -2.18085529\n",
            " -2.68412159 -2.76629051 -1.20964384  0.36757115 -1.29356072 -1.39226169\n",
            " -1.70485658  2.4841253  -1.45280452 -1.45773825 -0.87925726 -0.31752384\n",
            " -1.67561256 -0.9931515  -1.50542559 -2.01577184 -2.74902401 -3.54275371\n",
            " -1.32023692 -1.42266631 -1.48957297 -1.1503851  -0.37703703 -0.55388253\n",
            " -1.42614985 -2.60965804 -2.80796489 -1.88445752 -2.16865935 -2.66911124\n",
            " -2.75082065 -1.20287918  0.36551559 -1.28632677 -1.38447578 -1.69532256\n",
            "  0.84965157  0.85253699  0.51422081  0.18569919  0.97995761  0.5808302\n",
            "  0.88042624  1.17889482  1.60772667  2.07192793  0.77212134  0.83202568\n",
            "  0.87115507  0.67278598  0.22050462  0.32393013  0.83406298  1.52622051\n",
            "  1.64219738  1.10209755  1.26830885  1.56099085  1.60877741  0.70348638\n",
            " -0.21376647  0.75228949  0.8096905   0.99148471  0.85543221  0.5159671\n",
            "  0.18632983  0.98328555  0.5828027   0.88341617  1.18289835  1.61318652\n",
            "  2.07896421  0.77474347  0.83485124  0.87411351  0.67507076  0.22125345\n",
            "  0.3250302   0.83689546  1.53140356  1.6477743   1.10584028  1.27261603\n",
            "  1.56629198  1.61424083  0.70587542 -0.21449242  0.75484427  0.81244022\n",
            "  0.9948518   0.3112135   0.1123877   0.59308381  0.35152642  0.53284606\n",
            "  0.71348334  0.97301828  1.25395926  0.46729845  0.50355337  0.52723502\n",
            "  0.40717932  0.13345243  0.19604697  0.50478638  0.92368963  0.99388043\n",
            "  0.66700458  0.76759794  0.94473311  0.9736542   0.42575962 -0.12937441\n",
            "  0.45529594  0.49003582  0.60006018  0.04058627  0.21417878  0.1269458\n",
            "  0.19242528  0.25765834  0.3513835   0.45283897  0.16875425  0.18184689\n",
            "  0.19039898  0.14704358  0.04819332  0.07079792  0.18229216  0.33356958\n",
            "  0.3589174   0.24087359  0.2772006   0.34116896  0.35161315  0.15375344\n",
            " -0.04672064  0.16441981  0.17696533  0.21669814  1.13024792  0.66990869\n",
            "  1.01545201  1.35969495  1.85429421  2.38968728  0.89053703  0.95962854\n",
            "  1.00475897  0.77596719  0.25432211  0.37360938  0.96197829  1.76028793\n",
            "  1.8940515   1.27111974  1.46282188  1.80039079  1.85550609  0.81137593\n",
            " -0.24655057  0.86766368  0.93386795  1.14354287  0.39706125  0.60186806\n",
            "  0.80590413  1.09905781  1.41639037  0.52782977  0.56878096  0.5955302\n",
            "  0.45992313  0.15073913  0.22144183  0.57017368  1.0433394   1.12262233\n",
            "  0.75340476  0.86702844  1.06710874  1.09977611  0.48091023 -0.14613287\n",
            "  0.51427251  0.55351242  0.67778873  0.91231558  1.22159479  1.66595908\n",
            "  2.14697387  0.80008784  0.86216193  0.9027086   0.69715452  0.22849137\n",
            "  0.33566299  0.86427303  1.58150074  1.70167834  1.1420159   1.31424743\n",
            "  1.61753047  1.66704788  0.72896689 -0.22150916  0.77953767  0.83901777\n",
            "  1.02739663  1.63572108  2.23072693  2.87480795  1.07132133  1.15443882\n",
            "  1.208731    0.93349313  0.305951    0.4494543   1.15726558  2.11763682\n",
            "  2.27855518  1.52916458  1.75978339  2.16588079  2.23218483  0.97609005\n",
            " -0.2966018   1.04380455  1.12344868  1.37568885  3.04217062  3.92054097\n",
            "  1.46102252  1.57437462  1.64841599  1.27305827  0.41724298  0.61294668\n",
            "  1.57822964  2.88794313  3.10739676  2.08540969  2.39991784  2.95373622\n",
            "  3.04415885  1.33115015 -0.40449293  1.4234963   1.53211159  1.87610601\n",
            "  5.05252446  1.88286567  2.0289461   2.12436553  1.64063024  0.53771416\n",
            "  0.78992367  2.03391418  3.72178315  4.00459994  2.68753306  3.0928496\n",
            "  3.80657277  3.92310326  1.71549506 -0.52128276  1.83450446  1.97448039\n",
            "  2.41779683  0.70166571  0.7561038   0.79166266  0.61139464  0.2003837\n",
            "  0.29437169  0.7579552   1.38695375  1.4923478   1.00153177  1.15257638\n",
            "  1.41855131  1.46197737  0.63929364 -0.1942604   0.68364349  0.7358067\n",
            "  0.90101229  0.81476543  0.85308308  0.65882913  0.21593028  0.31721025\n",
            "  0.81676047  1.49455929  1.60813025  1.0792347   1.24199797  1.52860833\n",
            "  1.57540356  0.68889266 -0.20933192  0.73668335  0.7928936   0.97091651\n",
            "  0.89320278  0.68981325  0.22608528  0.33212835  0.85517195  1.56484702\n",
            "  1.68375911  1.1299901   1.30040797  1.60049735  1.64949332  0.72129064\n",
            " -0.2191766   0.77132888  0.83018264  1.01657781  0.53273717  0.17460383\n",
            "  0.25650003  0.66044235  1.20851864  1.30035347  0.87268217  1.00429451\n",
            "  1.23605109  1.27389028  0.5570469  -0.16926831  0.59569103  0.64114331\n",
            "  0.78509478  0.05722615  0.08406751  0.21645901  0.39609021  0.42618895\n",
            "  0.2860203   0.32915605  0.40511394  0.41751567  0.1825713  -0.05547744\n",
            "  0.19523686  0.21013378  0.25731366  0.12349854  0.31798697  0.58187241\n",
            "  0.62608866  0.4201753   0.48354345  0.59512863  0.61334728  0.26820457\n",
            " -0.08149859  0.28681078  0.30869495  0.3780041   0.81876039  1.49821888\n",
            "  1.61206792  1.08187732  1.24503913  1.53235129  1.5792611   0.69057948\n",
            " -0.20984449  0.7384872   0.79483508  0.9732939   2.74153444  2.94986253\n",
            "  1.97968666  2.27825033  2.80399205  2.88983056  1.26366545 -0.38398655\n",
            "  1.35132998  1.45443885  1.78099395  3.17402138  2.13012224  2.45137365\n",
            "  3.01706626  3.10942761  1.35969088 -0.41316553  1.454017    1.56496107\n",
            "  1.91633096  1.42954953  1.64514504  2.02478786  2.08677262  0.91250418\n",
            " -0.27728014  0.97580753  1.05026337  1.28607174  1.89325529  2.33015341\n",
            "  2.40148631  1.05012222 -0.31909775  1.12297257  1.20865737  1.48002885\n",
            "  2.86787257  2.95566665  1.29245427 -0.39273452  1.38211597  1.48757386\n",
            "  1.82156853  3.04614837  1.33202012 -0.40475729  1.42442664  1.53311291\n",
            "  1.87733215  0.58246592 -0.17699232  0.62287345  0.6703998   0.82092003\n",
            "  0.05378217 -0.18927084 -0.20371254 -0.24945071  0.66608418  0.71690758\n",
            "  0.87786988  0.7716089   0.94485291  1.1569942 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytrain, y_pred_poly, squared=False)"
      ],
      "metadata": {
        "id": "-TTd5rhyFHL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f854c5f6-d5a0-4fcf-d2c0-3e174212feb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5857097029796254"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly_test = regression_model.predict(poly_model.fit_transform(Xtest_scaled))\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytest, y_pred_poly_test, squared=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rooiJ4C18YGP",
        "outputId": "6445f142-0b91-428d-b4f6-07315825eea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.102059000773104"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "print(\" Mean absolute error from polynomial regression : \" , mae_poly)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ai089U-XXz",
        "outputId": "8dfb0eba-05d9-4004-fb7c-a2ba63e974a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from polynomial regression :  4.418652042731221\n",
            " Mean absolute error from polynomial regression :  0.9773643347588769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check our accuracy for each degree, the lower the error the better!\n",
        "number_degrees = [1,2,3,4]\n",
        "plt_mean_squared_error = []\n",
        "for degree in number_degrees:\n",
        "\n",
        "   poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "   poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "   poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "   regression_model = LinearRegression()\n",
        "   regression_model.fit(poly_x_values, Ytrain)\n",
        "   y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "   plt_mean_squared_error.append(mean_squared_error(Ytrain, y_pred_poly, squared=False))\n",
        "\n",
        "   poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "   y_pred_poly_test = regression_model.predict(poly_model.fit_transform(Xtest_scaled))\n",
        "   mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "   mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "   print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "   print(\" Mean absolute error from polynomial regression : \" , mae_poly)\n",
        "\n",
        "plt.scatter(number_degrees,plt_mean_squared_error, color=\"green\")\n",
        "plt.plot(number_degrees,plt_mean_squared_error, color=\"red\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "sWrsMQs9wdbd",
        "outputId": "50f87b80-d469-444c-e1ce-00a6db1ec011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from polynomial regression :  1.7064336301820187\n",
            " Mean absolute error from polynomial regression :  1.0197840616891123\n",
            " Mean squared error from polynomial regression :  4.418652042731221\n",
            " Mean absolute error from polynomial regression :  0.9773643347588769\n",
            " Mean squared error from polynomial regression :  50.31737035890137\n",
            " Mean absolute error from polynomial regression :  2.1674784881193725\n",
            " Mean squared error from polynomial regression :  9502.945650975198\n",
            " Mean absolute error from polynomial regression :  6.938552946406621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d19c8a4e620>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}