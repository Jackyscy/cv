{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpVi4Xz+bvdbu88gEzzVty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jackyscy/cv/blob/main/ANN_Regression_selected_Features_20231221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKE52MXN6PWJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as read_csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"2023_one hours__normal_on_state2_Selected_Feature.csv\",  parse_dates=[\"Date_Time\"],\n",
        "        index_col=[\"Date_Time\"],)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "8HNmwtyn6VLO",
        "outputId": "db1196cc-9a07-438c-f2f2-ddaad5b8d9fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Gt Exhaust Outlet Temp  GT Fuel Gas Mass Flow  \\\n",
              "Date_Time                                                            \n",
              "2023-01-20 17:00:00                 611.855                 13.760   \n",
              "2023-01-20 18:00:00                 604.004                 13.175   \n",
              "2023-01-20 19:00:00                 637.918                 11.979   \n",
              "2023-01-20 20:00:00                 636.447                 12.306   \n",
              "2023-01-20 21:00:00                 637.513                 11.290   \n",
              "\n",
              "                     GT Gross MW  GT Compres Inlet Temp  GT IGV Position  \\\n",
              "Date_Time                                                                  \n",
              "2023-01-20 17:00:00      231.782                 18.940           87.999   \n",
              "2023-01-20 18:00:00      226.570                 18.938           84.113   \n",
              "2023-01-20 19:00:00      207.629                 18.780           65.027   \n",
              "2023-01-20 20:00:00      212.659                 18.626           67.205   \n",
              "2023-01-20 21:00:00      193.451                 17.743           60.577   \n",
              "\n",
              "                     GT Turbine Inlet Temperature  GT Swirl Angle  \\\n",
              "Date_Time                                                           \n",
              "2023-01-20 17:00:00                      1255.732          14.534   \n",
              "2023-01-20 18:00:00                      1244.014          19.430   \n",
              "2023-01-20 19:00:00                      1284.943          38.101   \n",
              "2023-01-20 20:00:00                      1283.541          33.234   \n",
              "2023-01-20 21:00:00                      1270.635          51.623   \n",
              "\n",
              "                     GT Efficiency Actual (LHV)  \\\n",
              "Date_Time                                         \n",
              "2023-01-20 17:00:00                      34.919   \n",
              "2023-01-20 18:00:00                      35.239   \n",
              "2023-01-20 19:00:00                      35.913   \n",
              "2023-01-20 20:00:00                      35.783   \n",
              "2023-01-20 21:00:00                      35.513   \n",
              "\n",
              "                     Combust Monitor Actual Spread 2  \\\n",
              "Date_Time                                              \n",
              "2023-01-20 17:00:00                           31.110   \n",
              "2023-01-20 18:00:00                           24.820   \n",
              "2023-01-20 19:00:00                           27.752   \n",
              "2023-01-20 20:00:00                           28.361   \n",
              "2023-01-20 21:00:00                           15.186   \n",
              "\n",
              "                     GT Exhaust Gas Flow - HB  ...  Turb Exhaust T/C 23  \\\n",
              "Date_Time                                      ...                        \n",
              "2023-01-20 17:00:00                   650.398  ...              608.536   \n",
              "2023-01-20 18:00:00                   635.450  ...              606.971   \n",
              "2023-01-20 19:00:00                   531.246  ...              637.373   \n",
              "2023-01-20 20:00:00                   548.814  ...              632.764   \n",
              "2023-01-20 21:00:00                   504.648  ...              636.851   \n",
              "\n",
              "                     Turb Exhaust T/C 24  Turb Exhaust T/C 25  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              605.209              601.492   \n",
              "2023-01-20 18:00:00              595.928              589.052   \n",
              "2023-01-20 19:00:00              643.240              637.800   \n",
              "2023-01-20 20:00:00              648.446              627.277   \n",
              "2023-01-20 21:00:00              641.639              638.126   \n",
              "\n",
              "                     Turb Exhaust T/C 26  Turb Exhaust T/C 27  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              610.876              615.695   \n",
              "2023-01-20 18:00:00              595.202              609.593   \n",
              "2023-01-20 19:00:00              623.243              636.460   \n",
              "2023-01-20 20:00:00              618.795              641.789   \n",
              "2023-01-20 21:00:00              639.001              628.511   \n",
              "\n",
              "                     Turb Exhaust T/C 28  Turb Exhaust T/C 29  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              628.713              611.376   \n",
              "2023-01-20 18:00:00              616.492              608.235   \n",
              "2023-01-20 19:00:00              648.020              645.099   \n",
              "2023-01-20 20:00:00              640.982              649.530   \n",
              "2023-01-20 21:00:00              633.543              643.794   \n",
              "\n",
              "                     Turb Exhaust T/C 30  Turb Exhaust T/C 31  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              604.494              619.819   \n",
              "2023-01-20 18:00:00              600.413              600.202   \n",
              "2023-01-20 19:00:00              648.190              637.079   \n",
              "2023-01-20 20:00:00              641.044              630.275   \n",
              "2023-01-20 21:00:00              639.210              642.735   \n",
              "\n",
              "                     Combust Monitor Actual Spread 1  \n",
              "Date_Time                                             \n",
              "2023-01-20 17:00:00                           32.684  \n",
              "2023-01-20 18:00:00                           32.458  \n",
              "2023-01-20 19:00:00                           34.742  \n",
              "2023-01-20 20:00:00                           35.122  \n",
              "2023-01-20 21:00:00                           19.609  \n",
              "\n",
              "[5 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d07ecc5-8abf-4bd7-b3b4-31a00596ecf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gt Exhaust Outlet Temp</th>\n",
              "      <th>GT Fuel Gas Mass Flow</th>\n",
              "      <th>GT Gross MW</th>\n",
              "      <th>GT Compres Inlet Temp</th>\n",
              "      <th>GT IGV Position</th>\n",
              "      <th>GT Turbine Inlet Temperature</th>\n",
              "      <th>GT Swirl Angle</th>\n",
              "      <th>GT Efficiency Actual (LHV)</th>\n",
              "      <th>Combust Monitor Actual Spread 2</th>\n",
              "      <th>GT Exhaust Gas Flow - HB</th>\n",
              "      <th>...</th>\n",
              "      <th>Turb Exhaust T/C 23</th>\n",
              "      <th>Turb Exhaust T/C 24</th>\n",
              "      <th>Turb Exhaust T/C 25</th>\n",
              "      <th>Turb Exhaust T/C 26</th>\n",
              "      <th>Turb Exhaust T/C 27</th>\n",
              "      <th>Turb Exhaust T/C 28</th>\n",
              "      <th>Turb Exhaust T/C 29</th>\n",
              "      <th>Turb Exhaust T/C 30</th>\n",
              "      <th>Turb Exhaust T/C 31</th>\n",
              "      <th>Combust Monitor Actual Spread 1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date_Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-20 17:00:00</th>\n",
              "      <td>611.855</td>\n",
              "      <td>13.760</td>\n",
              "      <td>231.782</td>\n",
              "      <td>18.940</td>\n",
              "      <td>87.999</td>\n",
              "      <td>1255.732</td>\n",
              "      <td>14.534</td>\n",
              "      <td>34.919</td>\n",
              "      <td>31.110</td>\n",
              "      <td>650.398</td>\n",
              "      <td>...</td>\n",
              "      <td>608.536</td>\n",
              "      <td>605.209</td>\n",
              "      <td>601.492</td>\n",
              "      <td>610.876</td>\n",
              "      <td>615.695</td>\n",
              "      <td>628.713</td>\n",
              "      <td>611.376</td>\n",
              "      <td>604.494</td>\n",
              "      <td>619.819</td>\n",
              "      <td>32.684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 18:00:00</th>\n",
              "      <td>604.004</td>\n",
              "      <td>13.175</td>\n",
              "      <td>226.570</td>\n",
              "      <td>18.938</td>\n",
              "      <td>84.113</td>\n",
              "      <td>1244.014</td>\n",
              "      <td>19.430</td>\n",
              "      <td>35.239</td>\n",
              "      <td>24.820</td>\n",
              "      <td>635.450</td>\n",
              "      <td>...</td>\n",
              "      <td>606.971</td>\n",
              "      <td>595.928</td>\n",
              "      <td>589.052</td>\n",
              "      <td>595.202</td>\n",
              "      <td>609.593</td>\n",
              "      <td>616.492</td>\n",
              "      <td>608.235</td>\n",
              "      <td>600.413</td>\n",
              "      <td>600.202</td>\n",
              "      <td>32.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 19:00:00</th>\n",
              "      <td>637.918</td>\n",
              "      <td>11.979</td>\n",
              "      <td>207.629</td>\n",
              "      <td>18.780</td>\n",
              "      <td>65.027</td>\n",
              "      <td>1284.943</td>\n",
              "      <td>38.101</td>\n",
              "      <td>35.913</td>\n",
              "      <td>27.752</td>\n",
              "      <td>531.246</td>\n",
              "      <td>...</td>\n",
              "      <td>637.373</td>\n",
              "      <td>643.240</td>\n",
              "      <td>637.800</td>\n",
              "      <td>623.243</td>\n",
              "      <td>636.460</td>\n",
              "      <td>648.020</td>\n",
              "      <td>645.099</td>\n",
              "      <td>648.190</td>\n",
              "      <td>637.079</td>\n",
              "      <td>34.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 20:00:00</th>\n",
              "      <td>636.447</td>\n",
              "      <td>12.306</td>\n",
              "      <td>212.659</td>\n",
              "      <td>18.626</td>\n",
              "      <td>67.205</td>\n",
              "      <td>1283.541</td>\n",
              "      <td>33.234</td>\n",
              "      <td>35.783</td>\n",
              "      <td>28.361</td>\n",
              "      <td>548.814</td>\n",
              "      <td>...</td>\n",
              "      <td>632.764</td>\n",
              "      <td>648.446</td>\n",
              "      <td>627.277</td>\n",
              "      <td>618.795</td>\n",
              "      <td>641.789</td>\n",
              "      <td>640.982</td>\n",
              "      <td>649.530</td>\n",
              "      <td>641.044</td>\n",
              "      <td>630.275</td>\n",
              "      <td>35.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 21:00:00</th>\n",
              "      <td>637.513</td>\n",
              "      <td>11.290</td>\n",
              "      <td>193.451</td>\n",
              "      <td>17.743</td>\n",
              "      <td>60.577</td>\n",
              "      <td>1270.635</td>\n",
              "      <td>51.623</td>\n",
              "      <td>35.513</td>\n",
              "      <td>15.186</td>\n",
              "      <td>504.648</td>\n",
              "      <td>...</td>\n",
              "      <td>636.851</td>\n",
              "      <td>641.639</td>\n",
              "      <td>638.126</td>\n",
              "      <td>639.001</td>\n",
              "      <td>628.511</td>\n",
              "      <td>633.543</td>\n",
              "      <td>643.794</td>\n",
              "      <td>639.210</td>\n",
              "      <td>642.735</td>\n",
              "      <td>19.609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d07ecc5-8abf-4bd7-b3b4-31a00596ecf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d07ecc5-8abf-4bd7-b3b4-31a00596ecf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d07ecc5-8abf-4bd7-b3b4-31a00596ecf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7b944b3-c7da-41da-9da0-9ac67ad21043\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7b944b3-c7da-41da-9da0-9ac67ad21043')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7b944b3-c7da-41da-9da0-9ac67ad21043 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "iOH_0t5Y6VNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706c4340-9ba0-498e-f1b0-36eef2c65397"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2743 entries, 2023-01-20 17:00:00 to 2023-10-29 22:00:00\n",
            "Data columns (total 40 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   Gt Exhaust Outlet Temp           2743 non-null   float64\n",
            " 1   GT Fuel Gas Mass Flow            2743 non-null   float64\n",
            " 2   GT Gross MW                      2743 non-null   float64\n",
            " 3   GT Compres Inlet Temp            2743 non-null   float64\n",
            " 4   GT IGV Position                  2743 non-null   float64\n",
            " 5   GT Turbine Inlet Temperature     2743 non-null   float64\n",
            " 6   GT Swirl Angle                   2743 non-null   float64\n",
            " 7   GT Efficiency Actual (LHV)       2743 non-null   float64\n",
            " 8   Combust Monitor Actual Spread 2  2743 non-null   float64\n",
            " 9   GT Exhaust Gas Flow - HB         2743 non-null   float64\n",
            " 10  Combust Monitor Actual Spread 3  2743 non-null   float64\n",
            " 11  Turb Exhaust T/C 2               2743 non-null   float64\n",
            " 12  Turb Exhaust T/C 3               2743 non-null   float64\n",
            " 13  Turb Exhaust T/C 4               2743 non-null   float64\n",
            " 14  Turb Exhaust T/C 5               2743 non-null   float64\n",
            " 15  Turb Exhaust T/C 6               2743 non-null   float64\n",
            " 16  Turb Exhaust T/C 7               2743 non-null   float64\n",
            " 17  Turb Exhaust T/C 8               2743 non-null   float64\n",
            " 18  Turb Exhaust T/C 9               2743 non-null   float64\n",
            " 19  Turb Exhaust T/C 10              2743 non-null   float64\n",
            " 20  Turb Exhaust T/C 11              2743 non-null   float64\n",
            " 21  Turb Exhaust T/C 13              2743 non-null   float64\n",
            " 22  Turb Exhaust T/C 14              2743 non-null   float64\n",
            " 23  Turb Exhaust T/C 16              2743 non-null   float64\n",
            " 24  Turb Exhaust T/C 17              2743 non-null   float64\n",
            " 25  Turb Exhaust T/C 18              2743 non-null   float64\n",
            " 26  Turb Exhaust T/C 19              2743 non-null   float64\n",
            " 27  Turb Exhaust T/C 20              2743 non-null   float64\n",
            " 28  Turb Exhaust T/C 21              2743 non-null   float64\n",
            " 29  Turb Exhaust T/C 22              2743 non-null   float64\n",
            " 30  Turb Exhaust T/C 23              2743 non-null   float64\n",
            " 31  Turb Exhaust T/C 24              2743 non-null   float64\n",
            " 32  Turb Exhaust T/C 25              2743 non-null   float64\n",
            " 33  Turb Exhaust T/C 26              2743 non-null   float64\n",
            " 34  Turb Exhaust T/C 27              2743 non-null   float64\n",
            " 35  Turb Exhaust T/C 28              2743 non-null   float64\n",
            " 36  Turb Exhaust T/C 29              2743 non-null   float64\n",
            " 37  Turb Exhaust T/C 30              2743 non-null   float64\n",
            " 38  Turb Exhaust T/C 31              2743 non-null   float64\n",
            " 39  Combust Monitor Actual Spread 1  2743 non-null   float64\n",
            "dtypes: float64(40)\n",
            "memory usage: 878.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_object(obj , name):\n",
        "    pickle_obj = open(f\"{name}.pck\",\"wb\")\n",
        "    pickle.dump(obj, pickle_obj)\n",
        "    pickle_obj.close()"
      ],
      "metadata": {
        "id": "dlPH0K2L0z8n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_columns = list(data.columns)\n",
        "remaining_columns.remove(\"Combust Monitor Actual Spread 1\")"
      ],
      "metadata": {
        "id": "O3fEOAMI6VTi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[remaining_columns].values\n",
        "Y = data['Combust Monitor Actual Spread 1'].values"
      ],
      "metadata": {
        "id": "sIi0rAAHm7je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "QSSDnV4mGoIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee89a190-309e-4002-807e-805abea5ad00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gt Exhaust Outlet Temp', 'GT Fuel Gas Mass Flow', 'GT Gross MW',\n",
              "       'GT Compres Inlet Temp', 'GT IGV Position',\n",
              "       'GT Turbine Inlet Temperature', 'GT Swirl Angle',\n",
              "       'GT Efficiency Actual (LHV)', 'Combust Monitor Actual Spread 2',\n",
              "       'GT Exhaust Gas Flow - HB', 'Combust Monitor Actual Spread 3',\n",
              "       'Turb Exhaust T/C 2', 'Turb Exhaust T/C 3', 'Turb Exhaust T/C 4',\n",
              "       'Turb Exhaust T/C 5', 'Turb Exhaust T/C 6', 'Turb Exhaust T/C 7',\n",
              "       'Turb Exhaust T/C 8', 'Turb Exhaust T/C 9', 'Turb Exhaust T/C 10',\n",
              "       'Turb Exhaust T/C 11', 'Turb Exhaust T/C 13', 'Turb Exhaust T/C 14',\n",
              "       'Turb Exhaust T/C 16', 'Turb Exhaust T/C 17', 'Turb Exhaust T/C 18',\n",
              "       'Turb Exhaust T/C 19', 'Turb Exhaust T/C 20', 'Turb Exhaust T/C 21',\n",
              "       'Turb Exhaust T/C 22', 'Turb Exhaust T/C 23', 'Turb Exhaust T/C 24',\n",
              "       'Turb Exhaust T/C 25', 'Turb Exhaust T/C 26', 'Turb Exhaust T/C 27',\n",
              "       'Turb Exhaust T/C 28', 'Turb Exhaust T/C 29', 'Turb Exhaust T/C 30',\n",
              "       'Turb Exhaust T/C 31', 'Combust Monitor Actual Spread 1'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain , Xtest , Ytrain , Ytest = train_test_split(X , Y , test_size = 0.2 , random_state = 4)"
      ],
      "metadata": {
        "id": "lKNlEbvl6VV4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(Xtrain)\n",
        "\n",
        "Xtrain_scaled = scaler.transform(Xtrain)\n",
        "Xtest_scaled = scaler.transform(Xtest)"
      ],
      "metadata": {
        "id": "97ydOg056VYs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_object(scaler,\"scaler\")"
      ],
      "metadata": {
        "id": "296OJsUw05TT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported Network designed in previous lesson\n",
        "\n",
        "# Start your model with Sequential Object\n",
        "model = tf.keras.models.Sequential()\n",
        "# Next add in your Input object and Specify the Dimension you want to pass in\n",
        "model.add(tf.keras.Input(shape=(39,)))\n",
        "# Add in your Neurons of 1st layer\n",
        "model.add(tf.keras.layers.Dense(1000, activation='sigmoid'))\n",
        "# 2nd layer\n",
        "model.add(tf.keras.layers.Dense(500, activation='sigmoid'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1 , activation='linear'))\n",
        "\n",
        "\n",
        "Optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(Optimizer, loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# print summary to undertstand your neural network flow\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eUu-P0lz6VbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520a765c-c588-466c-cdb6-993bbab99290"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1000)              40000     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541001 (2.06 MB)\n",
            "Trainable params: 541001 (2.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xtrain_scaled , Ytrain , validation_data=(Xtest_scaled , Ytest) , epochs=1000)"
      ],
      "metadata": {
        "id": "arJHOFaJta5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec333194-f455-4853-b84a-fd26aaf63d2a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "69/69 [==============================] - 3s 6ms/step - loss: 101.6050 - mae: 8.1292 - val_loss: 17.4655 - val_mae: 3.4376\n",
            "Epoch 2/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.6884 - mae: 2.7936 - val_loss: 14.4922 - val_mae: 2.8019\n",
            "Epoch 3/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 8.1521 - mae: 2.1320 - val_loss: 6.4733 - val_mae: 1.8802\n",
            "Epoch 4/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 5.1920 - mae: 1.7462 - val_loss: 5.9088 - val_mae: 1.7819\n",
            "Epoch 5/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.8586 - mae: 1.6778 - val_loss: 5.7111 - val_mae: 1.7438\n",
            "Epoch 6/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.7067 - mae: 1.6564 - val_loss: 5.5984 - val_mae: 1.7254\n",
            "Epoch 7/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.5863 - mae: 1.6335 - val_loss: 5.4807 - val_mae: 1.7108\n",
            "Epoch 8/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.4737 - mae: 1.6177 - val_loss: 5.2748 - val_mae: 1.6824\n",
            "Epoch 9/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 4.2612 - mae: 1.5875 - val_loss: 4.8231 - val_mae: 1.6498\n",
            "Epoch 10/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 3.7640 - mae: 1.5211 - val_loss: 3.7087 - val_mae: 1.5011\n",
            "Epoch 11/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 3.1748 - mae: 1.4049 - val_loss: 3.2194 - val_mae: 1.4207\n",
            "Epoch 12/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.6587 - mae: 1.2898 - val_loss: 2.7512 - val_mae: 1.2731\n",
            "Epoch 13/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3948 - mae: 1.2258 - val_loss: 2.5010 - val_mae: 1.2105\n",
            "Epoch 14/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.2977 - mae: 1.1892 - val_loss: 2.3162 - val_mae: 1.1610\n",
            "Epoch 15/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1732 - mae: 1.1547 - val_loss: 2.2211 - val_mae: 1.1587\n",
            "Epoch 16/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1087 - mae: 1.1409 - val_loss: 2.0724 - val_mae: 1.1097\n",
            "Epoch 17/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0326 - mae: 1.1259 - val_loss: 2.0208 - val_mae: 1.0880\n",
            "Epoch 18/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9642 - mae: 1.0978 - val_loss: 2.0749 - val_mae: 1.1234\n",
            "Epoch 19/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9713 - mae: 1.1000 - val_loss: 1.9938 - val_mae: 1.0972\n",
            "Epoch 20/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8834 - mae: 1.0786 - val_loss: 1.8720 - val_mae: 1.0588\n",
            "Epoch 21/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8357 - mae: 1.0643 - val_loss: 1.8683 - val_mae: 1.0537\n",
            "Epoch 22/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8086 - mae: 1.0536 - val_loss: 1.8431 - val_mae: 1.0529\n",
            "Epoch 23/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7799 - mae: 1.0421 - val_loss: 1.9230 - val_mae: 1.0796\n",
            "Epoch 24/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7812 - mae: 1.0415 - val_loss: 1.8299 - val_mae: 1.0414\n",
            "Epoch 25/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7657 - mae: 1.0411 - val_loss: 2.0362 - val_mae: 1.0890\n",
            "Epoch 26/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7135 - mae: 1.0239 - val_loss: 1.7482 - val_mae: 1.0168\n",
            "Epoch 27/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7391 - mae: 1.0327 - val_loss: 1.7160 - val_mae: 1.0139\n",
            "Epoch 28/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6913 - mae: 1.0148 - val_loss: 1.7150 - val_mae: 1.0056\n",
            "Epoch 29/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6976 - mae: 1.0149 - val_loss: 1.7105 - val_mae: 1.0105\n",
            "Epoch 30/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7042 - mae: 1.0227 - val_loss: 1.7969 - val_mae: 1.0339\n",
            "Epoch 31/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6498 - mae: 1.0018 - val_loss: 1.6421 - val_mae: 0.9818\n",
            "Epoch 32/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6306 - mae: 0.9948 - val_loss: 1.6490 - val_mae: 0.9956\n",
            "Epoch 33/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6479 - mae: 0.9975 - val_loss: 1.6892 - val_mae: 1.0032\n",
            "Epoch 34/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6056 - mae: 0.9890 - val_loss: 1.7831 - val_mae: 1.0518\n",
            "Epoch 35/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6016 - mae: 0.9838 - val_loss: 1.8144 - val_mae: 1.0308\n",
            "Epoch 36/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6031 - mae: 0.9871 - val_loss: 1.6233 - val_mae: 0.9783\n",
            "Epoch 37/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6446 - mae: 0.9989 - val_loss: 1.6110 - val_mae: 0.9863\n",
            "Epoch 38/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5519 - mae: 0.9676 - val_loss: 1.5919 - val_mae: 0.9778\n",
            "Epoch 39/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5757 - mae: 0.9775 - val_loss: 1.6369 - val_mae: 0.9896\n",
            "Epoch 40/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5547 - mae: 0.9684 - val_loss: 1.6048 - val_mae: 0.9773\n",
            "Epoch 41/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5372 - mae: 0.9640 - val_loss: 1.5574 - val_mae: 0.9553\n",
            "Epoch 42/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5432 - mae: 0.9639 - val_loss: 1.5532 - val_mae: 0.9626\n",
            "Epoch 43/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5484 - mae: 0.9661 - val_loss: 1.5476 - val_mae: 0.9558\n",
            "Epoch 44/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5285 - mae: 0.9611 - val_loss: 1.6514 - val_mae: 0.9947\n",
            "Epoch 45/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5075 - mae: 0.9507 - val_loss: 1.5577 - val_mae: 0.9578\n",
            "Epoch 46/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4951 - mae: 0.9484 - val_loss: 1.7026 - val_mae: 1.0172\n",
            "Epoch 47/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5038 - mae: 0.9548 - val_loss: 1.5811 - val_mae: 0.9744\n",
            "Epoch 48/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4662 - mae: 0.9387 - val_loss: 1.5277 - val_mae: 0.9604\n",
            "Epoch 49/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5257 - mae: 0.9596 - val_loss: 1.7029 - val_mae: 0.9989\n",
            "Epoch 50/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4902 - mae: 0.9461 - val_loss: 1.5296 - val_mae: 0.9515\n",
            "Epoch 51/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4780 - mae: 0.9438 - val_loss: 1.7680 - val_mae: 1.0150\n",
            "Epoch 52/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4490 - mae: 0.9331 - val_loss: 1.5012 - val_mae: 0.9463\n",
            "Epoch 53/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5006 - mae: 0.9564 - val_loss: 1.6237 - val_mae: 0.9875\n",
            "Epoch 54/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4697 - mae: 0.9441 - val_loss: 1.6599 - val_mae: 0.9957\n",
            "Epoch 55/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4606 - mae: 0.9343 - val_loss: 1.6360 - val_mae: 0.9868\n",
            "Epoch 56/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4887 - mae: 0.9484 - val_loss: 1.6170 - val_mae: 0.9650\n",
            "Epoch 57/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4589 - mae: 0.9357 - val_loss: 1.5637 - val_mae: 0.9538\n",
            "Epoch 58/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4348 - mae: 0.9299 - val_loss: 1.5468 - val_mae: 0.9703\n",
            "Epoch 59/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4748 - mae: 0.9442 - val_loss: 1.5051 - val_mae: 0.9508\n",
            "Epoch 60/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4720 - mae: 0.9439 - val_loss: 1.4688 - val_mae: 0.9279\n",
            "Epoch 61/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4639 - mae: 0.9430 - val_loss: 1.5377 - val_mae: 0.9487\n",
            "Epoch 62/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4497 - mae: 0.9348 - val_loss: 1.4684 - val_mae: 0.9389\n",
            "Epoch 63/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4088 - mae: 0.9192 - val_loss: 1.4896 - val_mae: 0.9367\n",
            "Epoch 64/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4447 - mae: 0.9288 - val_loss: 1.4723 - val_mae: 0.9405\n",
            "Epoch 65/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4230 - mae: 0.9243 - val_loss: 1.6133 - val_mae: 1.0041\n",
            "Epoch 66/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4130 - mae: 0.9220 - val_loss: 1.5342 - val_mae: 0.9457\n",
            "Epoch 67/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4383 - mae: 0.9329 - val_loss: 1.5376 - val_mae: 0.9466\n",
            "Epoch 68/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4349 - mae: 0.9228 - val_loss: 1.4733 - val_mae: 0.9303\n",
            "Epoch 69/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4376 - mae: 0.9342 - val_loss: 1.4412 - val_mae: 0.9343\n",
            "Epoch 70/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4721 - mae: 0.9421 - val_loss: 1.4643 - val_mae: 0.9292\n",
            "Epoch 71/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3985 - mae: 0.9156 - val_loss: 1.4324 - val_mae: 0.9165\n",
            "Epoch 72/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3406 - mae: 0.8942 - val_loss: 1.4351 - val_mae: 0.9221\n",
            "Epoch 73/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3597 - mae: 0.9040 - val_loss: 1.6089 - val_mae: 0.9652\n",
            "Epoch 74/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3543 - mae: 0.9022 - val_loss: 1.4705 - val_mae: 0.9281\n",
            "Epoch 75/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3327 - mae: 0.8941 - val_loss: 1.5637 - val_mae: 0.9490\n",
            "Epoch 76/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3618 - mae: 0.9061 - val_loss: 1.5818 - val_mae: 0.9530\n",
            "Epoch 77/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3713 - mae: 0.9085 - val_loss: 1.4799 - val_mae: 0.9401\n",
            "Epoch 78/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3270 - mae: 0.8880 - val_loss: 1.3965 - val_mae: 0.9044\n",
            "Epoch 79/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3417 - mae: 0.8939 - val_loss: 1.4478 - val_mae: 0.9178\n",
            "Epoch 80/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3464 - mae: 0.8981 - val_loss: 1.5331 - val_mae: 0.9572\n",
            "Epoch 81/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3101 - mae: 0.8910 - val_loss: 1.4669 - val_mae: 0.9294\n",
            "Epoch 82/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3484 - mae: 0.8965 - val_loss: 1.4886 - val_mae: 0.9310\n",
            "Epoch 83/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3267 - mae: 0.8920 - val_loss: 1.4973 - val_mae: 0.9424\n",
            "Epoch 84/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3686 - mae: 0.9123 - val_loss: 1.4318 - val_mae: 0.9204\n",
            "Epoch 85/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3042 - mae: 0.8909 - val_loss: 1.4544 - val_mae: 0.9102\n",
            "Epoch 86/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2849 - mae: 0.8781 - val_loss: 1.7426 - val_mae: 0.9972\n",
            "Epoch 87/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3159 - mae: 0.8866 - val_loss: 1.4152 - val_mae: 0.9141\n",
            "Epoch 88/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2810 - mae: 0.8740 - val_loss: 1.4642 - val_mae: 0.9263\n",
            "Epoch 89/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2862 - mae: 0.8752 - val_loss: 1.4079 - val_mae: 0.9030\n",
            "Epoch 90/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2932 - mae: 0.8794 - val_loss: 1.3762 - val_mae: 0.8931\n",
            "Epoch 91/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3091 - mae: 0.8930 - val_loss: 1.4388 - val_mae: 0.9133\n",
            "Epoch 92/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2903 - mae: 0.8866 - val_loss: 1.3864 - val_mae: 0.8950\n",
            "Epoch 93/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2658 - mae: 0.8745 - val_loss: 1.3432 - val_mae: 0.8823\n",
            "Epoch 94/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2732 - mae: 0.8763 - val_loss: 1.3331 - val_mae: 0.8864\n",
            "Epoch 95/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2974 - mae: 0.8853 - val_loss: 1.3776 - val_mae: 0.8942\n",
            "Epoch 96/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2198 - mae: 0.8539 - val_loss: 1.3347 - val_mae: 0.8818\n",
            "Epoch 97/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2259 - mae: 0.8547 - val_loss: 1.3292 - val_mae: 0.8748\n",
            "Epoch 98/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2088 - mae: 0.8490 - val_loss: 1.3521 - val_mae: 0.8894\n",
            "Epoch 99/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2337 - mae: 0.8622 - val_loss: 1.5107 - val_mae: 0.9300\n",
            "Epoch 100/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2832 - mae: 0.8812 - val_loss: 1.3227 - val_mae: 0.8770\n",
            "Epoch 101/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2578 - mae: 0.8686 - val_loss: 1.3566 - val_mae: 0.8929\n",
            "Epoch 102/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2317 - mae: 0.8726 - val_loss: 1.3635 - val_mae: 0.8848\n",
            "Epoch 103/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2244 - mae: 0.8583 - val_loss: 1.3801 - val_mae: 0.8918\n",
            "Epoch 104/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1919 - mae: 0.8511 - val_loss: 1.4039 - val_mae: 0.8900\n",
            "Epoch 105/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2271 - mae: 0.8561 - val_loss: 1.3635 - val_mae: 0.8883\n",
            "Epoch 106/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.2130 - mae: 0.8600 - val_loss: 1.3981 - val_mae: 0.9242\n",
            "Epoch 107/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1983 - mae: 0.8526 - val_loss: 1.5475 - val_mae: 0.9730\n",
            "Epoch 108/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1758 - mae: 0.8428 - val_loss: 1.3061 - val_mae: 0.8686\n",
            "Epoch 109/1000\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 1.1404 - mae: 0.8255 - val_loss: 1.3114 - val_mae: 0.8690\n",
            "Epoch 110/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1609 - mae: 0.8312 - val_loss: 1.2716 - val_mae: 0.8582\n",
            "Epoch 111/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1472 - mae: 0.8334 - val_loss: 1.2509 - val_mae: 0.8525\n",
            "Epoch 112/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1237 - mae: 0.8203 - val_loss: 1.5637 - val_mae: 0.9555\n",
            "Epoch 113/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1988 - mae: 0.8532 - val_loss: 1.2453 - val_mae: 0.8553\n",
            "Epoch 114/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1401 - mae: 0.8267 - val_loss: 1.2995 - val_mae: 0.8654\n",
            "Epoch 115/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1162 - mae: 0.8160 - val_loss: 1.4018 - val_mae: 0.9221\n",
            "Epoch 116/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1820 - mae: 0.8499 - val_loss: 1.2890 - val_mae: 0.8607\n",
            "Epoch 117/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1130 - mae: 0.8187 - val_loss: 1.3234 - val_mae: 0.8724\n",
            "Epoch 118/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1188 - mae: 0.8182 - val_loss: 1.2442 - val_mae: 0.8582\n",
            "Epoch 119/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1403 - mae: 0.8293 - val_loss: 1.2556 - val_mae: 0.8602\n",
            "Epoch 120/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1330 - mae: 0.8240 - val_loss: 1.3759 - val_mae: 0.8850\n",
            "Epoch 121/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1630 - mae: 0.8273 - val_loss: 1.2887 - val_mae: 0.8566\n",
            "Epoch 122/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1001 - mae: 0.8105 - val_loss: 1.2532 - val_mae: 0.8466\n",
            "Epoch 123/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0734 - mae: 0.8059 - val_loss: 1.2516 - val_mae: 0.8507\n",
            "Epoch 124/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0872 - mae: 0.8091 - val_loss: 1.2032 - val_mae: 0.8317\n",
            "Epoch 125/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0754 - mae: 0.8060 - val_loss: 1.2455 - val_mae: 0.8451\n",
            "Epoch 126/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0363 - mae: 0.7871 - val_loss: 1.3441 - val_mae: 0.8725\n",
            "Epoch 127/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1264 - mae: 0.8220 - val_loss: 1.2292 - val_mae: 0.8391\n",
            "Epoch 128/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0232 - mae: 0.7850 - val_loss: 1.3158 - val_mae: 0.8618\n",
            "Epoch 129/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0710 - mae: 0.8010 - val_loss: 1.2475 - val_mae: 0.8440\n",
            "Epoch 130/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0383 - mae: 0.7970 - val_loss: 1.4415 - val_mae: 0.9290\n",
            "Epoch 131/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0941 - mae: 0.8141 - val_loss: 1.2373 - val_mae: 0.8448\n",
            "Epoch 132/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0592 - mae: 0.7955 - val_loss: 1.2265 - val_mae: 0.8382\n",
            "Epoch 133/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0139 - mae: 0.7799 - val_loss: 1.2606 - val_mae: 0.8395\n",
            "Epoch 134/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0468 - mae: 0.7921 - val_loss: 1.2504 - val_mae: 0.8491\n",
            "Epoch 135/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0164 - mae: 0.7779 - val_loss: 1.2364 - val_mae: 0.8440\n",
            "Epoch 136/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0085 - mae: 0.7794 - val_loss: 1.1988 - val_mae: 0.8319\n",
            "Epoch 137/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0178 - mae: 0.7908 - val_loss: 1.2102 - val_mae: 0.8409\n",
            "Epoch 138/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9741 - mae: 0.7667 - val_loss: 1.2663 - val_mae: 0.8543\n",
            "Epoch 139/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0151 - mae: 0.7855 - val_loss: 1.1775 - val_mae: 0.8303\n",
            "Epoch 140/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9812 - mae: 0.7698 - val_loss: 1.3018 - val_mae: 0.8654\n",
            "Epoch 141/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0524 - mae: 0.7968 - val_loss: 1.1947 - val_mae: 0.8266\n",
            "Epoch 142/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0191 - mae: 0.7874 - val_loss: 1.3211 - val_mae: 0.8719\n",
            "Epoch 143/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0111 - mae: 0.7831 - val_loss: 1.1819 - val_mae: 0.8206\n",
            "Epoch 144/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9715 - mae: 0.7662 - val_loss: 1.2138 - val_mae: 0.8333\n",
            "Epoch 145/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9718 - mae: 0.7609 - val_loss: 1.1844 - val_mae: 0.8252\n",
            "Epoch 146/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0069 - mae: 0.7775 - val_loss: 1.4562 - val_mae: 0.9291\n",
            "Epoch 147/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0227 - mae: 0.7841 - val_loss: 1.1750 - val_mae: 0.8214\n",
            "Epoch 148/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9684 - mae: 0.7658 - val_loss: 1.6303 - val_mae: 0.9763\n",
            "Epoch 149/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0557 - mae: 0.7994 - val_loss: 1.1314 - val_mae: 0.8116\n",
            "Epoch 150/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0099 - mae: 0.7831 - val_loss: 1.1687 - val_mae: 0.8294\n",
            "Epoch 151/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9431 - mae: 0.7556 - val_loss: 1.1271 - val_mae: 0.8013\n",
            "Epoch 152/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9012 - mae: 0.7358 - val_loss: 1.1862 - val_mae: 0.8202\n",
            "Epoch 153/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9656 - mae: 0.7625 - val_loss: 1.1675 - val_mae: 0.8268\n",
            "Epoch 154/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.9068 - mae: 0.7380 - val_loss: 1.2475 - val_mae: 0.8419\n",
            "Epoch 155/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0265 - mae: 0.7890 - val_loss: 1.3058 - val_mae: 0.8595\n",
            "Epoch 156/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9958 - mae: 0.7751 - val_loss: 1.2812 - val_mae: 0.8522\n",
            "Epoch 157/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9220 - mae: 0.7445 - val_loss: 1.2156 - val_mae: 0.8385\n",
            "Epoch 158/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9145 - mae: 0.7440 - val_loss: 1.1467 - val_mae: 0.8077\n",
            "Epoch 159/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9166 - mae: 0.7456 - val_loss: 1.2920 - val_mae: 0.8546\n",
            "Epoch 160/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8957 - mae: 0.7302 - val_loss: 1.2104 - val_mae: 0.8250\n",
            "Epoch 161/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9174 - mae: 0.7363 - val_loss: 1.1713 - val_mae: 0.8141\n",
            "Epoch 162/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9572 - mae: 0.7642 - val_loss: 1.2432 - val_mae: 0.8579\n",
            "Epoch 163/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8727 - mae: 0.7261 - val_loss: 1.1363 - val_mae: 0.8022\n",
            "Epoch 164/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8847 - mae: 0.7198 - val_loss: 1.1729 - val_mae: 0.8117\n",
            "Epoch 165/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9081 - mae: 0.7364 - val_loss: 1.1524 - val_mae: 0.8021\n",
            "Epoch 166/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9028 - mae: 0.7329 - val_loss: 1.1114 - val_mae: 0.7935\n",
            "Epoch 167/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8848 - mae: 0.7363 - val_loss: 1.1399 - val_mae: 0.8226\n",
            "Epoch 168/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9033 - mae: 0.7322 - val_loss: 1.1393 - val_mae: 0.8010\n",
            "Epoch 169/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8403 - mae: 0.7058 - val_loss: 1.1164 - val_mae: 0.7889\n",
            "Epoch 170/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8993 - mae: 0.7332 - val_loss: 1.4051 - val_mae: 0.9480\n",
            "Epoch 171/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9071 - mae: 0.7364 - val_loss: 1.1275 - val_mae: 0.8019\n",
            "Epoch 172/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8570 - mae: 0.7169 - val_loss: 1.2080 - val_mae: 0.8412\n",
            "Epoch 173/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8388 - mae: 0.7084 - val_loss: 1.0805 - val_mae: 0.7799\n",
            "Epoch 174/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8489 - mae: 0.7133 - val_loss: 1.1643 - val_mae: 0.8137\n",
            "Epoch 175/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8708 - mae: 0.7202 - val_loss: 1.1440 - val_mae: 0.8193\n",
            "Epoch 176/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8534 - mae: 0.7160 - val_loss: 1.0632 - val_mae: 0.7768\n",
            "Epoch 177/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8518 - mae: 0.7139 - val_loss: 1.3607 - val_mae: 0.9192\n",
            "Epoch 178/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8750 - mae: 0.7187 - val_loss: 1.0748 - val_mae: 0.7886\n",
            "Epoch 179/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8232 - mae: 0.6990 - val_loss: 1.0774 - val_mae: 0.7870\n",
            "Epoch 180/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8101 - mae: 0.6937 - val_loss: 1.1277 - val_mae: 0.8096\n",
            "Epoch 181/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8736 - mae: 0.7265 - val_loss: 1.1090 - val_mae: 0.7957\n",
            "Epoch 182/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8250 - mae: 0.7014 - val_loss: 1.0779 - val_mae: 0.7760\n",
            "Epoch 183/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8177 - mae: 0.7057 - val_loss: 1.0996 - val_mae: 0.7830\n",
            "Epoch 184/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7953 - mae: 0.6866 - val_loss: 1.1560 - val_mae: 0.7969\n",
            "Epoch 185/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8078 - mae: 0.6901 - val_loss: 1.1566 - val_mae: 0.8057\n",
            "Epoch 186/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8201 - mae: 0.6943 - val_loss: 1.1265 - val_mae: 0.8083\n",
            "Epoch 187/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.8200 - mae: 0.6968 - val_loss: 1.1797 - val_mae: 0.8222\n",
            "Epoch 188/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8070 - mae: 0.6926 - val_loss: 1.1210 - val_mae: 0.7957\n",
            "Epoch 189/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7841 - mae: 0.6834 - val_loss: 1.1792 - val_mae: 0.8142\n",
            "Epoch 190/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8053 - mae: 0.6968 - val_loss: 1.1474 - val_mae: 0.8205\n",
            "Epoch 191/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7879 - mae: 0.6841 - val_loss: 1.0882 - val_mae: 0.8049\n",
            "Epoch 192/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7844 - mae: 0.6820 - val_loss: 1.2068 - val_mae: 0.8188\n",
            "Epoch 193/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7760 - mae: 0.6742 - val_loss: 1.1498 - val_mae: 0.7963\n",
            "Epoch 194/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8186 - mae: 0.6965 - val_loss: 1.1690 - val_mae: 0.8112\n",
            "Epoch 195/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7606 - mae: 0.6756 - val_loss: 1.0814 - val_mae: 0.7891\n",
            "Epoch 196/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7703 - mae: 0.6719 - val_loss: 1.0771 - val_mae: 0.7826\n",
            "Epoch 197/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7708 - mae: 0.6780 - val_loss: 1.0726 - val_mae: 0.7864\n",
            "Epoch 198/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7329 - mae: 0.6600 - val_loss: 1.0216 - val_mae: 0.7727\n",
            "Epoch 199/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7960 - mae: 0.6904 - val_loss: 1.2383 - val_mae: 0.8288\n",
            "Epoch 200/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7480 - mae: 0.6673 - val_loss: 1.1265 - val_mae: 0.7956\n",
            "Epoch 201/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7412 - mae: 0.6600 - val_loss: 1.0337 - val_mae: 0.7636\n",
            "Epoch 202/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7543 - mae: 0.6691 - val_loss: 1.0553 - val_mae: 0.7661\n",
            "Epoch 203/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7356 - mae: 0.6593 - val_loss: 1.1493 - val_mae: 0.8042\n",
            "Epoch 204/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7420 - mae: 0.6682 - val_loss: 1.0882 - val_mae: 0.7908\n",
            "Epoch 205/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7590 - mae: 0.6716 - val_loss: 1.3321 - val_mae: 0.8884\n",
            "Epoch 206/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.7758 - mae: 0.6841 - val_loss: 0.9942 - val_mae: 0.7634\n",
            "Epoch 207/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7466 - mae: 0.6652 - val_loss: 1.0473 - val_mae: 0.7734\n",
            "Epoch 208/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7689 - mae: 0.6765 - val_loss: 1.1621 - val_mae: 0.8054\n",
            "Epoch 209/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7428 - mae: 0.6665 - val_loss: 1.1197 - val_mae: 0.7914\n",
            "Epoch 210/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7148 - mae: 0.6508 - val_loss: 1.0095 - val_mae: 0.7621\n",
            "Epoch 211/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6958 - mae: 0.6386 - val_loss: 1.0472 - val_mae: 0.7818\n",
            "Epoch 212/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7286 - mae: 0.6609 - val_loss: 1.0266 - val_mae: 0.7611\n",
            "Epoch 213/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6845 - mae: 0.6368 - val_loss: 1.0909 - val_mae: 0.7698\n",
            "Epoch 214/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6965 - mae: 0.6440 - val_loss: 1.0446 - val_mae: 0.7822\n",
            "Epoch 215/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7034 - mae: 0.6488 - val_loss: 0.9743 - val_mae: 0.7551\n",
            "Epoch 216/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6783 - mae: 0.6307 - val_loss: 1.0787 - val_mae: 0.7711\n",
            "Epoch 217/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6947 - mae: 0.6413 - val_loss: 1.2416 - val_mae: 0.8564\n",
            "Epoch 218/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7082 - mae: 0.6467 - val_loss: 1.0669 - val_mae: 0.7714\n",
            "Epoch 219/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6796 - mae: 0.6320 - val_loss: 1.0036 - val_mae: 0.7515\n",
            "Epoch 220/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6934 - mae: 0.6386 - val_loss: 0.9928 - val_mae: 0.7553\n",
            "Epoch 221/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7307 - mae: 0.6637 - val_loss: 1.0300 - val_mae: 0.7648\n",
            "Epoch 222/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6906 - mae: 0.6431 - val_loss: 1.0755 - val_mae: 0.7646\n",
            "Epoch 223/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7210 - mae: 0.6544 - val_loss: 1.0031 - val_mae: 0.7468\n",
            "Epoch 224/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6766 - mae: 0.6304 - val_loss: 1.0905 - val_mae: 0.7851\n",
            "Epoch 225/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6860 - mae: 0.6430 - val_loss: 1.0661 - val_mae: 0.7854\n",
            "Epoch 226/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6834 - mae: 0.6393 - val_loss: 0.9942 - val_mae: 0.7429\n",
            "Epoch 227/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6575 - mae: 0.6223 - val_loss: 0.9900 - val_mae: 0.7601\n",
            "Epoch 228/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6680 - mae: 0.6282 - val_loss: 0.9847 - val_mae: 0.7517\n",
            "Epoch 229/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7053 - mae: 0.6498 - val_loss: 1.1182 - val_mae: 0.7865\n",
            "Epoch 230/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6664 - mae: 0.6319 - val_loss: 1.0856 - val_mae: 0.7725\n",
            "Epoch 231/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7433 - mae: 0.6695 - val_loss: 1.0020 - val_mae: 0.7616\n",
            "Epoch 232/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6542 - mae: 0.6234 - val_loss: 0.9903 - val_mae: 0.7453\n",
            "Epoch 233/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6462 - mae: 0.6197 - val_loss: 0.9926 - val_mae: 0.7514\n",
            "Epoch 234/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6631 - mae: 0.6295 - val_loss: 0.9758 - val_mae: 0.7393\n",
            "Epoch 235/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6383 - mae: 0.6157 - val_loss: 1.2740 - val_mae: 0.8595\n",
            "Epoch 236/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6428 - mae: 0.6193 - val_loss: 0.9909 - val_mae: 0.7617\n",
            "Epoch 237/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6264 - mae: 0.6111 - val_loss: 1.0766 - val_mae: 0.7874\n",
            "Epoch 238/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6367 - mae: 0.6178 - val_loss: 1.0064 - val_mae: 0.7522\n",
            "Epoch 239/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6073 - mae: 0.6007 - val_loss: 0.9596 - val_mae: 0.7213\n",
            "Epoch 240/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6285 - mae: 0.6078 - val_loss: 1.0668 - val_mae: 0.7712\n",
            "Epoch 241/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6223 - mae: 0.6085 - val_loss: 1.0373 - val_mae: 0.7877\n",
            "Epoch 242/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6192 - mae: 0.6075 - val_loss: 0.9828 - val_mae: 0.7513\n",
            "Epoch 243/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6359 - mae: 0.6163 - val_loss: 1.0430 - val_mae: 0.7572\n",
            "Epoch 244/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6211 - mae: 0.6101 - val_loss: 1.0479 - val_mae: 0.7896\n",
            "Epoch 245/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6469 - mae: 0.6221 - val_loss: 0.9672 - val_mae: 0.7311\n",
            "Epoch 246/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6036 - mae: 0.5962 - val_loss: 0.9685 - val_mae: 0.7434\n",
            "Epoch 247/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6036 - mae: 0.5986 - val_loss: 0.9731 - val_mae: 0.7397\n",
            "Epoch 248/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6239 - mae: 0.6151 - val_loss: 1.0923 - val_mae: 0.7734\n",
            "Epoch 249/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6160 - mae: 0.6069 - val_loss: 1.1208 - val_mae: 0.7817\n",
            "Epoch 250/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6757 - mae: 0.6390 - val_loss: 1.0324 - val_mae: 0.7652\n",
            "Epoch 251/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5852 - mae: 0.5873 - val_loss: 1.0240 - val_mae: 0.7547\n",
            "Epoch 252/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6129 - mae: 0.6045 - val_loss: 1.0654 - val_mae: 0.7634\n",
            "Epoch 253/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5920 - mae: 0.5955 - val_loss: 0.9584 - val_mae: 0.7255\n",
            "Epoch 254/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6102 - mae: 0.6031 - val_loss: 0.9532 - val_mae: 0.7323\n",
            "Epoch 255/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6075 - mae: 0.6022 - val_loss: 0.9908 - val_mae: 0.7369\n",
            "Epoch 256/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5951 - mae: 0.5940 - val_loss: 0.9668 - val_mae: 0.7332\n",
            "Epoch 257/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5859 - mae: 0.5914 - val_loss: 0.9542 - val_mae: 0.7407\n",
            "Epoch 258/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5659 - mae: 0.5777 - val_loss: 1.0837 - val_mae: 0.7908\n",
            "Epoch 259/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6123 - mae: 0.6025 - val_loss: 1.0097 - val_mae: 0.7377\n",
            "Epoch 260/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5751 - mae: 0.5825 - val_loss: 1.0055 - val_mae: 0.7543\n",
            "Epoch 261/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5957 - mae: 0.5934 - val_loss: 1.0168 - val_mae: 0.7541\n",
            "Epoch 262/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5744 - mae: 0.5843 - val_loss: 1.0649 - val_mae: 0.7972\n",
            "Epoch 263/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5639 - mae: 0.5783 - val_loss: 1.0272 - val_mae: 0.7455\n",
            "Epoch 264/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5848 - mae: 0.5875 - val_loss: 0.9786 - val_mae: 0.7417\n",
            "Epoch 265/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5515 - mae: 0.5720 - val_loss: 1.0268 - val_mae: 0.7548\n",
            "Epoch 266/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5546 - mae: 0.5749 - val_loss: 0.9455 - val_mae: 0.7320\n",
            "Epoch 267/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5775 - mae: 0.5882 - val_loss: 1.0310 - val_mae: 0.7728\n",
            "Epoch 268/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5575 - mae: 0.5773 - val_loss: 0.9835 - val_mae: 0.7381\n",
            "Epoch 269/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5555 - mae: 0.5770 - val_loss: 0.9940 - val_mae: 0.7598\n",
            "Epoch 270/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5387 - mae: 0.5625 - val_loss: 0.9383 - val_mae: 0.7221\n",
            "Epoch 271/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5352 - mae: 0.5668 - val_loss: 0.9154 - val_mae: 0.7193\n",
            "Epoch 272/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5395 - mae: 0.5647 - val_loss: 0.9650 - val_mae: 0.7418\n",
            "Epoch 273/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5508 - mae: 0.5735 - val_loss: 0.9127 - val_mae: 0.7167\n",
            "Epoch 274/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5544 - mae: 0.5715 - val_loss: 0.9178 - val_mae: 0.7325\n",
            "Epoch 275/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5284 - mae: 0.5554 - val_loss: 0.9868 - val_mae: 0.7464\n",
            "Epoch 276/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5456 - mae: 0.5675 - val_loss: 0.9508 - val_mae: 0.7382\n",
            "Epoch 277/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5471 - mae: 0.5736 - val_loss: 0.9359 - val_mae: 0.7396\n",
            "Epoch 278/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5794 - mae: 0.5892 - val_loss: 1.0246 - val_mae: 0.7835\n",
            "Epoch 279/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5319 - mae: 0.5645 - val_loss: 0.9990 - val_mae: 0.7417\n",
            "Epoch 280/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5348 - mae: 0.5645 - val_loss: 0.9775 - val_mae: 0.7540\n",
            "Epoch 281/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5784 - mae: 0.5856 - val_loss: 1.0473 - val_mae: 0.7539\n",
            "Epoch 282/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5183 - mae: 0.5542 - val_loss: 1.0087 - val_mae: 0.7409\n",
            "Epoch 283/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5131 - mae: 0.5528 - val_loss: 0.9713 - val_mae: 0.7320\n",
            "Epoch 284/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5300 - mae: 0.5641 - val_loss: 0.9886 - val_mae: 0.7556\n",
            "Epoch 285/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4997 - mae: 0.5480 - val_loss: 0.9450 - val_mae: 0.7391\n",
            "Epoch 286/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5259 - mae: 0.5606 - val_loss: 1.0182 - val_mae: 0.7492\n",
            "Epoch 287/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5115 - mae: 0.5493 - val_loss: 1.0102 - val_mae: 0.7412\n",
            "Epoch 288/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5143 - mae: 0.5525 - val_loss: 1.0279 - val_mae: 0.7622\n",
            "Epoch 289/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4814 - mae: 0.5378 - val_loss: 1.0083 - val_mae: 0.7463\n",
            "Epoch 290/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5145 - mae: 0.5507 - val_loss: 1.0266 - val_mae: 0.7539\n",
            "Epoch 291/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5431 - mae: 0.5729 - val_loss: 1.2179 - val_mae: 0.8551\n",
            "Epoch 292/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5201 - mae: 0.5580 - val_loss: 0.9241 - val_mae: 0.7230\n",
            "Epoch 293/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5519 - mae: 0.5738 - val_loss: 0.9830 - val_mae: 0.7381\n",
            "Epoch 294/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5058 - mae: 0.5505 - val_loss: 1.0055 - val_mae: 0.7526\n",
            "Epoch 295/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5193 - mae: 0.5595 - val_loss: 1.0432 - val_mae: 0.7722\n",
            "Epoch 296/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5056 - mae: 0.5505 - val_loss: 0.9487 - val_mae: 0.7350\n",
            "Epoch 297/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4789 - mae: 0.5365 - val_loss: 1.0531 - val_mae: 0.7662\n",
            "Epoch 298/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4756 - mae: 0.5348 - val_loss: 1.0023 - val_mae: 0.7576\n",
            "Epoch 299/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4863 - mae: 0.5383 - val_loss: 0.9483 - val_mae: 0.7229\n",
            "Epoch 300/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5060 - mae: 0.5527 - val_loss: 1.0733 - val_mae: 0.7883\n",
            "Epoch 301/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4962 - mae: 0.5438 - val_loss: 0.9717 - val_mae: 0.7325\n",
            "Epoch 302/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4941 - mae: 0.5385 - val_loss: 0.9540 - val_mae: 0.7272\n",
            "Epoch 303/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4827 - mae: 0.5385 - val_loss: 0.9930 - val_mae: 0.7429\n",
            "Epoch 304/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4622 - mae: 0.5263 - val_loss: 0.9794 - val_mae: 0.7405\n",
            "Epoch 305/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4672 - mae: 0.5302 - val_loss: 0.9891 - val_mae: 0.7342\n",
            "Epoch 306/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4817 - mae: 0.5404 - val_loss: 1.0114 - val_mae: 0.7720\n",
            "Epoch 307/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5367 - mae: 0.5657 - val_loss: 0.9638 - val_mae: 0.7282\n",
            "Epoch 308/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4697 - mae: 0.5291 - val_loss: 1.0914 - val_mae: 0.7925\n",
            "Epoch 309/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4546 - mae: 0.5210 - val_loss: 0.9844 - val_mae: 0.7422\n",
            "Epoch 310/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4581 - mae: 0.5222 - val_loss: 0.9837 - val_mae: 0.7427\n",
            "Epoch 311/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4712 - mae: 0.5312 - val_loss: 0.9511 - val_mae: 0.7233\n",
            "Epoch 312/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4553 - mae: 0.5216 - val_loss: 0.9598 - val_mae: 0.7290\n",
            "Epoch 313/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4672 - mae: 0.5263 - val_loss: 0.9945 - val_mae: 0.7318\n",
            "Epoch 314/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4751 - mae: 0.5257 - val_loss: 0.9396 - val_mae: 0.7341\n",
            "Epoch 315/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4536 - mae: 0.5200 - val_loss: 0.9392 - val_mae: 0.7175\n",
            "Epoch 316/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4513 - mae: 0.5175 - val_loss: 1.0083 - val_mae: 0.7463\n",
            "Epoch 317/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4532 - mae: 0.5232 - val_loss: 1.2901 - val_mae: 0.8768\n",
            "Epoch 318/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4760 - mae: 0.5352 - val_loss: 1.0877 - val_mae: 0.7682\n",
            "Epoch 319/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4435 - mae: 0.5114 - val_loss: 0.9418 - val_mae: 0.7214\n",
            "Epoch 320/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4527 - mae: 0.5194 - val_loss: 1.0465 - val_mae: 0.7391\n",
            "Epoch 321/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4510 - mae: 0.5208 - val_loss: 0.9327 - val_mae: 0.7246\n",
            "Epoch 322/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4474 - mae: 0.5214 - val_loss: 1.0487 - val_mae: 0.7472\n",
            "Epoch 323/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4467 - mae: 0.5118 - val_loss: 0.9051 - val_mae: 0.7116\n",
            "Epoch 324/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4522 - mae: 0.5213 - val_loss: 0.9859 - val_mae: 0.7296\n",
            "Epoch 325/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4536 - mae: 0.5191 - val_loss: 0.9425 - val_mae: 0.7221\n",
            "Epoch 326/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4210 - mae: 0.5048 - val_loss: 0.9666 - val_mae: 0.7392\n",
            "Epoch 327/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4537 - mae: 0.5265 - val_loss: 0.9751 - val_mae: 0.7474\n",
            "Epoch 328/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4477 - mae: 0.5158 - val_loss: 0.9372 - val_mae: 0.7183\n",
            "Epoch 329/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4529 - mae: 0.5199 - val_loss: 0.9140 - val_mae: 0.7083\n",
            "Epoch 330/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4314 - mae: 0.5046 - val_loss: 1.0397 - val_mae: 0.7478\n",
            "Epoch 331/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4180 - mae: 0.4987 - val_loss: 1.0332 - val_mae: 0.7596\n",
            "Epoch 332/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4537 - mae: 0.5222 - val_loss: 0.9790 - val_mae: 0.7451\n",
            "Epoch 333/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4281 - mae: 0.5061 - val_loss: 0.9418 - val_mae: 0.7236\n",
            "Epoch 334/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4157 - mae: 0.5006 - val_loss: 1.0139 - val_mae: 0.7450\n",
            "Epoch 335/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4599 - mae: 0.5262 - val_loss: 0.9494 - val_mae: 0.7315\n",
            "Epoch 336/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4152 - mae: 0.4987 - val_loss: 0.9709 - val_mae: 0.7541\n",
            "Epoch 337/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4308 - mae: 0.5098 - val_loss: 1.0058 - val_mae: 0.7400\n",
            "Epoch 338/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4163 - mae: 0.4969 - val_loss: 1.0597 - val_mae: 0.7734\n",
            "Epoch 339/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4044 - mae: 0.4926 - val_loss: 0.9583 - val_mae: 0.7316\n",
            "Epoch 340/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4218 - mae: 0.5022 - val_loss: 0.9137 - val_mae: 0.7107\n",
            "Epoch 341/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4052 - mae: 0.4919 - val_loss: 0.9720 - val_mae: 0.7478\n",
            "Epoch 342/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4381 - mae: 0.5133 - val_loss: 1.0104 - val_mae: 0.7513\n",
            "Epoch 343/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4025 - mae: 0.4935 - val_loss: 0.9356 - val_mae: 0.7212\n",
            "Epoch 344/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4002 - mae: 0.4878 - val_loss: 0.9263 - val_mae: 0.7155\n",
            "Epoch 345/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4130 - mae: 0.4946 - val_loss: 0.9998 - val_mae: 0.7495\n",
            "Epoch 346/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3937 - mae: 0.4834 - val_loss: 1.0236 - val_mae: 0.7546\n",
            "Epoch 347/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3849 - mae: 0.4767 - val_loss: 0.9248 - val_mae: 0.7114\n",
            "Epoch 348/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4366 - mae: 0.5107 - val_loss: 1.0577 - val_mae: 0.7635\n",
            "Epoch 349/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3819 - mae: 0.4777 - val_loss: 0.9860 - val_mae: 0.7393\n",
            "Epoch 350/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3887 - mae: 0.4821 - val_loss: 0.9625 - val_mae: 0.7262\n",
            "Epoch 351/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4024 - mae: 0.4894 - val_loss: 0.9335 - val_mae: 0.7133\n",
            "Epoch 352/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3964 - mae: 0.4866 - val_loss: 0.9430 - val_mae: 0.7343\n",
            "Epoch 353/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3900 - mae: 0.4840 - val_loss: 0.9175 - val_mae: 0.7106\n",
            "Epoch 354/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4211 - mae: 0.5047 - val_loss: 0.9385 - val_mae: 0.7014\n",
            "Epoch 355/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3891 - mae: 0.4834 - val_loss: 0.9389 - val_mae: 0.7157\n",
            "Epoch 356/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4077 - mae: 0.4975 - val_loss: 1.0591 - val_mae: 0.7663\n",
            "Epoch 357/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4044 - mae: 0.4941 - val_loss: 0.9239 - val_mae: 0.7094\n",
            "Epoch 358/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4293 - mae: 0.5131 - val_loss: 1.1535 - val_mae: 0.8084\n",
            "Epoch 359/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4011 - mae: 0.4951 - val_loss: 1.0038 - val_mae: 0.7431\n",
            "Epoch 360/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3942 - mae: 0.4864 - val_loss: 0.9751 - val_mae: 0.7402\n",
            "Epoch 361/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3707 - mae: 0.4686 - val_loss: 0.9398 - val_mae: 0.7290\n",
            "Epoch 362/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3782 - mae: 0.4773 - val_loss: 0.9432 - val_mae: 0.7218\n",
            "Epoch 363/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3913 - mae: 0.4855 - val_loss: 0.9218 - val_mae: 0.7299\n",
            "Epoch 364/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3950 - mae: 0.4857 - val_loss: 0.9317 - val_mae: 0.7065\n",
            "Epoch 365/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3801 - mae: 0.4780 - val_loss: 0.9507 - val_mae: 0.7061\n",
            "Epoch 366/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3731 - mae: 0.4744 - val_loss: 0.9627 - val_mae: 0.7278\n",
            "Epoch 367/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3909 - mae: 0.4811 - val_loss: 0.9021 - val_mae: 0.7040\n",
            "Epoch 368/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3643 - mae: 0.4673 - val_loss: 1.0086 - val_mae: 0.7314\n",
            "Epoch 369/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3595 - mae: 0.4625 - val_loss: 1.0315 - val_mae: 0.7871\n",
            "Epoch 370/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3581 - mae: 0.4617 - val_loss: 0.9742 - val_mae: 0.7238\n",
            "Epoch 371/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3596 - mae: 0.4666 - val_loss: 0.9209 - val_mae: 0.7074\n",
            "Epoch 372/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3639 - mae: 0.4661 - val_loss: 0.9628 - val_mae: 0.7122\n",
            "Epoch 373/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3507 - mae: 0.4562 - val_loss: 1.0768 - val_mae: 0.7801\n",
            "Epoch 374/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4207 - mae: 0.5011 - val_loss: 1.0578 - val_mae: 0.7662\n",
            "Epoch 375/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3523 - mae: 0.4577 - val_loss: 0.9802 - val_mae: 0.7327\n",
            "Epoch 376/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3561 - mae: 0.4612 - val_loss: 0.9315 - val_mae: 0.7119\n",
            "Epoch 377/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3824 - mae: 0.4804 - val_loss: 0.9345 - val_mae: 0.7157\n",
            "Epoch 378/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3594 - mae: 0.4674 - val_loss: 0.9797 - val_mae: 0.7249\n",
            "Epoch 379/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3590 - mae: 0.4598 - val_loss: 0.9377 - val_mae: 0.7316\n",
            "Epoch 380/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3560 - mae: 0.4627 - val_loss: 0.9164 - val_mae: 0.7036\n",
            "Epoch 381/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3334 - mae: 0.4442 - val_loss: 0.9141 - val_mae: 0.7031\n",
            "Epoch 382/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3399 - mae: 0.4497 - val_loss: 0.9178 - val_mae: 0.7227\n",
            "Epoch 383/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3512 - mae: 0.4538 - val_loss: 0.9422 - val_mae: 0.7136\n",
            "Epoch 384/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3283 - mae: 0.4467 - val_loss: 0.9154 - val_mae: 0.7025\n",
            "Epoch 385/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3316 - mae: 0.4439 - val_loss: 0.9708 - val_mae: 0.7228\n",
            "Epoch 386/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3549 - mae: 0.4573 - val_loss: 0.8908 - val_mae: 0.7044\n",
            "Epoch 387/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3645 - mae: 0.4644 - val_loss: 0.9119 - val_mae: 0.7089\n",
            "Epoch 388/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3646 - mae: 0.4657 - val_loss: 0.8900 - val_mae: 0.7077\n",
            "Epoch 389/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3196 - mae: 0.4339 - val_loss: 0.9243 - val_mae: 0.7019\n",
            "Epoch 390/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.4445 - val_loss: 0.8953 - val_mae: 0.6953\n",
            "Epoch 391/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3190 - mae: 0.4344 - val_loss: 0.9515 - val_mae: 0.7120\n",
            "Epoch 392/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3192 - mae: 0.4346 - val_loss: 0.9213 - val_mae: 0.7073\n",
            "Epoch 393/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3156 - mae: 0.4306 - val_loss: 0.9261 - val_mae: 0.7142\n",
            "Epoch 394/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3065 - mae: 0.4275 - val_loss: 0.9310 - val_mae: 0.7067\n",
            "Epoch 395/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3138 - mae: 0.4294 - val_loss: 0.9496 - val_mae: 0.7228\n",
            "Epoch 396/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3531 - mae: 0.4615 - val_loss: 0.9874 - val_mae: 0.7330\n",
            "Epoch 397/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3242 - mae: 0.4358 - val_loss: 0.9009 - val_mae: 0.6939\n",
            "Epoch 398/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3317 - mae: 0.4459 - val_loss: 0.9294 - val_mae: 0.7193\n",
            "Epoch 399/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3262 - mae: 0.4392 - val_loss: 0.9177 - val_mae: 0.7045\n",
            "Epoch 400/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3116 - mae: 0.4305 - val_loss: 0.9116 - val_mae: 0.7018\n",
            "Epoch 401/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3057 - mae: 0.4228 - val_loss: 0.9422 - val_mae: 0.7144\n",
            "Epoch 402/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3004 - mae: 0.4187 - val_loss: 0.9660 - val_mae: 0.7205\n",
            "Epoch 403/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3084 - mae: 0.4270 - val_loss: 0.8813 - val_mae: 0.6919\n",
            "Epoch 404/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3233 - mae: 0.4389 - val_loss: 0.9261 - val_mae: 0.7154\n",
            "Epoch 405/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3120 - mae: 0.4275 - val_loss: 0.9056 - val_mae: 0.7043\n",
            "Epoch 406/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2951 - mae: 0.4154 - val_loss: 0.9287 - val_mae: 0.7144\n",
            "Epoch 407/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3160 - mae: 0.4301 - val_loss: 0.9676 - val_mae: 0.7104\n",
            "Epoch 408/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3207 - mae: 0.4344 - val_loss: 0.8962 - val_mae: 0.6871\n",
            "Epoch 409/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3168 - mae: 0.4327 - val_loss: 0.9571 - val_mae: 0.7242\n",
            "Epoch 410/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2978 - mae: 0.4213 - val_loss: 0.9428 - val_mae: 0.7210\n",
            "Epoch 411/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2938 - mae: 0.4163 - val_loss: 0.9483 - val_mae: 0.7162\n",
            "Epoch 412/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3001 - mae: 0.4155 - val_loss: 0.9442 - val_mae: 0.7091\n",
            "Epoch 413/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3191 - mae: 0.4331 - val_loss: 0.9073 - val_mae: 0.7048\n",
            "Epoch 414/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3066 - mae: 0.4324 - val_loss: 1.0803 - val_mae: 0.7683\n",
            "Epoch 415/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3211 - mae: 0.4411 - val_loss: 0.9671 - val_mae: 0.7375\n",
            "Epoch 416/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3148 - mae: 0.4351 - val_loss: 0.9479 - val_mae: 0.7210\n",
            "Epoch 417/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2898 - mae: 0.4156 - val_loss: 0.9256 - val_mae: 0.6988\n",
            "Epoch 418/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3059 - mae: 0.4237 - val_loss: 1.0664 - val_mae: 0.7788\n",
            "Epoch 419/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3104 - mae: 0.4307 - val_loss: 0.9434 - val_mae: 0.7203\n",
            "Epoch 420/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2886 - mae: 0.4133 - val_loss: 0.9065 - val_mae: 0.7035\n",
            "Epoch 421/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2970 - mae: 0.4192 - val_loss: 0.8916 - val_mae: 0.7004\n",
            "Epoch 422/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2865 - mae: 0.4141 - val_loss: 0.8962 - val_mae: 0.6943\n",
            "Epoch 423/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2827 - mae: 0.4072 - val_loss: 0.9087 - val_mae: 0.6982\n",
            "Epoch 424/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2880 - mae: 0.4161 - val_loss: 0.9193 - val_mae: 0.7138\n",
            "Epoch 425/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2802 - mae: 0.4032 - val_loss: 1.0462 - val_mae: 0.7664\n",
            "Epoch 426/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2897 - mae: 0.4123 - val_loss: 0.8991 - val_mae: 0.6935\n",
            "Epoch 427/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2773 - mae: 0.4067 - val_loss: 0.9284 - val_mae: 0.7045\n",
            "Epoch 428/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2711 - mae: 0.3981 - val_loss: 0.8969 - val_mae: 0.7003\n",
            "Epoch 429/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2778 - mae: 0.4066 - val_loss: 0.9371 - val_mae: 0.7152\n",
            "Epoch 430/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2847 - mae: 0.4102 - val_loss: 0.9318 - val_mae: 0.7097\n",
            "Epoch 431/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2854 - mae: 0.4120 - val_loss: 0.9285 - val_mae: 0.7048\n",
            "Epoch 432/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2968 - mae: 0.4160 - val_loss: 1.0285 - val_mae: 0.7471\n",
            "Epoch 433/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2946 - mae: 0.4147 - val_loss: 0.9833 - val_mae: 0.7265\n",
            "Epoch 434/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2704 - mae: 0.3975 - val_loss: 0.9253 - val_mae: 0.7031\n",
            "Epoch 435/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3057 - mae: 0.4281 - val_loss: 0.9605 - val_mae: 0.7258\n",
            "Epoch 436/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3013 - mae: 0.4235 - val_loss: 0.9080 - val_mae: 0.7163\n",
            "Epoch 437/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2859 - mae: 0.4172 - val_loss: 0.9249 - val_mae: 0.7047\n",
            "Epoch 438/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2643 - mae: 0.3966 - val_loss: 1.0049 - val_mae: 0.7631\n",
            "Epoch 439/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2642 - mae: 0.3923 - val_loss: 0.9204 - val_mae: 0.7020\n",
            "Epoch 440/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3208 - mae: 0.4402 - val_loss: 0.9175 - val_mae: 0.7180\n",
            "Epoch 441/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2796 - mae: 0.4096 - val_loss: 0.9003 - val_mae: 0.6948\n",
            "Epoch 442/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2671 - mae: 0.3971 - val_loss: 0.9651 - val_mae: 0.7119\n",
            "Epoch 443/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2712 - mae: 0.4025 - val_loss: 1.0353 - val_mae: 0.7590\n",
            "Epoch 444/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2758 - mae: 0.4100 - val_loss: 0.8981 - val_mae: 0.6951\n",
            "Epoch 445/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2666 - mae: 0.3946 - val_loss: 0.9354 - val_mae: 0.7145\n",
            "Epoch 446/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2660 - mae: 0.3963 - val_loss: 0.9813 - val_mae: 0.7228\n",
            "Epoch 447/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2632 - mae: 0.3911 - val_loss: 0.9568 - val_mae: 0.7135\n",
            "Epoch 448/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2656 - mae: 0.3977 - val_loss: 0.9536 - val_mae: 0.7275\n",
            "Epoch 449/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2656 - mae: 0.3911 - val_loss: 1.0306 - val_mae: 0.7541\n",
            "Epoch 450/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2480 - mae: 0.3802 - val_loss: 0.9238 - val_mae: 0.7057\n",
            "Epoch 451/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2670 - mae: 0.3991 - val_loss: 0.9150 - val_mae: 0.6995\n",
            "Epoch 452/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2542 - mae: 0.3883 - val_loss: 0.9353 - val_mae: 0.7068\n",
            "Epoch 453/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2812 - mae: 0.4111 - val_loss: 0.9060 - val_mae: 0.6906\n",
            "Epoch 454/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2701 - mae: 0.4002 - val_loss: 0.9333 - val_mae: 0.7208\n",
            "Epoch 455/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2603 - mae: 0.3912 - val_loss: 0.8932 - val_mae: 0.6900\n",
            "Epoch 456/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2525 - mae: 0.3857 - val_loss: 0.9684 - val_mae: 0.7303\n",
            "Epoch 457/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2414 - mae: 0.3730 - val_loss: 0.9452 - val_mae: 0.7131\n",
            "Epoch 458/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2380 - mae: 0.3740 - val_loss: 0.9070 - val_mae: 0.7071\n",
            "Epoch 459/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2422 - mae: 0.3739 - val_loss: 0.9072 - val_mae: 0.6971\n",
            "Epoch 460/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2402 - mae: 0.3719 - val_loss: 0.9404 - val_mae: 0.7169\n",
            "Epoch 461/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2402 - mae: 0.3745 - val_loss: 0.9095 - val_mae: 0.7004\n",
            "Epoch 462/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2415 - mae: 0.3745 - val_loss: 0.9548 - val_mae: 0.7247\n",
            "Epoch 463/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2448 - mae: 0.3767 - val_loss: 0.8826 - val_mae: 0.6872\n",
            "Epoch 464/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2473 - mae: 0.3822 - val_loss: 0.9528 - val_mae: 0.7280\n",
            "Epoch 465/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2332 - mae: 0.3695 - val_loss: 0.9894 - val_mae: 0.7247\n",
            "Epoch 466/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2368 - mae: 0.3731 - val_loss: 0.9091 - val_mae: 0.7086\n",
            "Epoch 467/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2463 - mae: 0.3809 - val_loss: 0.9568 - val_mae: 0.7148\n",
            "Epoch 468/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2413 - mae: 0.3721 - val_loss: 0.9725 - val_mae: 0.7351\n",
            "Epoch 469/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2434 - mae: 0.3795 - val_loss: 0.9500 - val_mae: 0.7245\n",
            "Epoch 470/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2379 - mae: 0.3721 - val_loss: 0.9232 - val_mae: 0.7024\n",
            "Epoch 471/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2560 - mae: 0.3878 - val_loss: 0.8891 - val_mae: 0.6993\n",
            "Epoch 472/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2444 - mae: 0.3802 - val_loss: 0.9284 - val_mae: 0.7204\n",
            "Epoch 473/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2440 - mae: 0.3815 - val_loss: 0.9333 - val_mae: 0.6974\n",
            "Epoch 474/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2322 - mae: 0.3701 - val_loss: 0.9386 - val_mae: 0.7049\n",
            "Epoch 475/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2421 - mae: 0.3785 - val_loss: 0.9308 - val_mae: 0.7051\n",
            "Epoch 476/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2205 - mae: 0.3593 - val_loss: 0.9178 - val_mae: 0.7056\n",
            "Epoch 477/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2408 - mae: 0.3773 - val_loss: 0.9738 - val_mae: 0.7321\n",
            "Epoch 478/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2228 - mae: 0.3584 - val_loss: 0.9036 - val_mae: 0.6965\n",
            "Epoch 479/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2218 - mae: 0.3573 - val_loss: 0.8988 - val_mae: 0.6937\n",
            "Epoch 480/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2325 - mae: 0.3711 - val_loss: 0.8854 - val_mae: 0.6899\n",
            "Epoch 481/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2341 - mae: 0.3709 - val_loss: 0.9304 - val_mae: 0.7009\n",
            "Epoch 482/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2189 - mae: 0.3589 - val_loss: 0.9289 - val_mae: 0.6956\n",
            "Epoch 483/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2452 - mae: 0.3807 - val_loss: 0.9324 - val_mae: 0.7107\n",
            "Epoch 484/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2124 - mae: 0.3500 - val_loss: 0.9082 - val_mae: 0.6915\n",
            "Epoch 485/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2290 - mae: 0.3659 - val_loss: 0.9487 - val_mae: 0.7204\n",
            "Epoch 486/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2171 - mae: 0.3570 - val_loss: 0.8918 - val_mae: 0.7051\n",
            "Epoch 487/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2244 - mae: 0.3611 - val_loss: 0.9099 - val_mae: 0.6995\n",
            "Epoch 488/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2169 - mae: 0.3607 - val_loss: 0.9353 - val_mae: 0.7179\n",
            "Epoch 489/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2222 - mae: 0.3613 - val_loss: 0.9139 - val_mae: 0.7024\n",
            "Epoch 490/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2075 - mae: 0.3491 - val_loss: 0.9499 - val_mae: 0.7194\n",
            "Epoch 491/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2139 - mae: 0.3522 - val_loss: 0.9634 - val_mae: 0.7125\n",
            "Epoch 492/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2151 - mae: 0.3553 - val_loss: 0.9122 - val_mae: 0.7088\n",
            "Epoch 493/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2290 - mae: 0.3687 - val_loss: 0.9103 - val_mae: 0.7036\n",
            "Epoch 494/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2097 - mae: 0.3502 - val_loss: 0.9201 - val_mae: 0.7096\n",
            "Epoch 495/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2206 - mae: 0.3617 - val_loss: 0.9272 - val_mae: 0.7096\n",
            "Epoch 496/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2079 - mae: 0.3497 - val_loss: 0.9217 - val_mae: 0.6954\n",
            "Epoch 497/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2154 - mae: 0.3539 - val_loss: 0.9022 - val_mae: 0.6968\n",
            "Epoch 498/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2222 - mae: 0.3640 - val_loss: 0.9230 - val_mae: 0.7049\n",
            "Epoch 499/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2015 - mae: 0.3425 - val_loss: 0.8880 - val_mae: 0.6848\n",
            "Epoch 500/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2368 - mae: 0.3725 - val_loss: 0.9683 - val_mae: 0.7296\n",
            "Epoch 501/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2117 - mae: 0.3537 - val_loss: 0.9728 - val_mae: 0.7270\n",
            "Epoch 502/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2249 - mae: 0.3673 - val_loss: 0.9844 - val_mae: 0.7360\n",
            "Epoch 503/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1927 - mae: 0.3340 - val_loss: 0.9314 - val_mae: 0.7095\n",
            "Epoch 504/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1922 - mae: 0.3377 - val_loss: 0.8836 - val_mae: 0.6871\n",
            "Epoch 505/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2209 - mae: 0.3580 - val_loss: 0.9151 - val_mae: 0.7088\n",
            "Epoch 506/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2217 - mae: 0.3609 - val_loss: 0.8788 - val_mae: 0.6957\n",
            "Epoch 507/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1851 - mae: 0.3268 - val_loss: 0.8726 - val_mae: 0.6975\n",
            "Epoch 508/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1898 - mae: 0.3323 - val_loss: 0.9285 - val_mae: 0.7144\n",
            "Epoch 509/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1914 - mae: 0.3342 - val_loss: 0.8953 - val_mae: 0.7010\n",
            "Epoch 510/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2428 - mae: 0.3797 - val_loss: 0.8902 - val_mae: 0.6965\n",
            "Epoch 511/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1966 - mae: 0.3377 - val_loss: 0.8879 - val_mae: 0.6877\n",
            "Epoch 512/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2053 - mae: 0.3449 - val_loss: 0.9705 - val_mae: 0.7305\n",
            "Epoch 513/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2192 - mae: 0.3597 - val_loss: 0.9910 - val_mae: 0.7412\n",
            "Epoch 514/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1959 - mae: 0.3379 - val_loss: 0.9135 - val_mae: 0.7027\n",
            "Epoch 515/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1964 - mae: 0.3377 - val_loss: 0.9053 - val_mae: 0.7012\n",
            "Epoch 516/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1944 - mae: 0.3396 - val_loss: 0.8907 - val_mae: 0.6955\n",
            "Epoch 517/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1948 - mae: 0.3355 - val_loss: 0.8897 - val_mae: 0.6888\n",
            "Epoch 518/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1702 - mae: 0.3152 - val_loss: 0.9246 - val_mae: 0.6996\n",
            "Epoch 519/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1776 - mae: 0.3243 - val_loss: 0.9021 - val_mae: 0.6953\n",
            "Epoch 520/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1754 - mae: 0.3182 - val_loss: 0.9352 - val_mae: 0.7026\n",
            "Epoch 521/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1761 - mae: 0.3180 - val_loss: 0.9069 - val_mae: 0.6925\n",
            "Epoch 522/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1894 - mae: 0.3296 - val_loss: 0.9156 - val_mae: 0.7007\n",
            "Epoch 523/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1954 - mae: 0.3426 - val_loss: 0.9349 - val_mae: 0.7104\n",
            "Epoch 524/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1857 - mae: 0.3281 - val_loss: 0.8943 - val_mae: 0.6942\n",
            "Epoch 525/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1880 - mae: 0.3298 - val_loss: 0.9875 - val_mae: 0.7433\n",
            "Epoch 526/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1838 - mae: 0.3269 - val_loss: 0.8913 - val_mae: 0.7008\n",
            "Epoch 527/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1801 - mae: 0.3269 - val_loss: 0.9241 - val_mae: 0.7015\n",
            "Epoch 528/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1730 - mae: 0.3165 - val_loss: 0.9305 - val_mae: 0.7058\n",
            "Epoch 529/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2035 - mae: 0.3488 - val_loss: 0.9108 - val_mae: 0.7044\n",
            "Epoch 530/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1715 - mae: 0.3137 - val_loss: 0.9247 - val_mae: 0.7002\n",
            "Epoch 531/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1947 - mae: 0.3391 - val_loss: 1.0042 - val_mae: 0.7300\n",
            "Epoch 532/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1810 - mae: 0.3217 - val_loss: 0.8927 - val_mae: 0.7008\n",
            "Epoch 533/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1684 - mae: 0.3119 - val_loss: 0.9321 - val_mae: 0.7118\n",
            "Epoch 534/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1806 - mae: 0.3257 - val_loss: 0.9299 - val_mae: 0.7104\n",
            "Epoch 535/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1761 - mae: 0.3227 - val_loss: 0.9488 - val_mae: 0.7209\n",
            "Epoch 536/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1789 - mae: 0.3211 - val_loss: 0.9154 - val_mae: 0.7057\n",
            "Epoch 537/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1627 - mae: 0.3063 - val_loss: 0.9234 - val_mae: 0.7013\n",
            "Epoch 538/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1905 - mae: 0.3352 - val_loss: 0.9333 - val_mae: 0.7191\n",
            "Epoch 539/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1799 - mae: 0.3285 - val_loss: 0.9331 - val_mae: 0.7103\n",
            "Epoch 540/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1810 - mae: 0.3253 - val_loss: 0.9267 - val_mae: 0.7009\n",
            "Epoch 541/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1659 - mae: 0.3098 - val_loss: 0.9325 - val_mae: 0.7188\n",
            "Epoch 542/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1669 - mae: 0.3116 - val_loss: 0.9427 - val_mae: 0.6951\n",
            "Epoch 543/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1723 - mae: 0.3164 - val_loss: 0.9332 - val_mae: 0.7089\n",
            "Epoch 544/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1687 - mae: 0.3135 - val_loss: 0.9317 - val_mae: 0.6943\n",
            "Epoch 545/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1606 - mae: 0.3062 - val_loss: 0.9394 - val_mae: 0.7105\n",
            "Epoch 546/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1739 - mae: 0.3207 - val_loss: 0.9257 - val_mae: 0.7066\n",
            "Epoch 547/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1642 - mae: 0.3107 - val_loss: 0.9791 - val_mae: 0.7287\n",
            "Epoch 548/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1836 - mae: 0.3313 - val_loss: 0.9723 - val_mae: 0.7247\n",
            "Epoch 549/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1736 - mae: 0.3216 - val_loss: 0.9391 - val_mae: 0.7172\n",
            "Epoch 550/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1828 - mae: 0.3249 - val_loss: 0.9113 - val_mae: 0.7088\n",
            "Epoch 551/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1555 - mae: 0.2992 - val_loss: 0.9460 - val_mae: 0.7076\n",
            "Epoch 552/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1553 - mae: 0.3017 - val_loss: 0.9217 - val_mae: 0.7043\n",
            "Epoch 553/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1540 - mae: 0.2980 - val_loss: 0.9915 - val_mae: 0.7352\n",
            "Epoch 554/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1932 - mae: 0.3364 - val_loss: 0.9161 - val_mae: 0.7006\n",
            "Epoch 555/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1622 - mae: 0.3069 - val_loss: 0.9183 - val_mae: 0.7025\n",
            "Epoch 556/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1789 - mae: 0.3248 - val_loss: 0.9382 - val_mae: 0.7080\n",
            "Epoch 557/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1708 - mae: 0.3127 - val_loss: 0.9116 - val_mae: 0.6929\n",
            "Epoch 558/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1690 - mae: 0.3167 - val_loss: 0.9227 - val_mae: 0.7053\n",
            "Epoch 559/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1588 - mae: 0.3048 - val_loss: 0.9844 - val_mae: 0.7238\n",
            "Epoch 560/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1614 - mae: 0.3073 - val_loss: 0.9254 - val_mae: 0.7004\n",
            "Epoch 561/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1475 - mae: 0.2915 - val_loss: 0.9124 - val_mae: 0.6959\n",
            "Epoch 562/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1515 - mae: 0.2963 - val_loss: 0.9176 - val_mae: 0.6938\n",
            "Epoch 563/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1655 - mae: 0.3069 - val_loss: 1.0051 - val_mae: 0.7505\n",
            "Epoch 564/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1691 - mae: 0.3163 - val_loss: 0.9526 - val_mae: 0.7122\n",
            "Epoch 565/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1349 - mae: 0.2777 - val_loss: 0.9153 - val_mae: 0.6972\n",
            "Epoch 566/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1672 - mae: 0.3172 - val_loss: 0.9580 - val_mae: 0.7026\n",
            "Epoch 567/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1432 - mae: 0.2871 - val_loss: 0.9260 - val_mae: 0.7072\n",
            "Epoch 568/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1388 - mae: 0.2808 - val_loss: 0.9295 - val_mae: 0.7009\n",
            "Epoch 569/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1546 - mae: 0.3039 - val_loss: 0.9399 - val_mae: 0.7095\n",
            "Epoch 570/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1454 - mae: 0.2879 - val_loss: 0.9189 - val_mae: 0.7017\n",
            "Epoch 571/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1670 - mae: 0.3109 - val_loss: 0.9524 - val_mae: 0.7148\n",
            "Epoch 572/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1519 - mae: 0.2953 - val_loss: 0.9231 - val_mae: 0.7026\n",
            "Epoch 573/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1418 - mae: 0.2864 - val_loss: 0.9279 - val_mae: 0.6961\n",
            "Epoch 574/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1581 - mae: 0.3044 - val_loss: 0.9352 - val_mae: 0.7167\n",
            "Epoch 575/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1520 - mae: 0.2996 - val_loss: 0.9395 - val_mae: 0.7046\n",
            "Epoch 576/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1517 - mae: 0.2955 - val_loss: 0.9171 - val_mae: 0.7002\n",
            "Epoch 577/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1520 - mae: 0.2925 - val_loss: 0.9374 - val_mae: 0.7111\n",
            "Epoch 578/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1600 - mae: 0.3025 - val_loss: 0.9427 - val_mae: 0.7224\n",
            "Epoch 579/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1484 - mae: 0.2941 - val_loss: 0.9324 - val_mae: 0.7187\n",
            "Epoch 580/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1452 - mae: 0.2927 - val_loss: 0.9106 - val_mae: 0.6979\n",
            "Epoch 581/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1483 - mae: 0.2902 - val_loss: 0.9327 - val_mae: 0.7174\n",
            "Epoch 582/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1463 - mae: 0.2922 - val_loss: 1.0234 - val_mae: 0.7391\n",
            "Epoch 583/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1520 - mae: 0.2957 - val_loss: 0.9195 - val_mae: 0.7186\n",
            "Epoch 584/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1418 - mae: 0.2898 - val_loss: 0.9210 - val_mae: 0.7067\n",
            "Epoch 585/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1404 - mae: 0.2858 - val_loss: 0.9435 - val_mae: 0.7206\n",
            "Epoch 586/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1338 - mae: 0.2754 - val_loss: 0.9468 - val_mae: 0.7239\n",
            "Epoch 587/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1393 - mae: 0.2836 - val_loss: 0.9018 - val_mae: 0.6970\n",
            "Epoch 588/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1382 - mae: 0.2835 - val_loss: 0.9579 - val_mae: 0.7258\n",
            "Epoch 589/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1412 - mae: 0.2858 - val_loss: 0.9274 - val_mae: 0.7189\n",
            "Epoch 590/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1574 - mae: 0.3065 - val_loss: 0.9194 - val_mae: 0.7133\n",
            "Epoch 591/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1538 - mae: 0.3006 - val_loss: 0.9370 - val_mae: 0.7130\n",
            "Epoch 592/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1392 - mae: 0.2828 - val_loss: 0.9344 - val_mae: 0.7054\n",
            "Epoch 593/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1248 - mae: 0.2686 - val_loss: 0.9243 - val_mae: 0.7013\n",
            "Epoch 594/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1368 - mae: 0.2842 - val_loss: 0.9724 - val_mae: 0.7170\n",
            "Epoch 595/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1364 - mae: 0.2803 - val_loss: 0.9285 - val_mae: 0.7125\n",
            "Epoch 596/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1339 - mae: 0.2780 - val_loss: 0.9196 - val_mae: 0.7005\n",
            "Epoch 597/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1409 - mae: 0.2861 - val_loss: 0.9285 - val_mae: 0.7001\n",
            "Epoch 598/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1465 - mae: 0.2921 - val_loss: 0.9835 - val_mae: 0.7189\n",
            "Epoch 599/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1569 - mae: 0.3043 - val_loss: 1.0288 - val_mae: 0.7432\n",
            "Epoch 600/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1363 - mae: 0.2804 - val_loss: 0.9104 - val_mae: 0.6956\n",
            "Epoch 601/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1194 - mae: 0.2577 - val_loss: 0.9569 - val_mae: 0.7046\n",
            "Epoch 602/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1300 - mae: 0.2696 - val_loss: 0.9543 - val_mae: 0.7145\n",
            "Epoch 603/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1395 - mae: 0.2833 - val_loss: 0.9314 - val_mae: 0.7121\n",
            "Epoch 604/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1513 - mae: 0.2988 - val_loss: 0.9421 - val_mae: 0.7082\n",
            "Epoch 605/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1253 - mae: 0.2682 - val_loss: 0.9462 - val_mae: 0.7116\n",
            "Epoch 606/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1203 - mae: 0.2624 - val_loss: 0.9369 - val_mae: 0.7153\n",
            "Epoch 607/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1340 - mae: 0.2815 - val_loss: 0.9902 - val_mae: 0.7298\n",
            "Epoch 608/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1422 - mae: 0.2898 - val_loss: 0.9781 - val_mae: 0.7350\n",
            "Epoch 609/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1312 - mae: 0.2745 - val_loss: 0.9173 - val_mae: 0.6944\n",
            "Epoch 610/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1173 - mae: 0.2565 - val_loss: 0.9372 - val_mae: 0.7077\n",
            "Epoch 611/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1194 - mae: 0.2595 - val_loss: 0.9250 - val_mae: 0.6975\n",
            "Epoch 612/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1386 - mae: 0.2835 - val_loss: 0.9087 - val_mae: 0.7045\n",
            "Epoch 613/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1189 - mae: 0.2608 - val_loss: 0.9334 - val_mae: 0.7139\n",
            "Epoch 614/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1217 - mae: 0.2641 - val_loss: 0.9193 - val_mae: 0.7033\n",
            "Epoch 615/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1252 - mae: 0.2739 - val_loss: 0.9406 - val_mae: 0.7103\n",
            "Epoch 616/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1263 - mae: 0.2740 - val_loss: 0.9439 - val_mae: 0.7065\n",
            "Epoch 617/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1380 - mae: 0.2856 - val_loss: 0.9683 - val_mae: 0.7392\n",
            "Epoch 618/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1224 - mae: 0.2640 - val_loss: 0.9344 - val_mae: 0.7077\n",
            "Epoch 619/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1285 - mae: 0.2740 - val_loss: 0.9568 - val_mae: 0.7168\n",
            "Epoch 620/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1288 - mae: 0.2738 - val_loss: 1.0498 - val_mae: 0.7648\n",
            "Epoch 621/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1550 - mae: 0.3006 - val_loss: 0.9310 - val_mae: 0.7070\n",
            "Epoch 622/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1226 - mae: 0.2658 - val_loss: 0.9212 - val_mae: 0.6993\n",
            "Epoch 623/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1192 - mae: 0.2611 - val_loss: 1.0070 - val_mae: 0.7506\n",
            "Epoch 624/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1256 - mae: 0.2693 - val_loss: 0.9338 - val_mae: 0.7118\n",
            "Epoch 625/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1235 - mae: 0.2675 - val_loss: 0.9240 - val_mae: 0.7015\n",
            "Epoch 626/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1192 - mae: 0.2563 - val_loss: 0.9514 - val_mae: 0.7202\n",
            "Epoch 627/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1077 - mae: 0.2471 - val_loss: 0.9203 - val_mae: 0.7011\n",
            "Epoch 628/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1156 - mae: 0.2562 - val_loss: 0.9370 - val_mae: 0.7147\n",
            "Epoch 629/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1070 - mae: 0.2474 - val_loss: 0.9372 - val_mae: 0.7069\n",
            "Epoch 630/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1106 - mae: 0.2519 - val_loss: 0.9461 - val_mae: 0.7127\n",
            "Epoch 631/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1270 - mae: 0.2739 - val_loss: 0.9823 - val_mae: 0.7300\n",
            "Epoch 632/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1227 - mae: 0.2670 - val_loss: 0.9077 - val_mae: 0.6957\n",
            "Epoch 633/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1250 - mae: 0.2711 - val_loss: 0.9307 - val_mae: 0.7144\n",
            "Epoch 634/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1238 - mae: 0.2668 - val_loss: 0.9695 - val_mae: 0.7176\n",
            "Epoch 635/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1058 - mae: 0.2467 - val_loss: 0.9166 - val_mae: 0.7041\n",
            "Epoch 636/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1190 - mae: 0.2593 - val_loss: 0.9269 - val_mae: 0.7032\n",
            "Epoch 637/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1109 - mae: 0.2493 - val_loss: 0.9658 - val_mae: 0.7280\n",
            "Epoch 638/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1155 - mae: 0.2577 - val_loss: 0.9436 - val_mae: 0.7122\n",
            "Epoch 639/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1046 - mae: 0.2447 - val_loss: 0.9478 - val_mae: 0.7064\n",
            "Epoch 640/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1173 - mae: 0.2596 - val_loss: 0.9390 - val_mae: 0.7116\n",
            "Epoch 641/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1058 - mae: 0.2459 - val_loss: 0.9604 - val_mae: 0.7233\n",
            "Epoch 642/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1080 - mae: 0.2478 - val_loss: 0.9631 - val_mae: 0.7067\n",
            "Epoch 643/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1315 - mae: 0.2747 - val_loss: 0.9365 - val_mae: 0.7053\n",
            "Epoch 644/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1009 - mae: 0.2387 - val_loss: 0.9340 - val_mae: 0.7125\n",
            "Epoch 645/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1041 - mae: 0.2405 - val_loss: 1.0172 - val_mae: 0.7480\n",
            "Epoch 646/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1073 - mae: 0.2508 - val_loss: 0.9328 - val_mae: 0.6982\n",
            "Epoch 647/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1087 - mae: 0.2484 - val_loss: 0.9355 - val_mae: 0.7063\n",
            "Epoch 648/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1067 - mae: 0.2490 - val_loss: 0.9607 - val_mae: 0.7227\n",
            "Epoch 649/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0953 - mae: 0.2312 - val_loss: 0.9340 - val_mae: 0.7060\n",
            "Epoch 650/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1124 - mae: 0.2555 - val_loss: 0.9463 - val_mae: 0.7202\n",
            "Epoch 651/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1306 - mae: 0.2749 - val_loss: 0.9640 - val_mae: 0.7063\n",
            "Epoch 652/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0993 - mae: 0.2397 - val_loss: 0.9320 - val_mae: 0.7073\n",
            "Epoch 653/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0983 - mae: 0.2366 - val_loss: 0.9523 - val_mae: 0.7121\n",
            "Epoch 654/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1060 - mae: 0.2463 - val_loss: 0.9485 - val_mae: 0.7199\n",
            "Epoch 655/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1195 - mae: 0.2653 - val_loss: 0.9661 - val_mae: 0.7263\n",
            "Epoch 656/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1197 - mae: 0.2622 - val_loss: 0.9481 - val_mae: 0.7058\n",
            "Epoch 657/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 0.2347 - val_loss: 0.9771 - val_mae: 0.7244\n",
            "Epoch 658/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0970 - mae: 0.2354 - val_loss: 0.9272 - val_mae: 0.7095\n",
            "Epoch 659/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1048 - mae: 0.2466 - val_loss: 0.9888 - val_mae: 0.7265\n",
            "Epoch 660/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1015 - mae: 0.2404 - val_loss: 0.9711 - val_mae: 0.7315\n",
            "Epoch 661/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1024 - mae: 0.2417 - val_loss: 0.9600 - val_mae: 0.7207\n",
            "Epoch 662/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1043 - mae: 0.2430 - val_loss: 0.9449 - val_mae: 0.7168\n",
            "Epoch 663/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1030 - mae: 0.2441 - val_loss: 0.9825 - val_mae: 0.7220\n",
            "Epoch 664/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1236 - mae: 0.2668 - val_loss: 0.9559 - val_mae: 0.7265\n",
            "Epoch 665/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1017 - mae: 0.2426 - val_loss: 0.9626 - val_mae: 0.7157\n",
            "Epoch 666/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1027 - mae: 0.2423 - val_loss: 0.9546 - val_mae: 0.7163\n",
            "Epoch 667/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0953 - mae: 0.2317 - val_loss: 0.9325 - val_mae: 0.7093\n",
            "Epoch 668/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0919 - mae: 0.2303 - val_loss: 0.9401 - val_mae: 0.7107\n",
            "Epoch 669/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0971 - mae: 0.2348 - val_loss: 0.9790 - val_mae: 0.7361\n",
            "Epoch 670/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1093 - mae: 0.2484 - val_loss: 0.9630 - val_mae: 0.7255\n",
            "Epoch 671/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1024 - mae: 0.2466 - val_loss: 0.9718 - val_mae: 0.7229\n",
            "Epoch 672/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0948 - mae: 0.2327 - val_loss: 0.9484 - val_mae: 0.7161\n",
            "Epoch 673/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1216 - mae: 0.2648 - val_loss: 0.9798 - val_mae: 0.7352\n",
            "Epoch 674/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1195 - mae: 0.2662 - val_loss: 1.0227 - val_mae: 0.7403\n",
            "Epoch 675/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1149 - mae: 0.2610 - val_loss: 0.9789 - val_mae: 0.7181\n",
            "Epoch 676/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0999 - mae: 0.2416 - val_loss: 1.0042 - val_mae: 0.7353\n",
            "Epoch 677/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011 - mae: 0.2430 - val_loss: 0.9559 - val_mae: 0.7127\n",
            "Epoch 678/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0836 - mae: 0.2158 - val_loss: 0.9508 - val_mae: 0.7123\n",
            "Epoch 679/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002 - mae: 0.2391 - val_loss: 0.9514 - val_mae: 0.7124\n",
            "Epoch 680/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0944 - mae: 0.2331 - val_loss: 0.9534 - val_mae: 0.7081\n",
            "Epoch 681/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 0.2359 - val_loss: 0.9607 - val_mae: 0.7112\n",
            "Epoch 682/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1028 - mae: 0.2446 - val_loss: 0.9414 - val_mae: 0.7083\n",
            "Epoch 683/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0880 - mae: 0.2236 - val_loss: 0.9360 - val_mae: 0.7100\n",
            "Epoch 684/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0955 - mae: 0.2320 - val_loss: 0.9962 - val_mae: 0.7380\n",
            "Epoch 685/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1038 - mae: 0.2438 - val_loss: 0.9248 - val_mae: 0.7128\n",
            "Epoch 686/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0972 - mae: 0.2370 - val_loss: 0.9617 - val_mae: 0.7157\n",
            "Epoch 687/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0993 - mae: 0.2379 - val_loss: 0.9586 - val_mae: 0.7102\n",
            "Epoch 688/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0867 - mae: 0.2222 - val_loss: 0.9415 - val_mae: 0.7050\n",
            "Epoch 689/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0934 - mae: 0.2319 - val_loss: 0.9876 - val_mae: 0.7316\n",
            "Epoch 690/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0908 - mae: 0.2232 - val_loss: 0.9663 - val_mae: 0.7156\n",
            "Epoch 691/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0918 - mae: 0.2290 - val_loss: 0.9439 - val_mae: 0.7102\n",
            "Epoch 692/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0788 - mae: 0.2078 - val_loss: 0.9554 - val_mae: 0.7083\n",
            "Epoch 693/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0810 - mae: 0.2140 - val_loss: 0.9326 - val_mae: 0.7113\n",
            "Epoch 694/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0823 - mae: 0.2130 - val_loss: 0.9879 - val_mae: 0.7335\n",
            "Epoch 695/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0880 - mae: 0.2239 - val_loss: 0.9521 - val_mae: 0.7053\n",
            "Epoch 696/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1025 - mae: 0.2429 - val_loss: 1.0201 - val_mae: 0.7593\n",
            "Epoch 697/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0909 - mae: 0.2312 - val_loss: 0.9567 - val_mae: 0.7090\n",
            "Epoch 698/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0985 - mae: 0.2395 - val_loss: 0.9459 - val_mae: 0.7093\n",
            "Epoch 699/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0949 - mae: 0.2333 - val_loss: 0.9909 - val_mae: 0.7287\n",
            "Epoch 700/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0793 - mae: 0.2123 - val_loss: 0.9302 - val_mae: 0.6986\n",
            "Epoch 701/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0821 - mae: 0.2152 - val_loss: 0.9536 - val_mae: 0.7190\n",
            "Epoch 702/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0876 - mae: 0.2264 - val_loss: 0.9378 - val_mae: 0.7151\n",
            "Epoch 703/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0837 - mae: 0.2182 - val_loss: 0.9321 - val_mae: 0.7047\n",
            "Epoch 704/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0759 - mae: 0.2063 - val_loss: 0.9504 - val_mae: 0.7156\n",
            "Epoch 705/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0842 - mae: 0.2194 - val_loss: 0.9496 - val_mae: 0.7074\n",
            "Epoch 706/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0873 - mae: 0.2235 - val_loss: 0.9493 - val_mae: 0.7164\n",
            "Epoch 707/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0931 - mae: 0.2317 - val_loss: 0.9819 - val_mae: 0.7172\n",
            "Epoch 708/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0848 - mae: 0.2209 - val_loss: 0.9477 - val_mae: 0.7153\n",
            "Epoch 709/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0864 - mae: 0.2228 - val_loss: 0.9675 - val_mae: 0.7269\n",
            "Epoch 710/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1006 - mae: 0.2391 - val_loss: 0.9943 - val_mae: 0.7366\n",
            "Epoch 711/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0857 - mae: 0.2208 - val_loss: 0.9639 - val_mae: 0.7146\n",
            "Epoch 712/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1022 - mae: 0.2461 - val_loss: 0.9835 - val_mae: 0.7286\n",
            "Epoch 713/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0868 - mae: 0.2233 - val_loss: 1.0287 - val_mae: 0.7423\n",
            "Epoch 714/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0866 - mae: 0.2240 - val_loss: 0.9319 - val_mae: 0.7117\n",
            "Epoch 715/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0920 - mae: 0.2308 - val_loss: 0.9834 - val_mae: 0.7326\n",
            "Epoch 716/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0738 - mae: 0.2060 - val_loss: 0.9864 - val_mae: 0.7298\n",
            "Epoch 717/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0696 - mae: 0.1959 - val_loss: 0.9477 - val_mae: 0.7113\n",
            "Epoch 718/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0815 - mae: 0.2133 - val_loss: 0.9915 - val_mae: 0.7274\n",
            "Epoch 719/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0802 - mae: 0.2098 - val_loss: 0.9909 - val_mae: 0.7205\n",
            "Epoch 720/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0762 - mae: 0.2075 - val_loss: 0.9494 - val_mae: 0.7168\n",
            "Epoch 721/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0747 - mae: 0.2062 - val_loss: 0.9855 - val_mae: 0.7185\n",
            "Epoch 722/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0792 - mae: 0.2127 - val_loss: 1.0022 - val_mae: 0.7350\n",
            "Epoch 723/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0813 - mae: 0.2161 - val_loss: 1.0178 - val_mae: 0.7389\n",
            "Epoch 724/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0857 - mae: 0.2193 - val_loss: 0.9892 - val_mae: 0.7265\n",
            "Epoch 725/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0762 - mae: 0.2042 - val_loss: 1.0053 - val_mae: 0.7288\n",
            "Epoch 726/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0720 - mae: 0.2016 - val_loss: 1.0090 - val_mae: 0.7311\n",
            "Epoch 727/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0794 - mae: 0.2103 - val_loss: 0.9749 - val_mae: 0.7132\n",
            "Epoch 728/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0731 - mae: 0.2042 - val_loss: 0.9890 - val_mae: 0.7219\n",
            "Epoch 729/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0828 - mae: 0.2197 - val_loss: 0.9686 - val_mae: 0.7159\n",
            "Epoch 730/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0829 - mae: 0.2194 - val_loss: 0.9863 - val_mae: 0.7269\n",
            "Epoch 731/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.2120 - val_loss: 0.9603 - val_mae: 0.7128\n",
            "Epoch 732/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0700 - mae: 0.1976 - val_loss: 0.9918 - val_mae: 0.7249\n",
            "Epoch 733/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0666 - mae: 0.1938 - val_loss: 0.9658 - val_mae: 0.7099\n",
            "Epoch 734/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1041 - mae: 0.2461 - val_loss: 0.9652 - val_mae: 0.7146\n",
            "Epoch 735/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0911 - mae: 0.2336 - val_loss: 1.0167 - val_mae: 0.7273\n",
            "Epoch 736/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.2133 - val_loss: 0.9699 - val_mae: 0.7126\n",
            "Epoch 737/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0717 - mae: 0.2025 - val_loss: 0.9772 - val_mae: 0.7198\n",
            "Epoch 738/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0701 - mae: 0.1986 - val_loss: 0.9944 - val_mae: 0.7266\n",
            "Epoch 739/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0746 - mae: 0.2048 - val_loss: 0.9729 - val_mae: 0.7194\n",
            "Epoch 740/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0687 - mae: 0.1944 - val_loss: 1.0057 - val_mae: 0.7339\n",
            "Epoch 741/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0678 - mae: 0.1936 - val_loss: 0.9877 - val_mae: 0.7180\n",
            "Epoch 742/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0728 - mae: 0.2023 - val_loss: 0.9766 - val_mae: 0.7184\n",
            "Epoch 743/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0631 - mae: 0.1883 - val_loss: 0.9733 - val_mae: 0.7162\n",
            "Epoch 744/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0657 - mae: 0.1905 - val_loss: 0.9940 - val_mae: 0.7291\n",
            "Epoch 745/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0682 - mae: 0.1945 - val_loss: 0.9998 - val_mae: 0.7270\n",
            "Epoch 746/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0742 - mae: 0.2065 - val_loss: 0.9578 - val_mae: 0.7071\n",
            "Epoch 747/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0769 - mae: 0.2118 - val_loss: 0.9709 - val_mae: 0.7066\n",
            "Epoch 748/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0717 - mae: 0.2021 - val_loss: 0.9721 - val_mae: 0.7188\n",
            "Epoch 749/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0717 - mae: 0.2012 - val_loss: 1.0229 - val_mae: 0.7395\n",
            "Epoch 750/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0743 - mae: 0.2080 - val_loss: 0.9936 - val_mae: 0.7248\n",
            "Epoch 751/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0629 - mae: 0.1857 - val_loss: 0.9924 - val_mae: 0.7137\n",
            "Epoch 752/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0689 - mae: 0.1960 - val_loss: 0.9883 - val_mae: 0.7282\n",
            "Epoch 753/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0685 - mae: 0.1967 - val_loss: 0.9704 - val_mae: 0.7233\n",
            "Epoch 754/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0786 - mae: 0.2140 - val_loss: 0.9957 - val_mae: 0.7201\n",
            "Epoch 755/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0817 - mae: 0.2199 - val_loss: 0.9665 - val_mae: 0.7218\n",
            "Epoch 756/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0749 - mae: 0.2082 - val_loss: 0.9826 - val_mae: 0.7171\n",
            "Epoch 757/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0716 - mae: 0.2015 - val_loss: 1.0233 - val_mae: 0.7439\n",
            "Epoch 758/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0642 - mae: 0.1914 - val_loss: 0.9823 - val_mae: 0.7198\n",
            "Epoch 759/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0630 - mae: 0.1859 - val_loss: 1.0134 - val_mae: 0.7309\n",
            "Epoch 760/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0638 - mae: 0.1879 - val_loss: 1.0028 - val_mae: 0.7222\n",
            "Epoch 761/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0711 - mae: 0.2023 - val_loss: 0.9811 - val_mae: 0.7233\n",
            "Epoch 762/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0774 - mae: 0.2112 - val_loss: 1.0122 - val_mae: 0.7319\n",
            "Epoch 763/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0875 - mae: 0.2233 - val_loss: 0.9737 - val_mae: 0.7096\n",
            "Epoch 764/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0636 - mae: 0.1846 - val_loss: 1.0825 - val_mae: 0.7562\n",
            "Epoch 765/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0758 - mae: 0.2037 - val_loss: 1.0038 - val_mae: 0.7238\n",
            "Epoch 766/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 0.1933 - val_loss: 0.9708 - val_mae: 0.7116\n",
            "Epoch 767/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 0.1812 - val_loss: 0.9882 - val_mae: 0.7216\n",
            "Epoch 768/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.1824 - val_loss: 1.0064 - val_mae: 0.7363\n",
            "Epoch 769/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0655 - mae: 0.1911 - val_loss: 0.9992 - val_mae: 0.7213\n",
            "Epoch 770/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0652 - mae: 0.1914 - val_loss: 1.0126 - val_mae: 0.7262\n",
            "Epoch 771/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0622 - mae: 0.1870 - val_loss: 1.0305 - val_mae: 0.7295\n",
            "Epoch 772/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0788 - mae: 0.2129 - val_loss: 0.9905 - val_mae: 0.7228\n",
            "Epoch 773/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0722 - mae: 0.2082 - val_loss: 1.0339 - val_mae: 0.7376\n",
            "Epoch 774/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0723 - mae: 0.2064 - val_loss: 0.9888 - val_mae: 0.7268\n",
            "Epoch 775/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0735 - mae: 0.2051 - val_loss: 0.9974 - val_mae: 0.7290\n",
            "Epoch 776/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0651 - mae: 0.1906 - val_loss: 0.9885 - val_mae: 0.7202\n",
            "Epoch 777/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.1795 - val_loss: 1.0120 - val_mae: 0.7303\n",
            "Epoch 778/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0635 - mae: 0.1905 - val_loss: 1.0325 - val_mae: 0.7308\n",
            "Epoch 779/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0577 - mae: 0.1794 - val_loss: 0.9934 - val_mae: 0.7175\n",
            "Epoch 780/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0677 - mae: 0.1961 - val_loss: 1.0037 - val_mae: 0.7292\n",
            "Epoch 781/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0655 - mae: 0.1943 - val_loss: 1.0425 - val_mae: 0.7371\n",
            "Epoch 782/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0644 - mae: 0.1912 - val_loss: 1.0027 - val_mae: 0.7178\n",
            "Epoch 783/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0746 - mae: 0.2096 - val_loss: 1.0195 - val_mae: 0.7265\n",
            "Epoch 784/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0812 - mae: 0.2176 - val_loss: 1.0043 - val_mae: 0.7254\n",
            "Epoch 785/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0662 - mae: 0.1947 - val_loss: 1.0250 - val_mae: 0.7315\n",
            "Epoch 786/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0616 - mae: 0.1880 - val_loss: 0.9944 - val_mae: 0.7180\n",
            "Epoch 787/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0614 - mae: 0.1860 - val_loss: 0.9869 - val_mae: 0.7191\n",
            "Epoch 788/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0759 - mae: 0.2063 - val_loss: 1.0296 - val_mae: 0.7353\n",
            "Epoch 789/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0909 - mae: 0.2286 - val_loss: 0.9844 - val_mae: 0.7172\n",
            "Epoch 790/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0693 - mae: 0.1982 - val_loss: 1.0045 - val_mae: 0.7253\n",
            "Epoch 791/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0654 - mae: 0.1952 - val_loss: 0.9732 - val_mae: 0.7085\n",
            "Epoch 792/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0609 - mae: 0.1860 - val_loss: 0.9909 - val_mae: 0.7265\n",
            "Epoch 793/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0663 - mae: 0.1959 - val_loss: 1.0097 - val_mae: 0.7273\n",
            "Epoch 794/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0577 - mae: 0.1811 - val_loss: 0.9823 - val_mae: 0.7183\n",
            "Epoch 795/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0646 - mae: 0.1929 - val_loss: 0.9949 - val_mae: 0.7232\n",
            "Epoch 796/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0567 - mae: 0.1795 - val_loss: 1.0003 - val_mae: 0.7199\n",
            "Epoch 797/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0571 - mae: 0.1781 - val_loss: 0.9827 - val_mae: 0.7180\n",
            "Epoch 798/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1647 - val_loss: 1.0072 - val_mae: 0.7237\n",
            "Epoch 799/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0527 - mae: 0.1685 - val_loss: 0.9913 - val_mae: 0.7203\n",
            "Epoch 800/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0591 - mae: 0.1820 - val_loss: 1.0118 - val_mae: 0.7274\n",
            "Epoch 801/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0645 - mae: 0.1895 - val_loss: 1.0391 - val_mae: 0.7418\n",
            "Epoch 802/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0669 - mae: 0.1944 - val_loss: 1.0110 - val_mae: 0.7340\n",
            "Epoch 803/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0559 - mae: 0.1766 - val_loss: 0.9924 - val_mae: 0.7160\n",
            "Epoch 804/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0558 - mae: 0.1754 - val_loss: 1.0175 - val_mae: 0.7240\n",
            "Epoch 805/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0677 - mae: 0.1957 - val_loss: 1.0156 - val_mae: 0.7325\n",
            "Epoch 806/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0640 - mae: 0.1931 - val_loss: 1.0019 - val_mae: 0.7153\n",
            "Epoch 807/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0620 - mae: 0.1871 - val_loss: 1.0088 - val_mae: 0.7203\n",
            "Epoch 808/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0595 - mae: 0.1823 - val_loss: 0.9856 - val_mae: 0.7286\n",
            "Epoch 809/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0562 - mae: 0.1769 - val_loss: 1.0338 - val_mae: 0.7443\n",
            "Epoch 810/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0522 - mae: 0.1692 - val_loss: 1.0062 - val_mae: 0.7257\n",
            "Epoch 811/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1639 - val_loss: 1.0355 - val_mae: 0.7422\n",
            "Epoch 812/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0616 - mae: 0.1894 - val_loss: 1.0212 - val_mae: 0.7314\n",
            "Epoch 813/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1782 - val_loss: 1.0633 - val_mae: 0.7509\n",
            "Epoch 814/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0827 - mae: 0.2215 - val_loss: 1.0117 - val_mae: 0.7310\n",
            "Epoch 815/1000\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.1989 - val_loss: 1.0174 - val_mae: 0.7252\n",
            "Epoch 816/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0567 - mae: 0.1793 - val_loss: 1.0127 - val_mae: 0.7244\n",
            "Epoch 817/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0540 - mae: 0.1728 - val_loss: 1.0027 - val_mae: 0.7218\n",
            "Epoch 818/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0519 - mae: 0.1703 - val_loss: 0.9995 - val_mae: 0.7276\n",
            "Epoch 819/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1692 - val_loss: 1.0079 - val_mae: 0.7234\n",
            "Epoch 820/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0598 - mae: 0.1849 - val_loss: 1.0530 - val_mae: 0.7359\n",
            "Epoch 821/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0637 - mae: 0.1911 - val_loss: 0.9992 - val_mae: 0.7264\n",
            "Epoch 822/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0544 - mae: 0.1754 - val_loss: 1.0082 - val_mae: 0.7235\n",
            "Epoch 823/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.1805 - val_loss: 1.0107 - val_mae: 0.7237\n",
            "Epoch 824/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0557 - mae: 0.1754 - val_loss: 0.9949 - val_mae: 0.7185\n",
            "Epoch 825/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.1842 - val_loss: 1.0157 - val_mae: 0.7344\n",
            "Epoch 826/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1799 - val_loss: 1.0087 - val_mae: 0.7260\n",
            "Epoch 827/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0503 - mae: 0.1664 - val_loss: 1.0145 - val_mae: 0.7278\n",
            "Epoch 828/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1598 - val_loss: 1.0085 - val_mae: 0.7252\n",
            "Epoch 829/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1740 - val_loss: 1.0545 - val_mae: 0.7524\n",
            "Epoch 830/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0580 - mae: 0.1809 - val_loss: 1.0255 - val_mae: 0.7312\n",
            "Epoch 831/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0504 - mae: 0.1674 - val_loss: 1.0169 - val_mae: 0.7291\n",
            "Epoch 832/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0591 - mae: 0.1840 - val_loss: 1.0141 - val_mae: 0.7251\n",
            "Epoch 833/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0557 - mae: 0.1769 - val_loss: 1.0058 - val_mae: 0.7182\n",
            "Epoch 834/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0530 - mae: 0.1726 - val_loss: 1.0114 - val_mae: 0.7230\n",
            "Epoch 835/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0478 - mae: 0.1634 - val_loss: 0.9999 - val_mae: 0.7173\n",
            "Epoch 836/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1681 - val_loss: 1.0040 - val_mae: 0.7229\n",
            "Epoch 837/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0431 - mae: 0.1534 - val_loss: 1.0054 - val_mae: 0.7191\n",
            "Epoch 838/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1601 - val_loss: 0.9916 - val_mae: 0.7102\n",
            "Epoch 839/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.1696 - val_loss: 1.0307 - val_mae: 0.7303\n",
            "Epoch 840/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0494 - mae: 0.1656 - val_loss: 1.0233 - val_mae: 0.7313\n",
            "Epoch 841/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0565 - mae: 0.1814 - val_loss: 1.0085 - val_mae: 0.7209\n",
            "Epoch 842/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1780 - val_loss: 1.0266 - val_mae: 0.7410\n",
            "Epoch 843/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0576 - mae: 0.1817 - val_loss: 0.9985 - val_mae: 0.7240\n",
            "Epoch 844/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0623 - mae: 0.1904 - val_loss: 1.0089 - val_mae: 0.7425\n",
            "Epoch 845/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1017 - mae: 0.2476 - val_loss: 1.0028 - val_mae: 0.7165\n",
            "Epoch 846/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1769 - val_loss: 1.0080 - val_mae: 0.7211\n",
            "Epoch 847/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0520 - mae: 0.1698 - val_loss: 1.0110 - val_mae: 0.7255\n",
            "Epoch 848/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1516 - val_loss: 1.0441 - val_mae: 0.7403\n",
            "Epoch 849/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0510 - mae: 0.1686 - val_loss: 1.0425 - val_mae: 0.7440\n",
            "Epoch 850/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.1744 - val_loss: 1.0564 - val_mae: 0.7475\n",
            "Epoch 851/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0759 - mae: 0.2149 - val_loss: 1.0602 - val_mae: 0.7463\n",
            "Epoch 852/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0693 - mae: 0.2014 - val_loss: 1.0212 - val_mae: 0.7304\n",
            "Epoch 853/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0490 - mae: 0.1662 - val_loss: 1.0156 - val_mae: 0.7262\n",
            "Epoch 854/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0474 - mae: 0.1626 - val_loss: 1.0321 - val_mae: 0.7329\n",
            "Epoch 855/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1552 - val_loss: 1.0022 - val_mae: 0.7180\n",
            "Epoch 856/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1624 - val_loss: 1.0176 - val_mae: 0.7260\n",
            "Epoch 857/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0502 - mae: 0.1709 - val_loss: 1.0382 - val_mae: 0.7353\n",
            "Epoch 858/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1611 - val_loss: 1.0037 - val_mae: 0.7175\n",
            "Epoch 859/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0473 - mae: 0.1630 - val_loss: 0.9999 - val_mae: 0.7208\n",
            "Epoch 860/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0461 - mae: 0.1588 - val_loss: 1.0048 - val_mae: 0.7289\n",
            "Epoch 861/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1571 - val_loss: 1.0490 - val_mae: 0.7383\n",
            "Epoch 862/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0438 - mae: 0.1569 - val_loss: 1.0268 - val_mae: 0.7290\n",
            "Epoch 863/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1511 - val_loss: 1.0170 - val_mae: 0.7235\n",
            "Epoch 864/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0401 - mae: 0.1484 - val_loss: 1.0292 - val_mae: 0.7275\n",
            "Epoch 865/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1494 - val_loss: 1.0472 - val_mae: 0.7418\n",
            "Epoch 866/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0573 - mae: 0.1835 - val_loss: 1.0275 - val_mae: 0.7276\n",
            "Epoch 867/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1571 - val_loss: 1.0258 - val_mae: 0.7252\n",
            "Epoch 868/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0463 - mae: 0.1608 - val_loss: 1.0411 - val_mae: 0.7282\n",
            "Epoch 869/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0545 - mae: 0.1777 - val_loss: 1.0427 - val_mae: 0.7316\n",
            "Epoch 870/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0760 - mae: 0.2118 - val_loss: 1.0510 - val_mae: 0.7308\n",
            "Epoch 871/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.1732 - val_loss: 1.0280 - val_mae: 0.7371\n",
            "Epoch 872/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1706 - val_loss: 1.0049 - val_mae: 0.7278\n",
            "Epoch 873/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0429 - mae: 0.1551 - val_loss: 1.0575 - val_mae: 0.7434\n",
            "Epoch 874/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0531 - mae: 0.1752 - val_loss: 1.0178 - val_mae: 0.7184\n",
            "Epoch 875/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1586 - val_loss: 1.0130 - val_mae: 0.7176\n",
            "Epoch 876/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0442 - mae: 0.1565 - val_loss: 1.0190 - val_mae: 0.7260\n",
            "Epoch 877/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0386 - mae: 0.1442 - val_loss: 1.0156 - val_mae: 0.7225\n",
            "Epoch 878/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1481 - val_loss: 1.0366 - val_mae: 0.7302\n",
            "Epoch 879/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0392 - mae: 0.1458 - val_loss: 1.0396 - val_mae: 0.7344\n",
            "Epoch 880/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0462 - mae: 0.1595 - val_loss: 1.0274 - val_mae: 0.7249\n",
            "Epoch 881/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1557 - val_loss: 1.0492 - val_mae: 0.7399\n",
            "Epoch 882/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0984 - mae: 0.2398 - val_loss: 1.0669 - val_mae: 0.7483\n",
            "Epoch 883/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0840 - mae: 0.2275 - val_loss: 1.0896 - val_mae: 0.7591\n",
            "Epoch 884/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0585 - mae: 0.1848 - val_loss: 1.0275 - val_mae: 0.7276\n",
            "Epoch 885/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1473 - val_loss: 1.0220 - val_mae: 0.7264\n",
            "Epoch 886/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1388 - val_loss: 1.0304 - val_mae: 0.7266\n",
            "Epoch 887/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1515 - val_loss: 1.0244 - val_mae: 0.7216\n",
            "Epoch 888/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0355 - mae: 0.1356 - val_loss: 1.0275 - val_mae: 0.7357\n",
            "Epoch 889/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1433 - val_loss: 1.0259 - val_mae: 0.7287\n",
            "Epoch 890/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1485 - val_loss: 1.0365 - val_mae: 0.7309\n",
            "Epoch 891/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1473 - val_loss: 1.0276 - val_mae: 0.7287\n",
            "Epoch 892/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1466 - val_loss: 1.0424 - val_mae: 0.7323\n",
            "Epoch 893/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0468 - mae: 0.1615 - val_loss: 1.0106 - val_mae: 0.7157\n",
            "Epoch 894/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1474 - val_loss: 1.0259 - val_mae: 0.7240\n",
            "Epoch 895/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0345 - mae: 0.1360 - val_loss: 1.0276 - val_mae: 0.7277\n",
            "Epoch 896/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0418 - mae: 0.1530 - val_loss: 1.0085 - val_mae: 0.7214\n",
            "Epoch 897/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0395 - mae: 0.1481 - val_loss: 1.0262 - val_mae: 0.7281\n",
            "Epoch 898/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.1634 - val_loss: 1.0253 - val_mae: 0.7292\n",
            "Epoch 899/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.1547 - val_loss: 1.0221 - val_mae: 0.7265\n",
            "Epoch 900/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0415 - mae: 0.1500 - val_loss: 1.0354 - val_mae: 0.7265\n",
            "Epoch 901/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1526 - val_loss: 1.0279 - val_mae: 0.7315\n",
            "Epoch 902/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0461 - mae: 0.1600 - val_loss: 1.0222 - val_mae: 0.7233\n",
            "Epoch 903/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1730 - val_loss: 1.0401 - val_mae: 0.7325\n",
            "Epoch 904/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1625 - val_loss: 1.0131 - val_mae: 0.7279\n",
            "Epoch 905/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1628 - val_loss: 1.0297 - val_mae: 0.7264\n",
            "Epoch 906/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1576 - val_loss: 1.0201 - val_mae: 0.7247\n",
            "Epoch 907/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1614 - val_loss: 1.0420 - val_mae: 0.7351\n",
            "Epoch 908/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1543 - val_loss: 1.0173 - val_mae: 0.7224\n",
            "Epoch 909/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1546 - val_loss: 1.0304 - val_mae: 0.7263\n",
            "Epoch 910/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1531 - val_loss: 1.0224 - val_mae: 0.7275\n",
            "Epoch 911/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0420 - mae: 0.1548 - val_loss: 1.0493 - val_mae: 0.7355\n",
            "Epoch 912/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0363 - mae: 0.1413 - val_loss: 1.0296 - val_mae: 0.7255\n",
            "Epoch 913/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1400 - val_loss: 1.0393 - val_mae: 0.7304\n",
            "Epoch 914/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1468 - val_loss: 1.0318 - val_mae: 0.7309\n",
            "Epoch 915/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0476 - mae: 0.1644 - val_loss: 1.0377 - val_mae: 0.7333\n",
            "Epoch 916/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0398 - mae: 0.1495 - val_loss: 1.0324 - val_mae: 0.7304\n",
            "Epoch 917/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1639 - val_loss: 1.0391 - val_mae: 0.7336\n",
            "Epoch 918/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1496 - val_loss: 1.0294 - val_mae: 0.7292\n",
            "Epoch 919/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0423 - mae: 0.1554 - val_loss: 1.0369 - val_mae: 0.7375\n",
            "Epoch 920/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0352 - mae: 0.1390 - val_loss: 1.0310 - val_mae: 0.7257\n",
            "Epoch 921/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1507 - val_loss: 1.0218 - val_mae: 0.7270\n",
            "Epoch 922/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1606 - val_loss: 1.0496 - val_mae: 0.7422\n",
            "Epoch 923/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1559 - val_loss: 1.0272 - val_mae: 0.7308\n",
            "Epoch 924/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0404 - mae: 0.1518 - val_loss: 1.0292 - val_mae: 0.7233\n",
            "Epoch 925/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1509 - val_loss: 1.0178 - val_mae: 0.7215\n",
            "Epoch 926/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0358 - mae: 0.1390 - val_loss: 1.0486 - val_mae: 0.7340\n",
            "Epoch 927/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0421 - mae: 0.1542 - val_loss: 1.0283 - val_mae: 0.7301\n",
            "Epoch 928/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1500 - val_loss: 1.0303 - val_mae: 0.7222\n",
            "Epoch 929/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1545 - val_loss: 1.0194 - val_mae: 0.7260\n",
            "Epoch 930/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0344 - mae: 0.1371 - val_loss: 1.0422 - val_mae: 0.7308\n",
            "Epoch 931/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1363 - val_loss: 1.0486 - val_mae: 0.7333\n",
            "Epoch 932/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1353 - val_loss: 1.0380 - val_mae: 0.7206\n",
            "Epoch 933/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1487 - val_loss: 1.0265 - val_mae: 0.7321\n",
            "Epoch 934/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0542 - mae: 0.1763 - val_loss: 1.0740 - val_mae: 0.7497\n",
            "Epoch 935/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.1932 - val_loss: 1.0249 - val_mae: 0.7313\n",
            "Epoch 936/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1515 - val_loss: 1.0478 - val_mae: 0.7378\n",
            "Epoch 937/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1587 - val_loss: 1.0426 - val_mae: 0.7320\n",
            "Epoch 938/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0426 - mae: 0.1551 - val_loss: 1.0560 - val_mae: 0.7328\n",
            "Epoch 939/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0422 - mae: 0.1529 - val_loss: 1.0449 - val_mae: 0.7321\n",
            "Epoch 940/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0331 - mae: 0.1346 - val_loss: 1.0499 - val_mae: 0.7326\n",
            "Epoch 941/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1458 - val_loss: 1.0485 - val_mae: 0.7338\n",
            "Epoch 942/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0338 - mae: 0.1364 - val_loss: 1.0217 - val_mae: 0.7249\n",
            "Epoch 943/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1271 - val_loss: 1.0594 - val_mae: 0.7347\n",
            "Epoch 944/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1409 - val_loss: 1.0296 - val_mae: 0.7237\n",
            "Epoch 945/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0364 - mae: 0.1407 - val_loss: 1.0556 - val_mae: 0.7394\n",
            "Epoch 946/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1516 - val_loss: 1.0383 - val_mae: 0.7361\n",
            "Epoch 947/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0454 - mae: 0.1597 - val_loss: 1.0535 - val_mae: 0.7342\n",
            "Epoch 948/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0391 - mae: 0.1484 - val_loss: 1.0507 - val_mae: 0.7375\n",
            "Epoch 949/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1448 - val_loss: 1.0311 - val_mae: 0.7289\n",
            "Epoch 950/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1413 - val_loss: 1.0499 - val_mae: 0.7360\n",
            "Epoch 951/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.1435 - val_loss: 1.0498 - val_mae: 0.7312\n",
            "Epoch 952/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1416 - val_loss: 1.0469 - val_mae: 0.7329\n",
            "Epoch 953/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0333 - mae: 0.1356 - val_loss: 1.0345 - val_mae: 0.7272\n",
            "Epoch 954/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1503 - val_loss: 1.0588 - val_mae: 0.7420\n",
            "Epoch 955/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0375 - mae: 0.1448 - val_loss: 1.0421 - val_mae: 0.7315\n",
            "Epoch 956/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1408 - val_loss: 1.0834 - val_mae: 0.7589\n",
            "Epoch 957/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1615 - val_loss: 1.0410 - val_mae: 0.7424\n",
            "Epoch 958/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0527 - mae: 0.1747 - val_loss: 1.0362 - val_mae: 0.7301\n",
            "Epoch 959/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0365 - mae: 0.1423 - val_loss: 1.0469 - val_mae: 0.7357\n",
            "Epoch 960/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1433 - val_loss: 1.0296 - val_mae: 0.7231\n",
            "Epoch 961/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0340 - mae: 0.1400 - val_loss: 1.0571 - val_mae: 0.7317\n",
            "Epoch 962/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0466 - mae: 0.1634 - val_loss: 1.0465 - val_mae: 0.7410\n",
            "Epoch 963/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0424 - mae: 0.1534 - val_loss: 1.0427 - val_mae: 0.7316\n",
            "Epoch 964/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1556 - val_loss: 1.0707 - val_mae: 0.7419\n",
            "Epoch 965/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1464 - val_loss: 1.0682 - val_mae: 0.7320\n",
            "Epoch 966/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0324 - mae: 0.1345 - val_loss: 1.0286 - val_mae: 0.7252\n",
            "Epoch 967/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0335 - mae: 0.1371 - val_loss: 1.0559 - val_mae: 0.7306\n",
            "Epoch 968/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1290 - val_loss: 1.0390 - val_mae: 0.7327\n",
            "Epoch 969/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1488 - val_loss: 1.0262 - val_mae: 0.7218\n",
            "Epoch 970/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1438 - val_loss: 1.0339 - val_mae: 0.7303\n",
            "Epoch 971/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1365 - val_loss: 1.0693 - val_mae: 0.7514\n",
            "Epoch 972/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1451 - val_loss: 1.0606 - val_mae: 0.7393\n",
            "Epoch 973/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1529 - val_loss: 1.0430 - val_mae: 0.7310\n",
            "Epoch 974/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1415 - val_loss: 1.0441 - val_mae: 0.7256\n",
            "Epoch 975/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0303 - mae: 0.1286 - val_loss: 1.0477 - val_mae: 0.7319\n",
            "Epoch 976/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1408 - val_loss: 1.0421 - val_mae: 0.7355\n",
            "Epoch 977/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1351 - val_loss: 1.0669 - val_mae: 0.7377\n",
            "Epoch 978/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1391 - val_loss: 1.0552 - val_mae: 0.7367\n",
            "Epoch 979/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1271 - val_loss: 1.0238 - val_mae: 0.7259\n",
            "Epoch 980/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1257 - val_loss: 1.0512 - val_mae: 0.7377\n",
            "Epoch 981/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1510 - val_loss: 1.0440 - val_mae: 0.7365\n",
            "Epoch 982/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1525 - val_loss: 1.0666 - val_mae: 0.7350\n",
            "Epoch 983/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1435 - val_loss: 1.0659 - val_mae: 0.7463\n",
            "Epoch 984/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1500 - val_loss: 1.0187 - val_mae: 0.7260\n",
            "Epoch 985/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0489 - mae: 0.1679 - val_loss: 1.0349 - val_mae: 0.7334\n",
            "Epoch 986/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0354 - mae: 0.1396 - val_loss: 1.0339 - val_mae: 0.7275\n",
            "Epoch 987/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1520 - val_loss: 1.0420 - val_mae: 0.7308\n",
            "Epoch 988/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0375 - mae: 0.1464 - val_loss: 1.0387 - val_mae: 0.7321\n",
            "Epoch 989/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0329 - mae: 0.1369 - val_loss: 1.0579 - val_mae: 0.7363\n",
            "Epoch 990/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0291 - mae: 0.1274 - val_loss: 1.0255 - val_mae: 0.7207\n",
            "Epoch 991/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1238 - val_loss: 1.0735 - val_mae: 0.7463\n",
            "Epoch 992/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0297 - mae: 0.1268 - val_loss: 1.0458 - val_mae: 0.7305\n",
            "Epoch 993/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0311 - mae: 0.1314 - val_loss: 1.0469 - val_mae: 0.7275\n",
            "Epoch 994/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0243 - mae: 0.1137 - val_loss: 1.0537 - val_mae: 0.7356\n",
            "Epoch 995/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1292 - val_loss: 1.0420 - val_mae: 0.7348\n",
            "Epoch 996/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0298 - mae: 0.1285 - val_loss: 1.0736 - val_mae: 0.7433\n",
            "Epoch 997/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0360 - mae: 0.1456 - val_loss: 1.0532 - val_mae: 0.7360\n",
            "Epoch 998/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0342 - mae: 0.1389 - val_loss: 1.0539 - val_mae: 0.7338\n",
            "Epoch 999/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0283 - mae: 0.1264 - val_loss: 1.0399 - val_mae: 0.7261\n",
            "Epoch 1000/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1392 - val_loss: 1.0459 - val_mae: 0.7365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  \"Accuracy Plot\"\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# \"Loss Plot\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TlaVtTQ06VeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "83bcf3c9-c8f2-47ca-91ae-cbe169d166a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on test data\n",
        "predictions = model.predict(Xtest_scaled[:5])\n",
        "print(\"predicted values are:\", predictions)\n",
        "print(\"Real values are: \", Ytest[:5])"
      ],
      "metadata": {
        "id": "cfiu9AFoue7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f50e4f-c412-44b4-f61b-62c241d58459"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "predicted values are: [[29.025381]\n",
            " [27.990553]\n",
            " [29.78232 ]\n",
            " [28.494236]\n",
            " [28.890373]]\n",
            "Real values are:  [28.169 27.563 29.515 27.428 29.993]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_neural,mae_neural = model.evaluate(Xtest_scaled,Ytest)\n",
        "print(\"Mean squared error from neural net:\", mse_neural)\n",
        "print(\"Mean absolute error from neural net \", mae_neural)"
      ],
      "metadata": {
        "id": "3v6uKT8nue-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c8711a-8994-412f-da58-c5aa4a5470d5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0459 - mae: 0.7365\n",
            "Mean squared error from neural net: 1.0459208488464355\n",
            "Mean absolute error from neural net  0.7365389466285706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "yG4lkH-2ufBi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression"
      ],
      "metadata": {
        "id": "RIDdkXS8-G4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear = linear_model.LinearRegression()\n",
        "lr_model_linear.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_lr = model.predict(Xtest_scaled)\n",
        "\n",
        "mse_lr = mean_squared_error(Ytest,Ypred_lr)\n",
        "mae_lr = mean_absolute_error(Ytest,Ypred_lr)\n",
        "print(\" Mean squared error from linear regression : \" , mse_lr)\n",
        "print(\" Mean absolute error from linear regression : \" , mae_lr)"
      ],
      "metadata": {
        "id": "mhtjhaKpufF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733876fd-576a-488c-bd19-b62ee51a6262"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n",
            " Mean squared error from linear regression :  1.0459209160618592\n",
            " Mean absolute error from linear regression :  0.7365390762718215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkL8LAJgj3Mv",
        "outputId": "220138fa-72c6-4908-dafe-cd475bffd72b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.99330456, -0.46392492, -0.074285  , -0.13058981, -2.8027378 ,\n",
              "       -0.2698787 , -0.00913999,  0.51779674,  0.89675477,  2.97207109,\n",
              "        0.54544638,  0.84677348,  0.59844477,  0.66765061, -0.35967527,\n",
              "        0.50050771, -0.59486257, -0.79742832, -0.46854085, -3.92187636,\n",
              "       -2.13226225, -0.00825891,  0.26605145,  0.81198666, -0.60428986,\n",
              "        0.2407348 ,  1.41342007, -1.72451606,  0.7833479 ,  1.54183248,\n",
              "       -0.66821493, -0.85169348,  1.13788892,  0.38923322, -0.67504557,\n",
              "        0.94881924, -0.48051969,  0.11524846, -0.33001355])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hydzsxAjj5qt",
        "outputId": "c2fc1204-156f-4259-8761-90953aaad2bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.213369644484526"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear.score(Xtest_scaled , Ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EeZMVtYj7GO",
        "outputId": "cb89f9d9-56fd-4000-d394-fbc775a32b6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8895989358845079"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "L7CWJVy1-K98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "tree.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_tree = tree.predict(Xtest_scaled)\n",
        "mse_dt = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_dt = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using decision tree : \" , mse_dt)\n",
        "print(\" Mean absolute error useing decision tree : \" , mae_dt)"
      ],
      "metadata": {
        "id": "UZv8pZbHufP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6e8287-291a-4289-f904-000ea0fed1dc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using decision tree :  3.3866374918032793\n",
            " Mean absolute error useing decision tree :  1.3795063752276866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest"
      ],
      "metadata": {
        "id": "V3Ml1OxKCFk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor(n_estimators=30, random_state=30)\n",
        "model_rf.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_rf = model_rf.predict(Xtest_scaled)\n",
        "mse_rf = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_rf = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using Random Forest : \" , mse_rf)\n",
        "print(\" Mean absolute error using Random Forest : \" , mae_rf)"
      ],
      "metadata": {
        "id": "7rbI7HHQufS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70633b5a-e84a-4faf-f694-5cd781924ebb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using Random Forest :  3.3866374918032793\n",
            " Mean absolute error using Random Forest :  1.3795063752276866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature randking"
      ],
      "metadata": {
        "id": "UL8F17I-FBVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now plot the feature's importance\n",
        "# according to the linear model.\n",
        "\n",
        "# Create series with feature importance.\n",
        "tmp = pd.Series(np.abs(model_rf.feature_importances_))\n",
        "\n",
        "# Let's add the variable names.\n",
        "Xtrain = pd.DataFrame(Xtrain)\n",
        "tmp.index = Xtrain.columns\n",
        "\n",
        "# Let's make a bar plot.\n",
        "tmp.plot.bar(figsize=(15, 6))\n",
        "plt.title(\"Feature importance\")\n",
        "plt.ylabel(\"Importance\")"
      ],
      "metadata": {
        "id": "gfB0T5GIufVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "cf8f05cf-5c10-498a-add4-6c00d2ca35a1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Importance')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure to import all of our modules\n",
        "# sklearn package\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# dataframes\n",
        "import pandas as pd\n",
        "# computation\n",
        "import numpy as np\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dataset\n",
        "# https://www.kaggle.com/datasets/ciphernine/brooklyn-real-estate-listings\n",
        "# place it in the same folder as this workbook\n",
        "#df = pd.read_csv('brooklyn_listings.csv')\n",
        "\n",
        "# for this example, we're going to estimate the price with sqft, bathroom, and bedrooms\n",
        "#df = df[['price','bathrooms','sqft']].dropna()\n",
        "\n",
        "# show some random lines from our data\n",
        "#print(df.sample(n=15)"
      ],
      "metadata": {
        "id": "9B4C-caKFHHJ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our polynomial model, with whatever degree we want\n",
        "degree=2\n",
        "\n",
        "# PolynomialFeatures will create a new matrix consisting of all polynomial combinations\n",
        "# of the features with a degree less than or equal to the degree we just gave the model (2)\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "# transform out polynomial features\n",
        "poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "\n",
        "# should be in the form [1, a, b, a^2, ab, b^2]\n",
        "#print(f'initial values {Xtrain_scaled[0]}\\nMapped to {poly_x_values[0]}')"
      ],
      "metadata": {
        "id": "9iKrfrOBFHJn"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytrain, y_pred_poly, squared=False)"
      ],
      "metadata": {
        "id": "-TTd5rhyFHL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dc25be-8c02-4249-c3c0-6da8f93fef2e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5857097029796254"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly_test = regression_model.predict(poly_model.fit_transform(Xtest_scaled))\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytest, y_pred_poly_test, squared=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rooiJ4C18YGP",
        "outputId": "91a84c9d-7dac-4019-bee0-2dfc4deef159"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.102059000773104"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "print(\" Mean absolute error from polynomial regression : \" , mae_poly)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ai089U-XXz",
        "outputId": "8b04bdf8-ba28-4efd-bca0-d203afeb9e94"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from polynomial regression :  4.418652042731221\n",
            " Mean absolute error from polynomial regression :  0.9773643347588769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check our accuracy for each degree, the lower the error the better!\n",
        "number_degrees = [1]\n",
        "plt_mean_squared_error = []\n",
        "for degree in number_degrees:\n",
        "\n",
        "   poly_model = PolynomialFeatures(degree=degree, include_bias= False)\n",
        "\n",
        "   poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "   poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "   regression_model = LinearRegression()\n",
        "   regression_model.fit(poly_x_values, Ytrain)\n",
        "   y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "   plt_mean_squared_error.append(mean_squared_error(Ytrain, y_pred_poly, squared=False))\n",
        "\n",
        "   poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "   y_pred_poly_test = regression_model.predict(poly_x_values)\n",
        "   mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "   mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "   print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "   print(\" Mean absolute error from polynomial regression : \" , mae_poly)\n",
        "\n",
        "\n",
        "\n",
        "#plt.scatter(number_degrees,plt_mean_squared_error, color=\"green\")\n",
        "#plt.plot(number_degrees,plt_mean_squared_error, color=\"red\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "sWrsMQs9wdbd",
        "outputId": "71fc471f-42e6-4fb5-e437-ef436b08f973"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-24e1975e203b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0mpoly_Xtest_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m    \u001b[0my_pred_poly_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_x_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m    \u001b[0mmse_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_poly_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m    \u001b[0mmae_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_poly_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" Mean squared error from polynomial regression : \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmse_poly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;36m0.825\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \"\"\"\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [549, 2194]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_model.coef_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbQOV5xToYUO",
        "outputId": "4af07841-72e6-4441-b5e1-7e68d1a80f84"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.99330456, -0.46392492, -0.074285  , -0.13058981, -2.8027378 ,\n",
              "       -0.2698787 , -0.00913999,  0.51779674,  0.89675477,  2.97207109,\n",
              "        0.54544638,  0.84677348,  0.59844477,  0.66765061, -0.35967527,\n",
              "        0.50050771, -0.59486257, -0.79742832, -0.46854085, -3.92187636,\n",
              "       -2.13226225, -0.00825891,  0.26605145,  0.81198666, -0.60428986,\n",
              "        0.2407348 ,  1.41342007, -1.72451606,  0.7833479 ,  1.54183248,\n",
              "       -0.66821493, -0.85169348,  1.13788892,  0.38923322, -0.67504557,\n",
              "        0.94881924, -0.48051969,  0.11524846, -0.33001355])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_model.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwiYgu6RoaxP",
        "outputId": "fc623128-1ae9-4ee3-b0e5-ba7b413c02ed"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.213369644484526"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}