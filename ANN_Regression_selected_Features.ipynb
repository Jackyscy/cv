{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOyett2nfwkyJ02jzrCVm7d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jackyscy/cv/blob/main/ANN_Regression_selected_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKE52MXN6PWJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as read_csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"2023_one hours__normal_on_state2_Selected_Feature.csv\",  parse_dates=[\"Date_Time\"],\n",
        "        index_col=[\"Date_Time\"],)\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "8HNmwtyn6VLO",
        "outputId": "c1b0080e-bb25-452e-e85b-2e9a29a2696b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Gt Exhaust Outlet Temp  GT Fuel Gas Mass Flow  \\\n",
              "Date_Time                                                            \n",
              "2023-01-20 17:00:00                 611.855                 13.760   \n",
              "2023-01-20 18:00:00                 604.004                 13.175   \n",
              "2023-01-20 19:00:00                 637.918                 11.979   \n",
              "2023-01-20 20:00:00                 636.447                 12.306   \n",
              "2023-01-20 21:00:00                 637.513                 11.290   \n",
              "\n",
              "                     GT Gross MW  GT Compres Inlet Temp  GT IGV Position  \\\n",
              "Date_Time                                                                  \n",
              "2023-01-20 17:00:00      231.782                 18.940           87.999   \n",
              "2023-01-20 18:00:00      226.570                 18.938           84.113   \n",
              "2023-01-20 19:00:00      207.629                 18.780           65.027   \n",
              "2023-01-20 20:00:00      212.659                 18.626           67.205   \n",
              "2023-01-20 21:00:00      193.451                 17.743           60.577   \n",
              "\n",
              "                     GT Turbine Inlet Temperature  GT Swirl Angle  \\\n",
              "Date_Time                                                           \n",
              "2023-01-20 17:00:00                      1255.732          14.534   \n",
              "2023-01-20 18:00:00                      1244.014          19.430   \n",
              "2023-01-20 19:00:00                      1284.943          38.101   \n",
              "2023-01-20 20:00:00                      1283.541          33.234   \n",
              "2023-01-20 21:00:00                      1270.635          51.623   \n",
              "\n",
              "                     GT Efficiency Actual (LHV)  \\\n",
              "Date_Time                                         \n",
              "2023-01-20 17:00:00                      34.919   \n",
              "2023-01-20 18:00:00                      35.239   \n",
              "2023-01-20 19:00:00                      35.913   \n",
              "2023-01-20 20:00:00                      35.783   \n",
              "2023-01-20 21:00:00                      35.513   \n",
              "\n",
              "                     Combust Monitor Actual Spread 2  \\\n",
              "Date_Time                                              \n",
              "2023-01-20 17:00:00                           31.110   \n",
              "2023-01-20 18:00:00                           24.820   \n",
              "2023-01-20 19:00:00                           27.752   \n",
              "2023-01-20 20:00:00                           28.361   \n",
              "2023-01-20 21:00:00                           15.186   \n",
              "\n",
              "                     GT Exhaust Gas Flow - HB  ...  Turb Exhaust T/C 23  \\\n",
              "Date_Time                                      ...                        \n",
              "2023-01-20 17:00:00                   650.398  ...              608.536   \n",
              "2023-01-20 18:00:00                   635.450  ...              606.971   \n",
              "2023-01-20 19:00:00                   531.246  ...              637.373   \n",
              "2023-01-20 20:00:00                   548.814  ...              632.764   \n",
              "2023-01-20 21:00:00                   504.648  ...              636.851   \n",
              "\n",
              "                     Turb Exhaust T/C 24  Turb Exhaust T/C 25  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              605.209              601.492   \n",
              "2023-01-20 18:00:00              595.928              589.052   \n",
              "2023-01-20 19:00:00              643.240              637.800   \n",
              "2023-01-20 20:00:00              648.446              627.277   \n",
              "2023-01-20 21:00:00              641.639              638.126   \n",
              "\n",
              "                     Turb Exhaust T/C 26  Turb Exhaust T/C 27  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              610.876              615.695   \n",
              "2023-01-20 18:00:00              595.202              609.593   \n",
              "2023-01-20 19:00:00              623.243              636.460   \n",
              "2023-01-20 20:00:00              618.795              641.789   \n",
              "2023-01-20 21:00:00              639.001              628.511   \n",
              "\n",
              "                     Turb Exhaust T/C 28  Turb Exhaust T/C 29  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              628.713              611.376   \n",
              "2023-01-20 18:00:00              616.492              608.235   \n",
              "2023-01-20 19:00:00              648.020              645.099   \n",
              "2023-01-20 20:00:00              640.982              649.530   \n",
              "2023-01-20 21:00:00              633.543              643.794   \n",
              "\n",
              "                     Turb Exhaust T/C 30  Turb Exhaust T/C 31  \\\n",
              "Date_Time                                                       \n",
              "2023-01-20 17:00:00              604.494              619.819   \n",
              "2023-01-20 18:00:00              600.413              600.202   \n",
              "2023-01-20 19:00:00              648.190              637.079   \n",
              "2023-01-20 20:00:00              641.044              630.275   \n",
              "2023-01-20 21:00:00              639.210              642.735   \n",
              "\n",
              "                     Combust Monitor Actual Spread 1  \n",
              "Date_Time                                             \n",
              "2023-01-20 17:00:00                           32.684  \n",
              "2023-01-20 18:00:00                           32.458  \n",
              "2023-01-20 19:00:00                           34.742  \n",
              "2023-01-20 20:00:00                           35.122  \n",
              "2023-01-20 21:00:00                           19.609  \n",
              "\n",
              "[5 rows x 40 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0dd296f7-c0a1-4f5e-a05c-3a55da7b92b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gt Exhaust Outlet Temp</th>\n",
              "      <th>GT Fuel Gas Mass Flow</th>\n",
              "      <th>GT Gross MW</th>\n",
              "      <th>GT Compres Inlet Temp</th>\n",
              "      <th>GT IGV Position</th>\n",
              "      <th>GT Turbine Inlet Temperature</th>\n",
              "      <th>GT Swirl Angle</th>\n",
              "      <th>GT Efficiency Actual (LHV)</th>\n",
              "      <th>Combust Monitor Actual Spread 2</th>\n",
              "      <th>GT Exhaust Gas Flow - HB</th>\n",
              "      <th>...</th>\n",
              "      <th>Turb Exhaust T/C 23</th>\n",
              "      <th>Turb Exhaust T/C 24</th>\n",
              "      <th>Turb Exhaust T/C 25</th>\n",
              "      <th>Turb Exhaust T/C 26</th>\n",
              "      <th>Turb Exhaust T/C 27</th>\n",
              "      <th>Turb Exhaust T/C 28</th>\n",
              "      <th>Turb Exhaust T/C 29</th>\n",
              "      <th>Turb Exhaust T/C 30</th>\n",
              "      <th>Turb Exhaust T/C 31</th>\n",
              "      <th>Combust Monitor Actual Spread 1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date_Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-20 17:00:00</th>\n",
              "      <td>611.855</td>\n",
              "      <td>13.760</td>\n",
              "      <td>231.782</td>\n",
              "      <td>18.940</td>\n",
              "      <td>87.999</td>\n",
              "      <td>1255.732</td>\n",
              "      <td>14.534</td>\n",
              "      <td>34.919</td>\n",
              "      <td>31.110</td>\n",
              "      <td>650.398</td>\n",
              "      <td>...</td>\n",
              "      <td>608.536</td>\n",
              "      <td>605.209</td>\n",
              "      <td>601.492</td>\n",
              "      <td>610.876</td>\n",
              "      <td>615.695</td>\n",
              "      <td>628.713</td>\n",
              "      <td>611.376</td>\n",
              "      <td>604.494</td>\n",
              "      <td>619.819</td>\n",
              "      <td>32.684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 18:00:00</th>\n",
              "      <td>604.004</td>\n",
              "      <td>13.175</td>\n",
              "      <td>226.570</td>\n",
              "      <td>18.938</td>\n",
              "      <td>84.113</td>\n",
              "      <td>1244.014</td>\n",
              "      <td>19.430</td>\n",
              "      <td>35.239</td>\n",
              "      <td>24.820</td>\n",
              "      <td>635.450</td>\n",
              "      <td>...</td>\n",
              "      <td>606.971</td>\n",
              "      <td>595.928</td>\n",
              "      <td>589.052</td>\n",
              "      <td>595.202</td>\n",
              "      <td>609.593</td>\n",
              "      <td>616.492</td>\n",
              "      <td>608.235</td>\n",
              "      <td>600.413</td>\n",
              "      <td>600.202</td>\n",
              "      <td>32.458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 19:00:00</th>\n",
              "      <td>637.918</td>\n",
              "      <td>11.979</td>\n",
              "      <td>207.629</td>\n",
              "      <td>18.780</td>\n",
              "      <td>65.027</td>\n",
              "      <td>1284.943</td>\n",
              "      <td>38.101</td>\n",
              "      <td>35.913</td>\n",
              "      <td>27.752</td>\n",
              "      <td>531.246</td>\n",
              "      <td>...</td>\n",
              "      <td>637.373</td>\n",
              "      <td>643.240</td>\n",
              "      <td>637.800</td>\n",
              "      <td>623.243</td>\n",
              "      <td>636.460</td>\n",
              "      <td>648.020</td>\n",
              "      <td>645.099</td>\n",
              "      <td>648.190</td>\n",
              "      <td>637.079</td>\n",
              "      <td>34.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 20:00:00</th>\n",
              "      <td>636.447</td>\n",
              "      <td>12.306</td>\n",
              "      <td>212.659</td>\n",
              "      <td>18.626</td>\n",
              "      <td>67.205</td>\n",
              "      <td>1283.541</td>\n",
              "      <td>33.234</td>\n",
              "      <td>35.783</td>\n",
              "      <td>28.361</td>\n",
              "      <td>548.814</td>\n",
              "      <td>...</td>\n",
              "      <td>632.764</td>\n",
              "      <td>648.446</td>\n",
              "      <td>627.277</td>\n",
              "      <td>618.795</td>\n",
              "      <td>641.789</td>\n",
              "      <td>640.982</td>\n",
              "      <td>649.530</td>\n",
              "      <td>641.044</td>\n",
              "      <td>630.275</td>\n",
              "      <td>35.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-20 21:00:00</th>\n",
              "      <td>637.513</td>\n",
              "      <td>11.290</td>\n",
              "      <td>193.451</td>\n",
              "      <td>17.743</td>\n",
              "      <td>60.577</td>\n",
              "      <td>1270.635</td>\n",
              "      <td>51.623</td>\n",
              "      <td>35.513</td>\n",
              "      <td>15.186</td>\n",
              "      <td>504.648</td>\n",
              "      <td>...</td>\n",
              "      <td>636.851</td>\n",
              "      <td>641.639</td>\n",
              "      <td>638.126</td>\n",
              "      <td>639.001</td>\n",
              "      <td>628.511</td>\n",
              "      <td>633.543</td>\n",
              "      <td>643.794</td>\n",
              "      <td>639.210</td>\n",
              "      <td>642.735</td>\n",
              "      <td>19.609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 40 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0dd296f7-c0a1-4f5e-a05c-3a55da7b92b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0dd296f7-c0a1-4f5e-a05c-3a55da7b92b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0dd296f7-c0a1-4f5e-a05c-3a55da7b92b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7a302ff-6ac5-4a10-afa3-ddb2b25cf3cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7a302ff-6ac5-4a10-afa3-ddb2b25cf3cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7a302ff-6ac5-4a10-afa3-ddb2b25cf3cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "iOH_0t5Y6VNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb870b5-3e12-4a3f-d80d-2a6d7766a2b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2743 entries, 2023-01-20 17:00:00 to 2023-10-29 22:00:00\n",
            "Data columns (total 40 columns):\n",
            " #   Column                           Non-Null Count  Dtype  \n",
            "---  ------                           --------------  -----  \n",
            " 0   Gt Exhaust Outlet Temp           2743 non-null   float64\n",
            " 1   GT Fuel Gas Mass Flow            2743 non-null   float64\n",
            " 2   GT Gross MW                      2743 non-null   float64\n",
            " 3   GT Compres Inlet Temp            2743 non-null   float64\n",
            " 4   GT IGV Position                  2743 non-null   float64\n",
            " 5   GT Turbine Inlet Temperature     2743 non-null   float64\n",
            " 6   GT Swirl Angle                   2743 non-null   float64\n",
            " 7   GT Efficiency Actual (LHV)       2743 non-null   float64\n",
            " 8   Combust Monitor Actual Spread 2  2743 non-null   float64\n",
            " 9   GT Exhaust Gas Flow - HB         2743 non-null   float64\n",
            " 10  Combust Monitor Actual Spread 3  2743 non-null   float64\n",
            " 11  Turb Exhaust T/C 2               2743 non-null   float64\n",
            " 12  Turb Exhaust T/C 3               2743 non-null   float64\n",
            " 13  Turb Exhaust T/C 4               2743 non-null   float64\n",
            " 14  Turb Exhaust T/C 5               2743 non-null   float64\n",
            " 15  Turb Exhaust T/C 6               2743 non-null   float64\n",
            " 16  Turb Exhaust T/C 7               2743 non-null   float64\n",
            " 17  Turb Exhaust T/C 8               2743 non-null   float64\n",
            " 18  Turb Exhaust T/C 9               2743 non-null   float64\n",
            " 19  Turb Exhaust T/C 10              2743 non-null   float64\n",
            " 20  Turb Exhaust T/C 11              2743 non-null   float64\n",
            " 21  Turb Exhaust T/C 13              2743 non-null   float64\n",
            " 22  Turb Exhaust T/C 14              2743 non-null   float64\n",
            " 23  Turb Exhaust T/C 16              2743 non-null   float64\n",
            " 24  Turb Exhaust T/C 17              2743 non-null   float64\n",
            " 25  Turb Exhaust T/C 18              2743 non-null   float64\n",
            " 26  Turb Exhaust T/C 19              2743 non-null   float64\n",
            " 27  Turb Exhaust T/C 20              2743 non-null   float64\n",
            " 28  Turb Exhaust T/C 21              2743 non-null   float64\n",
            " 29  Turb Exhaust T/C 22              2743 non-null   float64\n",
            " 30  Turb Exhaust T/C 23              2743 non-null   float64\n",
            " 31  Turb Exhaust T/C 24              2743 non-null   float64\n",
            " 32  Turb Exhaust T/C 25              2743 non-null   float64\n",
            " 33  Turb Exhaust T/C 26              2743 non-null   float64\n",
            " 34  Turb Exhaust T/C 27              2743 non-null   float64\n",
            " 35  Turb Exhaust T/C 28              2743 non-null   float64\n",
            " 36  Turb Exhaust T/C 29              2743 non-null   float64\n",
            " 37  Turb Exhaust T/C 30              2743 non-null   float64\n",
            " 38  Turb Exhaust T/C 31              2743 non-null   float64\n",
            " 39  Combust Monitor Actual Spread 1  2743 non-null   float64\n",
            "dtypes: float64(40)\n",
            "memory usage: 878.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_object(obj , name):\n",
        "    pickle_obj = open(f\"{name}.pck\",\"wb\")\n",
        "    pickle.dump(obj, pickle_obj)\n",
        "    pickle_obj.close()"
      ],
      "metadata": {
        "id": "dlPH0K2L0z8n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_columns = list(data.columns)\n",
        "remaining_columns.remove(\"Combust Monitor Actual Spread 1\")"
      ],
      "metadata": {
        "id": "O3fEOAMI6VTi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[remaining_columns].values\n",
        "Y = data['Combust Monitor Actual Spread 1'].values"
      ],
      "metadata": {
        "id": "sIi0rAAHm7je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "QSSDnV4mGoIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2e5124-7ece-4ce9-df0e-9e9d75de486a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gt Exhaust Outlet Temp', 'GT Fuel Gas Mass Flow', 'GT Gross MW',\n",
              "       'GT Compres Inlet Temp', 'GT IGV Position',\n",
              "       'GT Turbine Inlet Temperature', 'GT Swirl Angle',\n",
              "       'GT Efficiency Actual (LHV)', 'Combust Monitor Actual Spread 2',\n",
              "       'GT Exhaust Gas Flow - HB', 'Combust Monitor Actual Spread 3',\n",
              "       'Turb Exhaust T/C 2', 'Turb Exhaust T/C 3', 'Turb Exhaust T/C 4',\n",
              "       'Turb Exhaust T/C 5', 'Turb Exhaust T/C 6', 'Turb Exhaust T/C 7',\n",
              "       'Turb Exhaust T/C 8', 'Turb Exhaust T/C 9', 'Turb Exhaust T/C 10',\n",
              "       'Turb Exhaust T/C 11', 'Turb Exhaust T/C 13', 'Turb Exhaust T/C 14',\n",
              "       'Turb Exhaust T/C 16', 'Turb Exhaust T/C 17', 'Turb Exhaust T/C 18',\n",
              "       'Turb Exhaust T/C 19', 'Turb Exhaust T/C 20', 'Turb Exhaust T/C 21',\n",
              "       'Turb Exhaust T/C 22', 'Turb Exhaust T/C 23', 'Turb Exhaust T/C 24',\n",
              "       'Turb Exhaust T/C 25', 'Turb Exhaust T/C 26', 'Turb Exhaust T/C 27',\n",
              "       'Turb Exhaust T/C 28', 'Turb Exhaust T/C 29', 'Turb Exhaust T/C 30',\n",
              "       'Turb Exhaust T/C 31', 'Combust Monitor Actual Spread 1'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain , Xtest , Ytrain , Ytest = train_test_split(X , Y , test_size = 0.2 , random_state = 4)"
      ],
      "metadata": {
        "id": "lKNlEbvl6VV4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(Xtrain)\n",
        "\n",
        "Xtrain_scaled = scaler.transform(Xtrain)\n",
        "Xtest_scaled = scaler.transform(Xtest)"
      ],
      "metadata": {
        "id": "97ydOg056VYs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_object(scaler,\"scaler\")"
      ],
      "metadata": {
        "id": "296OJsUw05TT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported Network designed in previous lesson\n",
        "\n",
        "# Start your model with Sequential Object\n",
        "model = tf.keras.models.Sequential()\n",
        "# Next add in your Input object and Specify the Dimension you want to pass in\n",
        "model.add(tf.keras.Input(shape=(39,)))\n",
        "# Add in your Neurons of 1st layer\n",
        "model.add(tf.keras.layers.Dense(1000, activation='sigmoid'))\n",
        "# 2nd layer\n",
        "model.add(tf.keras.layers.Dense(500, activation='sigmoid'))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1 , activation='linear'))\n",
        "\n",
        "\n",
        "Optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(Optimizer, loss=\"mean_squared_error\", metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "# print summary to undertstand your neural network flow\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "eUu-P0lz6VbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe19c71-0970-4c9e-c6f6-30a01067ef82"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1000)              40000     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 500)               500500    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 541001 (2.06 MB)\n",
            "Trainable params: 541001 (2.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xtrain_scaled , Ytrain , validation_data=(Xtest_scaled , Ytest) , epochs=1000)"
      ],
      "metadata": {
        "id": "arJHOFaJta5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eaaeab8-2536-472d-8037-b3f87270ea44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "69/69 [==============================] - 6s 5ms/step - loss: 113.2793 - mae: 8.7460 - val_loss: 19.4140 - val_mae: 3.7735\n",
            "Epoch 2/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 13.9803 - mae: 2.8707 - val_loss: 14.9880 - val_mae: 2.8336\n",
            "Epoch 3/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 9.6476 - mae: 2.2988 - val_loss: 6.7811 - val_mae: 1.9166\n",
            "Epoch 4/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 5.2899 - mae: 1.7624 - val_loss: 5.9476 - val_mae: 1.7857\n",
            "Epoch 5/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.8863 - mae: 1.6841 - val_loss: 5.7418 - val_mae: 1.7491\n",
            "Epoch 6/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.7286 - mae: 1.6576 - val_loss: 5.6409 - val_mae: 1.7261\n",
            "Epoch 7/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.6198 - mae: 1.6436 - val_loss: 5.4023 - val_mae: 1.7016\n",
            "Epoch 8/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 4.4660 - mae: 1.6162 - val_loss: 5.3034 - val_mae: 1.6902\n",
            "Epoch 9/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 4.1895 - mae: 1.5779 - val_loss: 4.7159 - val_mae: 1.6383\n",
            "Epoch 10/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 3.7107 - mae: 1.5033 - val_loss: 3.6488 - val_mae: 1.5058\n",
            "Epoch 11/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 3.0357 - mae: 1.3767 - val_loss: 2.9804 - val_mae: 1.3435\n",
            "Epoch 12/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.5907 - mae: 1.2711 - val_loss: 2.6588 - val_mae: 1.2530\n",
            "Epoch 13/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3959 - mae: 1.2204 - val_loss: 2.4265 - val_mae: 1.2008\n",
            "Epoch 14/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.3368 - mae: 1.2015 - val_loss: 2.2780 - val_mae: 1.1552\n",
            "Epoch 15/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.1410 - mae: 1.1522 - val_loss: 2.2146 - val_mae: 1.1377\n",
            "Epoch 16/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0784 - mae: 1.1342 - val_loss: 2.1425 - val_mae: 1.1168\n",
            "Epoch 17/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 2.0420 - mae: 1.1208 - val_loss: 2.3239 - val_mae: 1.1639\n",
            "Epoch 18/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9430 - mae: 1.0951 - val_loss: 2.0054 - val_mae: 1.0787\n",
            "Epoch 19/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.9105 - mae: 1.0853 - val_loss: 1.9018 - val_mae: 1.0641\n",
            "Epoch 20/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8950 - mae: 1.0744 - val_loss: 1.9410 - val_mae: 1.0681\n",
            "Epoch 21/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.8827 - mae: 1.0741 - val_loss: 1.8850 - val_mae: 1.0502\n",
            "Epoch 22/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.8325 - mae: 1.0583 - val_loss: 1.8374 - val_mae: 1.0506\n",
            "Epoch 23/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7988 - mae: 1.0458 - val_loss: 1.8757 - val_mae: 1.0552\n",
            "Epoch 24/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7570 - mae: 1.0347 - val_loss: 1.7802 - val_mae: 1.0398\n",
            "Epoch 25/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7952 - mae: 1.0505 - val_loss: 1.7823 - val_mae: 1.0237\n",
            "Epoch 26/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7382 - mae: 1.0272 - val_loss: 1.7033 - val_mae: 1.0061\n",
            "Epoch 27/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.7521 - mae: 1.0358 - val_loss: 1.7866 - val_mae: 1.0272\n",
            "Epoch 28/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6683 - mae: 1.0046 - val_loss: 2.0422 - val_mae: 1.0896\n",
            "Epoch 29/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.7217 - mae: 1.0260 - val_loss: 1.8539 - val_mae: 1.0403\n",
            "Epoch 30/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6631 - mae: 1.0061 - val_loss: 1.7231 - val_mae: 1.0059\n",
            "Epoch 31/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6688 - mae: 1.0155 - val_loss: 1.7079 - val_mae: 1.0012\n",
            "Epoch 32/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6322 - mae: 1.0015 - val_loss: 1.6728 - val_mae: 0.9949\n",
            "Epoch 33/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6949 - mae: 1.0173 - val_loss: 1.6687 - val_mae: 0.9939\n",
            "Epoch 34/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6946 - mae: 1.0093 - val_loss: 1.7786 - val_mae: 1.0516\n",
            "Epoch 35/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6230 - mae: 0.9951 - val_loss: 1.7656 - val_mae: 1.0414\n",
            "Epoch 36/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6093 - mae: 0.9880 - val_loss: 1.6282 - val_mae: 0.9917\n",
            "Epoch 37/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5910 - mae: 0.9871 - val_loss: 1.7879 - val_mae: 1.0185\n",
            "Epoch 38/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6188 - mae: 0.9929 - val_loss: 1.5653 - val_mae: 0.9646\n",
            "Epoch 39/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6252 - mae: 0.9897 - val_loss: 1.6085 - val_mae: 0.9815\n",
            "Epoch 40/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5689 - mae: 0.9747 - val_loss: 1.5466 - val_mae: 0.9633\n",
            "Epoch 41/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6379 - mae: 0.9970 - val_loss: 1.9390 - val_mae: 1.0673\n",
            "Epoch 42/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.6030 - mae: 0.9874 - val_loss: 1.5539 - val_mae: 0.9549\n",
            "Epoch 43/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5249 - mae: 0.9608 - val_loss: 1.5218 - val_mae: 0.9530\n",
            "Epoch 44/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5427 - mae: 0.9642 - val_loss: 1.5520 - val_mae: 0.9592\n",
            "Epoch 45/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5169 - mae: 0.9574 - val_loss: 1.7618 - val_mae: 1.0071\n",
            "Epoch 46/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.5831 - mae: 0.9740 - val_loss: 1.5645 - val_mae: 0.9720\n",
            "Epoch 47/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5325 - mae: 0.9596 - val_loss: 1.5727 - val_mae: 0.9597\n",
            "Epoch 48/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4984 - mae: 0.9486 - val_loss: 1.5315 - val_mae: 0.9476\n",
            "Epoch 49/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4821 - mae: 0.9401 - val_loss: 1.5421 - val_mae: 0.9556\n",
            "Epoch 50/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.5063 - mae: 0.9566 - val_loss: 1.5098 - val_mae: 0.9431\n",
            "Epoch 51/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4613 - mae: 0.9390 - val_loss: 1.5822 - val_mae: 0.9731\n",
            "Epoch 52/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4662 - mae: 0.9350 - val_loss: 1.5383 - val_mae: 0.9607\n",
            "Epoch 53/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4720 - mae: 0.9451 - val_loss: 1.5295 - val_mae: 0.9518\n",
            "Epoch 54/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4907 - mae: 0.9552 - val_loss: 1.7627 - val_mae: 1.0174\n",
            "Epoch 55/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4603 - mae: 0.9372 - val_loss: 1.5226 - val_mae: 0.9493\n",
            "Epoch 56/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4830 - mae: 0.9507 - val_loss: 1.5500 - val_mae: 0.9537\n",
            "Epoch 57/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4711 - mae: 0.9383 - val_loss: 1.6546 - val_mae: 0.9887\n",
            "Epoch 58/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4895 - mae: 0.9508 - val_loss: 1.4746 - val_mae: 0.9330\n",
            "Epoch 59/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4686 - mae: 0.9447 - val_loss: 1.4799 - val_mae: 0.9421\n",
            "Epoch 60/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4937 - mae: 0.9499 - val_loss: 1.5622 - val_mae: 0.9760\n",
            "Epoch 61/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4173 - mae: 0.9204 - val_loss: 1.5331 - val_mae: 0.9569\n",
            "Epoch 62/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4216 - mae: 0.9243 - val_loss: 1.4917 - val_mae: 0.9391\n",
            "Epoch 63/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4108 - mae: 0.9207 - val_loss: 1.4857 - val_mae: 0.9432\n",
            "Epoch 64/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3880 - mae: 0.9137 - val_loss: 1.4699 - val_mae: 0.9364\n",
            "Epoch 65/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4438 - mae: 0.9354 - val_loss: 1.4642 - val_mae: 0.9401\n",
            "Epoch 66/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3730 - mae: 0.9095 - val_loss: 1.6958 - val_mae: 0.9917\n",
            "Epoch 67/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3758 - mae: 0.9127 - val_loss: 1.5017 - val_mae: 0.9418\n",
            "Epoch 68/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3975 - mae: 0.9206 - val_loss: 1.7035 - val_mae: 0.9848\n",
            "Epoch 69/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.4037 - mae: 0.9225 - val_loss: 1.4536 - val_mae: 0.9287\n",
            "Epoch 70/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4367 - mae: 0.9354 - val_loss: 1.9607 - val_mae: 1.0664\n",
            "Epoch 71/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.4202 - mae: 0.9284 - val_loss: 1.6722 - val_mae: 0.9855\n",
            "Epoch 72/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3893 - mae: 0.9123 - val_loss: 1.5006 - val_mae: 0.9467\n",
            "Epoch 73/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3899 - mae: 0.9121 - val_loss: 1.4771 - val_mae: 0.9414\n",
            "Epoch 74/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3805 - mae: 0.9092 - val_loss: 1.4720 - val_mae: 0.9351\n",
            "Epoch 75/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3430 - mae: 0.8953 - val_loss: 1.4706 - val_mae: 0.9383\n",
            "Epoch 76/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3529 - mae: 0.8992 - val_loss: 1.4227 - val_mae: 0.9190\n",
            "Epoch 77/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3285 - mae: 0.8933 - val_loss: 1.4469 - val_mae: 0.9363\n",
            "Epoch 78/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3631 - mae: 0.9080 - val_loss: 1.4232 - val_mae: 0.9197\n",
            "Epoch 79/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3449 - mae: 0.8955 - val_loss: 1.4940 - val_mae: 0.9393\n",
            "Epoch 80/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.3623 - mae: 0.9075 - val_loss: 1.4939 - val_mae: 0.9326\n",
            "Epoch 81/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3497 - mae: 0.9033 - val_loss: 1.4509 - val_mae: 0.9337\n",
            "Epoch 82/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3253 - mae: 0.8926 - val_loss: 1.3935 - val_mae: 0.9084\n",
            "Epoch 83/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3443 - mae: 0.8996 - val_loss: 1.4958 - val_mae: 0.9304\n",
            "Epoch 84/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3181 - mae: 0.8912 - val_loss: 1.4074 - val_mae: 0.9152\n",
            "Epoch 85/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3616 - mae: 0.9057 - val_loss: 1.4557 - val_mae: 0.9389\n",
            "Epoch 86/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3877 - mae: 0.9146 - val_loss: 1.4055 - val_mae: 0.9190\n",
            "Epoch 87/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3153 - mae: 0.8915 - val_loss: 1.3989 - val_mae: 0.8964\n",
            "Epoch 88/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3558 - mae: 0.9035 - val_loss: 1.3988 - val_mae: 0.9037\n",
            "Epoch 89/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2847 - mae: 0.8763 - val_loss: 1.4862 - val_mae: 0.9425\n",
            "Epoch 90/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2905 - mae: 0.8796 - val_loss: 1.4255 - val_mae: 0.9138\n",
            "Epoch 91/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2566 - mae: 0.8685 - val_loss: 1.4463 - val_mae: 0.9446\n",
            "Epoch 92/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.3084 - mae: 0.8854 - val_loss: 1.4358 - val_mae: 0.9095\n",
            "Epoch 93/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2738 - mae: 0.8762 - val_loss: 1.4334 - val_mae: 0.9027\n",
            "Epoch 94/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2644 - mae: 0.8684 - val_loss: 1.4248 - val_mae: 0.9103\n",
            "Epoch 95/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2555 - mae: 0.8665 - val_loss: 1.4142 - val_mae: 0.9046\n",
            "Epoch 96/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2723 - mae: 0.8762 - val_loss: 1.4207 - val_mae: 0.9084\n",
            "Epoch 97/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2487 - mae: 0.8657 - val_loss: 1.3601 - val_mae: 0.9009\n",
            "Epoch 98/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2723 - mae: 0.8822 - val_loss: 1.3753 - val_mae: 0.8955\n",
            "Epoch 99/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2536 - mae: 0.8690 - val_loss: 1.3185 - val_mae: 0.8765\n",
            "Epoch 100/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2049 - mae: 0.8471 - val_loss: 1.3328 - val_mae: 0.8858\n",
            "Epoch 101/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2141 - mae: 0.8535 - val_loss: 1.4654 - val_mae: 0.9216\n",
            "Epoch 102/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2188 - mae: 0.8541 - val_loss: 1.3749 - val_mae: 0.9143\n",
            "Epoch 103/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1843 - mae: 0.8436 - val_loss: 1.3242 - val_mae: 0.8712\n",
            "Epoch 104/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1716 - mae: 0.8381 - val_loss: 1.4773 - val_mae: 0.9270\n",
            "Epoch 105/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2105 - mae: 0.8528 - val_loss: 1.4086 - val_mae: 0.9207\n",
            "Epoch 106/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1876 - mae: 0.8449 - val_loss: 1.2854 - val_mae: 0.8550\n",
            "Epoch 107/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1923 - mae: 0.8465 - val_loss: 1.3969 - val_mae: 0.8881\n",
            "Epoch 108/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1385 - mae: 0.8260 - val_loss: 1.4647 - val_mae: 0.9037\n",
            "Epoch 109/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1922 - mae: 0.8470 - val_loss: 1.3121 - val_mae: 0.8788\n",
            "Epoch 110/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1573 - mae: 0.8347 - val_loss: 1.3300 - val_mae: 0.8904\n",
            "Epoch 111/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1866 - mae: 0.8505 - val_loss: 1.4601 - val_mae: 0.9120\n",
            "Epoch 112/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.2377 - mae: 0.8565 - val_loss: 1.2720 - val_mae: 0.8608\n",
            "Epoch 113/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1716 - mae: 0.8437 - val_loss: 1.5121 - val_mae: 0.9418\n",
            "Epoch 114/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1327 - mae: 0.8266 - val_loss: 1.2601 - val_mae: 0.8591\n",
            "Epoch 115/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1546 - mae: 0.8330 - val_loss: 1.3526 - val_mae: 0.8835\n",
            "Epoch 116/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0893 - mae: 0.8099 - val_loss: 1.3232 - val_mae: 0.8751\n",
            "Epoch 117/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1386 - mae: 0.8304 - val_loss: 1.2324 - val_mae: 0.8402\n",
            "Epoch 118/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0863 - mae: 0.8103 - val_loss: 1.2854 - val_mae: 0.8587\n",
            "Epoch 119/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1406 - mae: 0.8312 - val_loss: 1.2484 - val_mae: 0.8568\n",
            "Epoch 120/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0776 - mae: 0.8009 - val_loss: 1.2213 - val_mae: 0.8444\n",
            "Epoch 121/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1143 - mae: 0.8236 - val_loss: 1.3360 - val_mae: 0.8791\n",
            "Epoch 122/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1560 - mae: 0.8384 - val_loss: 1.2501 - val_mae: 0.8449\n",
            "Epoch 123/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1180 - mae: 0.8228 - val_loss: 1.3812 - val_mae: 0.8786\n",
            "Epoch 124/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.0619 - mae: 0.7975 - val_loss: 1.2393 - val_mae: 0.8515\n",
            "Epoch 125/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0742 - mae: 0.8002 - val_loss: 1.3015 - val_mae: 0.8864\n",
            "Epoch 126/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0679 - mae: 0.8026 - val_loss: 1.3032 - val_mae: 0.8561\n",
            "Epoch 127/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0837 - mae: 0.8071 - val_loss: 1.2819 - val_mae: 0.8587\n",
            "Epoch 128/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1544 - mae: 0.8354 - val_loss: 1.3634 - val_mae: 0.8967\n",
            "Epoch 129/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.0456 - mae: 0.7901 - val_loss: 1.1726 - val_mae: 0.8246\n",
            "Epoch 130/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0361 - mae: 0.7894 - val_loss: 1.3104 - val_mae: 0.8817\n",
            "Epoch 131/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0210 - mae: 0.7874 - val_loss: 1.3313 - val_mae: 0.8804\n",
            "Epoch 132/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.1274 - mae: 0.8292 - val_loss: 1.2666 - val_mae: 0.8585\n",
            "Epoch 133/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.0226 - mae: 0.7874 - val_loss: 1.2322 - val_mae: 0.8387\n",
            "Epoch 134/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0844 - mae: 0.8111 - val_loss: 1.2764 - val_mae: 0.8617\n",
            "Epoch 135/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.9990 - mae: 0.7765 - val_loss: 1.2693 - val_mae: 0.8532\n",
            "Epoch 136/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0332 - mae: 0.7843 - val_loss: 1.2319 - val_mae: 0.8424\n",
            "Epoch 137/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0064 - mae: 0.7826 - val_loss: 1.2036 - val_mae: 0.8346\n",
            "Epoch 138/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0214 - mae: 0.7848 - val_loss: 1.2487 - val_mae: 0.8477\n",
            "Epoch 139/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9987 - mae: 0.7715 - val_loss: 1.4373 - val_mae: 0.9114\n",
            "Epoch 140/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0142 - mae: 0.7812 - val_loss: 1.2036 - val_mae: 0.8342\n",
            "Epoch 141/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9984 - mae: 0.7773 - val_loss: 1.3010 - val_mae: 0.8839\n",
            "Epoch 142/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 1.0177 - mae: 0.7913 - val_loss: 1.2245 - val_mae: 0.8348\n",
            "Epoch 143/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9748 - mae: 0.7671 - val_loss: 1.2795 - val_mae: 0.8636\n",
            "Epoch 144/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9853 - mae: 0.7729 - val_loss: 1.2787 - val_mae: 0.8595\n",
            "Epoch 145/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9713 - mae: 0.7682 - val_loss: 1.1972 - val_mae: 0.8266\n",
            "Epoch 146/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9886 - mae: 0.7717 - val_loss: 1.2261 - val_mae: 0.8378\n",
            "Epoch 147/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9882 - mae: 0.7667 - val_loss: 1.1422 - val_mae: 0.8069\n",
            "Epoch 148/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9547 - mae: 0.7528 - val_loss: 1.1682 - val_mae: 0.8172\n",
            "Epoch 149/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9833 - mae: 0.7660 - val_loss: 1.2226 - val_mae: 0.8570\n",
            "Epoch 150/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9360 - mae: 0.7537 - val_loss: 1.2238 - val_mae: 0.8372\n",
            "Epoch 151/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9850 - mae: 0.7714 - val_loss: 1.3270 - val_mae: 0.8733\n",
            "Epoch 152/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9244 - mae: 0.7393 - val_loss: 1.2626 - val_mae: 0.8508\n",
            "Epoch 153/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9710 - mae: 0.7639 - val_loss: 1.3439 - val_mae: 0.8738\n",
            "Epoch 154/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9478 - mae: 0.7543 - val_loss: 1.2731 - val_mae: 0.8521\n",
            "Epoch 155/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9289 - mae: 0.7509 - val_loss: 1.4735 - val_mae: 0.9288\n",
            "Epoch 156/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.9618 - mae: 0.7583 - val_loss: 1.3526 - val_mae: 0.8877\n",
            "Epoch 157/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9207 - mae: 0.7416 - val_loss: 1.1532 - val_mae: 0.8249\n",
            "Epoch 158/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9165 - mae: 0.7412 - val_loss: 1.1881 - val_mae: 0.8265\n",
            "Epoch 159/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8947 - mae: 0.7344 - val_loss: 1.1680 - val_mae: 0.8138\n",
            "Epoch 160/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9112 - mae: 0.7338 - val_loss: 1.1173 - val_mae: 0.8077\n",
            "Epoch 161/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9012 - mae: 0.7377 - val_loss: 1.1327 - val_mae: 0.8074\n",
            "Epoch 162/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9091 - mae: 0.7444 - val_loss: 1.1911 - val_mae: 0.8230\n",
            "Epoch 163/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9200 - mae: 0.7496 - val_loss: 1.2206 - val_mae: 0.8237\n",
            "Epoch 164/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8911 - mae: 0.7312 - val_loss: 1.1302 - val_mae: 0.8150\n",
            "Epoch 165/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.9211 - mae: 0.7453 - val_loss: 1.1848 - val_mae: 0.8290\n",
            "Epoch 166/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8793 - mae: 0.7246 - val_loss: 1.1356 - val_mae: 0.8123\n",
            "Epoch 167/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.9036 - mae: 0.7370 - val_loss: 1.2091 - val_mae: 0.8322\n",
            "Epoch 168/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.9104 - mae: 0.7420 - val_loss: 1.1013 - val_mae: 0.7852\n",
            "Epoch 169/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8499 - mae: 0.7194 - val_loss: 1.2046 - val_mae: 0.8334\n",
            "Epoch 170/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8469 - mae: 0.7118 - val_loss: 1.1286 - val_mae: 0.8030\n",
            "Epoch 171/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8554 - mae: 0.7114 - val_loss: 1.1626 - val_mae: 0.8245\n",
            "Epoch 172/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8425 - mae: 0.7064 - val_loss: 1.1443 - val_mae: 0.8091\n",
            "Epoch 173/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8333 - mae: 0.7086 - val_loss: 1.2051 - val_mae: 0.8259\n",
            "Epoch 174/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8906 - mae: 0.7281 - val_loss: 1.1394 - val_mae: 0.8145\n",
            "Epoch 175/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8667 - mae: 0.7200 - val_loss: 1.1224 - val_mae: 0.8009\n",
            "Epoch 176/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.8086 - mae: 0.6937 - val_loss: 1.1945 - val_mae: 0.8281\n",
            "Epoch 177/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8685 - mae: 0.7209 - val_loss: 1.1251 - val_mae: 0.8025\n",
            "Epoch 178/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.8115 - mae: 0.6999 - val_loss: 1.0765 - val_mae: 0.7861\n",
            "Epoch 179/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8221 - mae: 0.7004 - val_loss: 1.0863 - val_mae: 0.7776\n",
            "Epoch 180/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.8024 - mae: 0.6891 - val_loss: 1.0690 - val_mae: 0.7839\n",
            "Epoch 181/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8083 - mae: 0.6923 - val_loss: 1.0847 - val_mae: 0.7800\n",
            "Epoch 182/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8251 - mae: 0.7051 - val_loss: 1.0890 - val_mae: 0.8022\n",
            "Epoch 183/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8844 - mae: 0.7287 - val_loss: 1.0862 - val_mae: 0.7874\n",
            "Epoch 184/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7963 - mae: 0.6928 - val_loss: 1.1727 - val_mae: 0.8134\n",
            "Epoch 185/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8044 - mae: 0.6965 - val_loss: 1.2135 - val_mae: 0.8190\n",
            "Epoch 186/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8446 - mae: 0.7136 - val_loss: 1.0731 - val_mae: 0.7839\n",
            "Epoch 187/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8267 - mae: 0.7018 - val_loss: 1.0849 - val_mae: 0.7912\n",
            "Epoch 188/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8170 - mae: 0.7067 - val_loss: 1.1410 - val_mae: 0.8032\n",
            "Epoch 189/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8005 - mae: 0.6895 - val_loss: 1.1309 - val_mae: 0.8036\n",
            "Epoch 190/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8125 - mae: 0.7003 - val_loss: 1.2620 - val_mae: 0.8551\n",
            "Epoch 191/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.8061 - mae: 0.6899 - val_loss: 1.1669 - val_mae: 0.8080\n",
            "Epoch 192/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7739 - mae: 0.6784 - val_loss: 1.0732 - val_mae: 0.7861\n",
            "Epoch 193/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7633 - mae: 0.6727 - val_loss: 1.1194 - val_mae: 0.7868\n",
            "Epoch 194/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7462 - mae: 0.6672 - val_loss: 1.0787 - val_mae: 0.7692\n",
            "Epoch 195/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7340 - mae: 0.6548 - val_loss: 1.0532 - val_mae: 0.7690\n",
            "Epoch 196/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7614 - mae: 0.6706 - val_loss: 1.1165 - val_mae: 0.8115\n",
            "Epoch 197/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7801 - mae: 0.6828 - val_loss: 1.0518 - val_mae: 0.7766\n",
            "Epoch 198/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7521 - mae: 0.6612 - val_loss: 1.1493 - val_mae: 0.8109\n",
            "Epoch 199/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7708 - mae: 0.6865 - val_loss: 1.0931 - val_mae: 0.7796\n",
            "Epoch 200/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7322 - mae: 0.6684 - val_loss: 1.0393 - val_mae: 0.7648\n",
            "Epoch 201/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7200 - mae: 0.6524 - val_loss: 1.0405 - val_mae: 0.7863\n",
            "Epoch 202/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7873 - mae: 0.6895 - val_loss: 1.0441 - val_mae: 0.7622\n",
            "Epoch 203/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7137 - mae: 0.6492 - val_loss: 1.0061 - val_mae: 0.7592\n",
            "Epoch 204/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7162 - mae: 0.6513 - val_loss: 1.0397 - val_mae: 0.7661\n",
            "Epoch 205/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7163 - mae: 0.6543 - val_loss: 1.1156 - val_mae: 0.7970\n",
            "Epoch 206/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7025 - mae: 0.6453 - val_loss: 1.0161 - val_mae: 0.7623\n",
            "Epoch 207/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7141 - mae: 0.6544 - val_loss: 1.2040 - val_mae: 0.8405\n",
            "Epoch 208/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7287 - mae: 0.6582 - val_loss: 1.1005 - val_mae: 0.7688\n",
            "Epoch 209/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7381 - mae: 0.6590 - val_loss: 0.9715 - val_mae: 0.7437\n",
            "Epoch 210/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7643 - mae: 0.6792 - val_loss: 1.0064 - val_mae: 0.7559\n",
            "Epoch 211/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6830 - mae: 0.6343 - val_loss: 1.0654 - val_mae: 0.7659\n",
            "Epoch 212/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7151 - mae: 0.6510 - val_loss: 1.0061 - val_mae: 0.7548\n",
            "Epoch 213/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7220 - mae: 0.6563 - val_loss: 1.1264 - val_mae: 0.7995\n",
            "Epoch 214/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6847 - mae: 0.6348 - val_loss: 0.9900 - val_mae: 0.7501\n",
            "Epoch 215/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6870 - mae: 0.6386 - val_loss: 1.0855 - val_mae: 0.7961\n",
            "Epoch 216/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6762 - mae: 0.6325 - val_loss: 1.0362 - val_mae: 0.7796\n",
            "Epoch 217/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7091 - mae: 0.6496 - val_loss: 1.0193 - val_mae: 0.7633\n",
            "Epoch 218/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6854 - mae: 0.6394 - val_loss: 1.0585 - val_mae: 0.7630\n",
            "Epoch 219/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6638 - mae: 0.6303 - val_loss: 1.0784 - val_mae: 0.7676\n",
            "Epoch 220/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7098 - mae: 0.6537 - val_loss: 0.9971 - val_mae: 0.7448\n",
            "Epoch 221/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6680 - mae: 0.6282 - val_loss: 0.9839 - val_mae: 0.7423\n",
            "Epoch 222/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6751 - mae: 0.6305 - val_loss: 1.1131 - val_mae: 0.8058\n",
            "Epoch 223/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.7503 - mae: 0.6668 - val_loss: 1.0858 - val_mae: 0.7882\n",
            "Epoch 224/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6686 - mae: 0.6305 - val_loss: 1.0611 - val_mae: 0.7781\n",
            "Epoch 225/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6423 - mae: 0.6137 - val_loss: 1.0111 - val_mae: 0.7514\n",
            "Epoch 226/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6546 - mae: 0.6276 - val_loss: 0.9926 - val_mae: 0.7427\n",
            "Epoch 227/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6306 - mae: 0.6067 - val_loss: 1.0523 - val_mae: 0.7541\n",
            "Epoch 228/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6575 - mae: 0.6261 - val_loss: 1.0449 - val_mae: 0.7736\n",
            "Epoch 229/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6640 - mae: 0.6235 - val_loss: 1.0383 - val_mae: 0.7675\n",
            "Epoch 230/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6428 - mae: 0.6186 - val_loss: 0.9933 - val_mae: 0.7526\n",
            "Epoch 231/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6356 - mae: 0.6178 - val_loss: 0.9712 - val_mae: 0.7428\n",
            "Epoch 232/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6281 - mae: 0.6099 - val_loss: 1.0817 - val_mae: 0.7918\n",
            "Epoch 233/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6349 - mae: 0.6121 - val_loss: 1.0617 - val_mae: 0.7610\n",
            "Epoch 234/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6625 - mae: 0.6295 - val_loss: 0.9913 - val_mae: 0.7509\n",
            "Epoch 235/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6879 - mae: 0.6419 - val_loss: 0.9657 - val_mae: 0.7304\n",
            "Epoch 236/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6138 - mae: 0.6008 - val_loss: 1.0568 - val_mae: 0.7657\n",
            "Epoch 237/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.6574 - mae: 0.6238 - val_loss: 1.0835 - val_mae: 0.7843\n",
            "Epoch 238/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.6222 - mae: 0.6082 - val_loss: 0.9437 - val_mae: 0.7337\n",
            "Epoch 239/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6364 - mae: 0.6190 - val_loss: 1.2996 - val_mae: 0.9096\n",
            "Epoch 240/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6853 - mae: 0.6453 - val_loss: 0.9681 - val_mae: 0.7339\n",
            "Epoch 241/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6170 - mae: 0.6065 - val_loss: 1.0800 - val_mae: 0.7803\n",
            "Epoch 242/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6155 - mae: 0.6033 - val_loss: 0.9825 - val_mae: 0.7473\n",
            "Epoch 243/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6587 - mae: 0.6240 - val_loss: 1.0292 - val_mae: 0.7547\n",
            "Epoch 244/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6006 - mae: 0.5967 - val_loss: 1.0001 - val_mae: 0.7387\n",
            "Epoch 245/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6508 - mae: 0.6259 - val_loss: 0.9435 - val_mae: 0.7312\n",
            "Epoch 246/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6367 - mae: 0.6155 - val_loss: 0.9389 - val_mae: 0.7239\n",
            "Epoch 247/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5776 - mae: 0.5836 - val_loss: 0.9976 - val_mae: 0.7366\n",
            "Epoch 248/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6187 - mae: 0.6054 - val_loss: 0.9584 - val_mae: 0.7422\n",
            "Epoch 249/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6038 - mae: 0.5962 - val_loss: 0.9556 - val_mae: 0.7310\n",
            "Epoch 250/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6004 - mae: 0.6048 - val_loss: 1.0504 - val_mae: 0.7764\n",
            "Epoch 251/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5933 - mae: 0.5963 - val_loss: 0.9224 - val_mae: 0.7319\n",
            "Epoch 252/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6787 - mae: 0.6345 - val_loss: 0.9852 - val_mae: 0.7557\n",
            "Epoch 253/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6267 - mae: 0.6096 - val_loss: 1.1436 - val_mae: 0.8157\n",
            "Epoch 254/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5860 - mae: 0.5944 - val_loss: 1.0091 - val_mae: 0.7422\n",
            "Epoch 255/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5895 - mae: 0.5899 - val_loss: 0.9735 - val_mae: 0.7376\n",
            "Epoch 256/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.6139 - mae: 0.6097 - val_loss: 0.9796 - val_mae: 0.7368\n",
            "Epoch 257/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5932 - mae: 0.5932 - val_loss: 1.0497 - val_mae: 0.7693\n",
            "Epoch 258/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5760 - mae: 0.5865 - val_loss: 0.9242 - val_mae: 0.7267\n",
            "Epoch 259/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5798 - mae: 0.5939 - val_loss: 0.9563 - val_mae: 0.7258\n",
            "Epoch 260/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5859 - mae: 0.5908 - val_loss: 1.0026 - val_mae: 0.7505\n",
            "Epoch 261/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5778 - mae: 0.5917 - val_loss: 1.0232 - val_mae: 0.7476\n",
            "Epoch 262/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5528 - mae: 0.5711 - val_loss: 0.9988 - val_mae: 0.7594\n",
            "Epoch 263/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5639 - mae: 0.5823 - val_loss: 0.9525 - val_mae: 0.7221\n",
            "Epoch 264/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5293 - mae: 0.5617 - val_loss: 0.9874 - val_mae: 0.7538\n",
            "Epoch 265/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5590 - mae: 0.5762 - val_loss: 1.1120 - val_mae: 0.8100\n",
            "Epoch 266/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5643 - mae: 0.5831 - val_loss: 0.9738 - val_mae: 0.7328\n",
            "Epoch 267/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5532 - mae: 0.5780 - val_loss: 0.9712 - val_mae: 0.7454\n",
            "Epoch 268/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5673 - mae: 0.5811 - val_loss: 0.9296 - val_mae: 0.7284\n",
            "Epoch 269/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5519 - mae: 0.5738 - val_loss: 0.9616 - val_mae: 0.7352\n",
            "Epoch 270/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5559 - mae: 0.5799 - val_loss: 0.9538 - val_mae: 0.7358\n",
            "Epoch 271/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5683 - mae: 0.5803 - val_loss: 1.0408 - val_mae: 0.7652\n",
            "Epoch 272/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5347 - mae: 0.5682 - val_loss: 0.9465 - val_mae: 0.7362\n",
            "Epoch 273/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5270 - mae: 0.5596 - val_loss: 0.9344 - val_mae: 0.7301\n",
            "Epoch 274/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5632 - mae: 0.5806 - val_loss: 1.0406 - val_mae: 0.7648\n",
            "Epoch 275/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5640 - mae: 0.5773 - val_loss: 0.9683 - val_mae: 0.7252\n",
            "Epoch 276/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5765 - mae: 0.5881 - val_loss: 1.0705 - val_mae: 0.7659\n",
            "Epoch 277/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5195 - mae: 0.5562 - val_loss: 0.9815 - val_mae: 0.7313\n",
            "Epoch 278/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5591 - mae: 0.5807 - val_loss: 1.0723 - val_mae: 0.8045\n",
            "Epoch 279/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5835 - mae: 0.5939 - val_loss: 1.0561 - val_mae: 0.7569\n",
            "Epoch 280/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5556 - mae: 0.5758 - val_loss: 0.9805 - val_mae: 0.7329\n",
            "Epoch 281/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5184 - mae: 0.5584 - val_loss: 1.0017 - val_mae: 0.7702\n",
            "Epoch 282/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5327 - mae: 0.5644 - val_loss: 0.9918 - val_mae: 0.7579\n",
            "Epoch 283/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5335 - mae: 0.5648 - val_loss: 0.9740 - val_mae: 0.7365\n",
            "Epoch 284/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4994 - mae: 0.5456 - val_loss: 1.0696 - val_mae: 0.7732\n",
            "Epoch 285/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5222 - mae: 0.5611 - val_loss: 0.9197 - val_mae: 0.7205\n",
            "Epoch 286/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5047 - mae: 0.5483 - val_loss: 1.0302 - val_mae: 0.7526\n",
            "Epoch 287/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5638 - mae: 0.5826 - val_loss: 1.0048 - val_mae: 0.7443\n",
            "Epoch 288/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5412 - mae: 0.5696 - val_loss: 0.9341 - val_mae: 0.7295\n",
            "Epoch 289/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4947 - mae: 0.5444 - val_loss: 0.9785 - val_mae: 0.7364\n",
            "Epoch 290/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5415 - mae: 0.5693 - val_loss: 1.1062 - val_mae: 0.8250\n",
            "Epoch 291/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5140 - mae: 0.5544 - val_loss: 1.0167 - val_mae: 0.7467\n",
            "Epoch 292/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5214 - mae: 0.5615 - val_loss: 1.0196 - val_mae: 0.7669\n",
            "Epoch 293/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5029 - mae: 0.5502 - val_loss: 0.9511 - val_mae: 0.7363\n",
            "Epoch 294/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5103 - mae: 0.5538 - val_loss: 0.9020 - val_mae: 0.7092\n",
            "Epoch 295/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5118 - mae: 0.5521 - val_loss: 1.0048 - val_mae: 0.7395\n",
            "Epoch 296/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5146 - mae: 0.5576 - val_loss: 1.0207 - val_mae: 0.7728\n",
            "Epoch 297/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4849 - mae: 0.5449 - val_loss: 1.0542 - val_mae: 0.7592\n",
            "Epoch 298/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5176 - mae: 0.5595 - val_loss: 0.9770 - val_mae: 0.7323\n",
            "Epoch 299/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4945 - mae: 0.5408 - val_loss: 0.9197 - val_mae: 0.7113\n",
            "Epoch 300/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4832 - mae: 0.5377 - val_loss: 0.9319 - val_mae: 0.7225\n",
            "Epoch 301/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4916 - mae: 0.5466 - val_loss: 0.9591 - val_mae: 0.7489\n",
            "Epoch 302/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4904 - mae: 0.5457 - val_loss: 0.9808 - val_mae: 0.7539\n",
            "Epoch 303/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.5127 - mae: 0.5547 - val_loss: 0.9802 - val_mae: 0.7561\n",
            "Epoch 304/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4899 - mae: 0.5403 - val_loss: 0.9802 - val_mae: 0.7240\n",
            "Epoch 305/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4671 - mae: 0.5308 - val_loss: 0.9540 - val_mae: 0.7201\n",
            "Epoch 306/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4852 - mae: 0.5382 - val_loss: 0.9423 - val_mae: 0.7369\n",
            "Epoch 307/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4788 - mae: 0.5404 - val_loss: 0.9610 - val_mae: 0.7239\n",
            "Epoch 308/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4788 - mae: 0.5337 - val_loss: 0.9772 - val_mae: 0.7281\n",
            "Epoch 309/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4720 - mae: 0.5355 - val_loss: 0.9908 - val_mae: 0.7542\n",
            "Epoch 310/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4813 - mae: 0.5389 - val_loss: 0.9402 - val_mae: 0.7212\n",
            "Epoch 311/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4525 - mae: 0.5270 - val_loss: 1.0061 - val_mae: 0.7550\n",
            "Epoch 312/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4682 - mae: 0.5304 - val_loss: 0.9684 - val_mae: 0.7395\n",
            "Epoch 313/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4779 - mae: 0.5323 - val_loss: 1.0405 - val_mae: 0.7511\n",
            "Epoch 314/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4655 - mae: 0.5303 - val_loss: 0.9645 - val_mae: 0.7234\n",
            "Epoch 315/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4565 - mae: 0.5274 - val_loss: 1.0447 - val_mae: 0.7588\n",
            "Epoch 316/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4533 - mae: 0.5203 - val_loss: 0.9399 - val_mae: 0.7297\n",
            "Epoch 317/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4643 - mae: 0.5270 - val_loss: 1.0123 - val_mae: 0.7530\n",
            "Epoch 318/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4583 - mae: 0.5247 - val_loss: 0.9411 - val_mae: 0.7269\n",
            "Epoch 319/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4595 - mae: 0.5261 - val_loss: 0.9440 - val_mae: 0.7345\n",
            "Epoch 320/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4450 - mae: 0.5186 - val_loss: 0.9733 - val_mae: 0.7423\n",
            "Epoch 321/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4868 - mae: 0.5427 - val_loss: 0.9870 - val_mae: 0.7247\n",
            "Epoch 322/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4363 - mae: 0.5126 - val_loss: 0.9803 - val_mae: 0.7306\n",
            "Epoch 323/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4793 - mae: 0.5430 - val_loss: 0.9451 - val_mae: 0.7216\n",
            "Epoch 324/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4302 - mae: 0.5094 - val_loss: 0.9581 - val_mae: 0.7341\n",
            "Epoch 325/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4556 - mae: 0.5249 - val_loss: 0.9501 - val_mae: 0.7192\n",
            "Epoch 326/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4196 - mae: 0.5033 - val_loss: 0.9697 - val_mae: 0.7281\n",
            "Epoch 327/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4296 - mae: 0.5105 - val_loss: 0.9457 - val_mae: 0.7238\n",
            "Epoch 328/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4382 - mae: 0.5148 - val_loss: 0.9342 - val_mae: 0.7240\n",
            "Epoch 329/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4469 - mae: 0.5187 - val_loss: 1.1615 - val_mae: 0.8218\n",
            "Epoch 330/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4598 - mae: 0.5264 - val_loss: 1.0122 - val_mae: 0.7376\n",
            "Epoch 331/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4235 - mae: 0.5055 - val_loss: 0.9563 - val_mae: 0.7173\n",
            "Epoch 332/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4324 - mae: 0.5114 - val_loss: 1.0508 - val_mae: 0.7639\n",
            "Epoch 333/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4973 - mae: 0.5513 - val_loss: 0.9755 - val_mae: 0.7335\n",
            "Epoch 334/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4659 - mae: 0.5332 - val_loss: 0.9734 - val_mae: 0.7363\n",
            "Epoch 335/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4365 - mae: 0.5164 - val_loss: 0.9313 - val_mae: 0.7179\n",
            "Epoch 336/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4234 - mae: 0.5077 - val_loss: 0.9884 - val_mae: 0.7435\n",
            "Epoch 337/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4288 - mae: 0.5106 - val_loss: 0.9641 - val_mae: 0.7222\n",
            "Epoch 338/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4188 - mae: 0.5018 - val_loss: 0.9443 - val_mae: 0.7243\n",
            "Epoch 339/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4469 - mae: 0.5252 - val_loss: 0.9313 - val_mae: 0.7075\n",
            "Epoch 340/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4472 - mae: 0.5245 - val_loss: 0.9407 - val_mae: 0.7255\n",
            "Epoch 341/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4447 - mae: 0.5201 - val_loss: 0.9735 - val_mae: 0.7271\n",
            "Epoch 342/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4263 - mae: 0.5073 - val_loss: 1.0437 - val_mae: 0.7692\n",
            "Epoch 343/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4321 - mae: 0.5105 - val_loss: 1.0869 - val_mae: 0.7730\n",
            "Epoch 344/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4290 - mae: 0.5090 - val_loss: 1.0289 - val_mae: 0.7678\n",
            "Epoch 345/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4162 - mae: 0.5045 - val_loss: 0.9842 - val_mae: 0.7358\n",
            "Epoch 346/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.4331 - mae: 0.5121 - val_loss: 0.9441 - val_mae: 0.7365\n",
            "Epoch 347/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4173 - mae: 0.5055 - val_loss: 1.0348 - val_mae: 0.7739\n",
            "Epoch 348/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4334 - mae: 0.5136 - val_loss: 0.9844 - val_mae: 0.7298\n",
            "Epoch 349/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4110 - mae: 0.5002 - val_loss: 0.9630 - val_mae: 0.7215\n",
            "Epoch 350/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4186 - mae: 0.5010 - val_loss: 0.9380 - val_mae: 0.7192\n",
            "Epoch 351/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4411 - mae: 0.5193 - val_loss: 0.9623 - val_mae: 0.7231\n",
            "Epoch 352/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4120 - mae: 0.5008 - val_loss: 0.9811 - val_mae: 0.7336\n",
            "Epoch 353/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4030 - mae: 0.4953 - val_loss: 0.9313 - val_mae: 0.7117\n",
            "Epoch 354/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3975 - mae: 0.4895 - val_loss: 0.9837 - val_mae: 0.7294\n",
            "Epoch 355/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4330 - mae: 0.5116 - val_loss: 0.9109 - val_mae: 0.7214\n",
            "Epoch 356/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4254 - mae: 0.5093 - val_loss: 1.0073 - val_mae: 0.7354\n",
            "Epoch 357/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4179 - mae: 0.5023 - val_loss: 1.0504 - val_mae: 0.7656\n",
            "Epoch 358/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3857 - mae: 0.4826 - val_loss: 1.0022 - val_mae: 0.7521\n",
            "Epoch 359/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4107 - mae: 0.4966 - val_loss: 1.0488 - val_mae: 0.7729\n",
            "Epoch 360/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4083 - mae: 0.4968 - val_loss: 1.0671 - val_mae: 0.7564\n",
            "Epoch 361/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3846 - mae: 0.4810 - val_loss: 0.9517 - val_mae: 0.7164\n",
            "Epoch 362/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3917 - mae: 0.4879 - val_loss: 0.9351 - val_mae: 0.7256\n",
            "Epoch 363/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3781 - mae: 0.4785 - val_loss: 1.0329 - val_mae: 0.7548\n",
            "Epoch 364/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3864 - mae: 0.4846 - val_loss: 0.9085 - val_mae: 0.7102\n",
            "Epoch 365/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4122 - mae: 0.5013 - val_loss: 0.9529 - val_mae: 0.7028\n",
            "Epoch 366/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4201 - mae: 0.5064 - val_loss: 1.0280 - val_mae: 0.7463\n",
            "Epoch 367/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3920 - mae: 0.4885 - val_loss: 0.9855 - val_mae: 0.7335\n",
            "Epoch 368/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3853 - mae: 0.4869 - val_loss: 1.0073 - val_mae: 0.7451\n",
            "Epoch 369/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.4078 - mae: 0.4990 - val_loss: 0.9311 - val_mae: 0.7072\n",
            "Epoch 370/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3802 - mae: 0.4827 - val_loss: 0.9692 - val_mae: 0.7188\n",
            "Epoch 371/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3827 - mae: 0.4782 - val_loss: 0.9369 - val_mae: 0.7129\n",
            "Epoch 372/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3871 - mae: 0.4849 - val_loss: 0.9431 - val_mae: 0.7184\n",
            "Epoch 373/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3631 - mae: 0.4636 - val_loss: 0.9656 - val_mae: 0.7194\n",
            "Epoch 374/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3637 - mae: 0.4706 - val_loss: 0.9294 - val_mae: 0.7144\n",
            "Epoch 375/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3832 - mae: 0.4823 - val_loss: 0.9536 - val_mae: 0.7178\n",
            "Epoch 376/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3540 - mae: 0.4650 - val_loss: 0.9376 - val_mae: 0.7261\n",
            "Epoch 377/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3919 - mae: 0.4883 - val_loss: 0.9534 - val_mae: 0.7162\n",
            "Epoch 378/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3660 - mae: 0.4721 - val_loss: 0.9711 - val_mae: 0.7258\n",
            "Epoch 379/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3585 - mae: 0.4649 - val_loss: 0.9499 - val_mae: 0.7204\n",
            "Epoch 380/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3583 - mae: 0.4671 - val_loss: 0.9478 - val_mae: 0.7123\n",
            "Epoch 381/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3649 - mae: 0.4669 - val_loss: 0.9514 - val_mae: 0.7167\n",
            "Epoch 382/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3672 - mae: 0.4733 - val_loss: 0.9578 - val_mae: 0.7237\n",
            "Epoch 383/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3638 - mae: 0.4659 - val_loss: 0.9682 - val_mae: 0.7232\n",
            "Epoch 384/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3506 - mae: 0.4593 - val_loss: 0.9710 - val_mae: 0.7126\n",
            "Epoch 385/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3457 - mae: 0.4563 - val_loss: 0.9471 - val_mae: 0.7187\n",
            "Epoch 386/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3583 - mae: 0.4660 - val_loss: 0.9602 - val_mae: 0.7076\n",
            "Epoch 387/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3498 - mae: 0.4552 - val_loss: 0.9634 - val_mae: 0.7287\n",
            "Epoch 388/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3585 - mae: 0.4620 - val_loss: 1.0043 - val_mae: 0.7462\n",
            "Epoch 389/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3301 - mae: 0.4447 - val_loss: 0.9354 - val_mae: 0.7219\n",
            "Epoch 390/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3317 - mae: 0.4476 - val_loss: 0.9174 - val_mae: 0.7114\n",
            "Epoch 391/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3434 - mae: 0.4575 - val_loss: 1.0098 - val_mae: 0.7256\n",
            "Epoch 392/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3745 - mae: 0.4807 - val_loss: 1.0341 - val_mae: 0.7646\n",
            "Epoch 393/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3577 - mae: 0.4674 - val_loss: 0.9284 - val_mae: 0.7124\n",
            "Epoch 394/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3362 - mae: 0.4511 - val_loss: 1.1404 - val_mae: 0.8170\n",
            "Epoch 395/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3509 - mae: 0.4579 - val_loss: 0.9440 - val_mae: 0.7135\n",
            "Epoch 396/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3361 - mae: 0.4466 - val_loss: 0.9524 - val_mae: 0.7105\n",
            "Epoch 397/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3343 - mae: 0.4524 - val_loss: 0.9395 - val_mae: 0.7218\n",
            "Epoch 398/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3540 - mae: 0.4614 - val_loss: 0.9450 - val_mae: 0.7032\n",
            "Epoch 399/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3434 - mae: 0.4565 - val_loss: 0.9427 - val_mae: 0.7067\n",
            "Epoch 400/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3400 - mae: 0.4554 - val_loss: 0.9891 - val_mae: 0.7460\n",
            "Epoch 401/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3407 - mae: 0.4518 - val_loss: 0.9567 - val_mae: 0.7192\n",
            "Epoch 402/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3231 - mae: 0.4383 - val_loss: 0.9410 - val_mae: 0.7211\n",
            "Epoch 403/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3228 - mae: 0.4374 - val_loss: 0.9561 - val_mae: 0.7104\n",
            "Epoch 404/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3152 - mae: 0.4365 - val_loss: 0.9449 - val_mae: 0.7097\n",
            "Epoch 405/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3550 - mae: 0.4638 - val_loss: 0.9563 - val_mae: 0.7277\n",
            "Epoch 406/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3097 - mae: 0.4311 - val_loss: 0.9538 - val_mae: 0.7164\n",
            "Epoch 407/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3241 - mae: 0.4402 - val_loss: 0.9846 - val_mae: 0.7323\n",
            "Epoch 408/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3221 - mae: 0.4405 - val_loss: 1.0297 - val_mae: 0.7478\n",
            "Epoch 409/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3323 - mae: 0.4501 - val_loss: 0.9481 - val_mae: 0.7032\n",
            "Epoch 410/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3333 - mae: 0.4516 - val_loss: 1.0403 - val_mae: 0.7446\n",
            "Epoch 411/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3392 - mae: 0.4512 - val_loss: 0.9584 - val_mae: 0.7150\n",
            "Epoch 412/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3194 - mae: 0.4341 - val_loss: 0.9404 - val_mae: 0.7150\n",
            "Epoch 413/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3130 - mae: 0.4329 - val_loss: 0.9740 - val_mae: 0.7286\n",
            "Epoch 414/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2997 - mae: 0.4239 - val_loss: 0.9602 - val_mae: 0.7103\n",
            "Epoch 415/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2944 - mae: 0.4171 - val_loss: 0.9760 - val_mae: 0.7221\n",
            "Epoch 416/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3107 - mae: 0.4349 - val_loss: 1.0123 - val_mae: 0.7341\n",
            "Epoch 417/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3093 - mae: 0.4325 - val_loss: 0.9892 - val_mae: 0.7123\n",
            "Epoch 418/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3300 - mae: 0.4431 - val_loss: 0.9505 - val_mae: 0.7075\n",
            "Epoch 419/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2986 - mae: 0.4260 - val_loss: 1.0253 - val_mae: 0.7366\n",
            "Epoch 420/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3140 - mae: 0.4358 - val_loss: 0.9964 - val_mae: 0.7322\n",
            "Epoch 421/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3159 - mae: 0.4370 - val_loss: 0.9166 - val_mae: 0.7085\n",
            "Epoch 422/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2969 - mae: 0.4164 - val_loss: 0.9560 - val_mae: 0.7007\n",
            "Epoch 423/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3328 - mae: 0.4437 - val_loss: 0.9500 - val_mae: 0.6979\n",
            "Epoch 424/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3047 - mae: 0.4285 - val_loss: 0.9873 - val_mae: 0.7234\n",
            "Epoch 425/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3072 - mae: 0.4252 - val_loss: 1.0064 - val_mae: 0.7268\n",
            "Epoch 426/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3045 - mae: 0.4299 - val_loss: 0.9542 - val_mae: 0.7070\n",
            "Epoch 427/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2964 - mae: 0.4223 - val_loss: 0.9345 - val_mae: 0.7057\n",
            "Epoch 428/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2929 - mae: 0.4180 - val_loss: 0.9456 - val_mae: 0.7115\n",
            "Epoch 429/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3532 - mae: 0.4615 - val_loss: 0.9603 - val_mae: 0.7076\n",
            "Epoch 430/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2853 - mae: 0.4130 - val_loss: 0.9383 - val_mae: 0.7080\n",
            "Epoch 431/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3077 - mae: 0.4309 - val_loss: 0.9257 - val_mae: 0.6964\n",
            "Epoch 432/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2890 - mae: 0.4193 - val_loss: 0.9687 - val_mae: 0.7059\n",
            "Epoch 433/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2892 - mae: 0.4167 - val_loss: 1.0129 - val_mae: 0.7248\n",
            "Epoch 434/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2890 - mae: 0.4169 - val_loss: 0.9753 - val_mae: 0.7206\n",
            "Epoch 435/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2978 - mae: 0.4195 - val_loss: 0.9712 - val_mae: 0.7060\n",
            "Epoch 436/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2771 - mae: 0.4078 - val_loss: 0.9565 - val_mae: 0.7115\n",
            "Epoch 437/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2901 - mae: 0.4144 - val_loss: 1.1331 - val_mae: 0.7921\n",
            "Epoch 438/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2879 - mae: 0.4156 - val_loss: 1.0300 - val_mae: 0.7521\n",
            "Epoch 439/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3165 - mae: 0.4381 - val_loss: 0.9785 - val_mae: 0.7162\n",
            "Epoch 440/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3128 - mae: 0.4342 - val_loss: 0.9795 - val_mae: 0.7207\n",
            "Epoch 441/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2971 - mae: 0.4222 - val_loss: 0.9402 - val_mae: 0.6943\n",
            "Epoch 442/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2682 - mae: 0.4039 - val_loss: 1.0138 - val_mae: 0.7433\n",
            "Epoch 443/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2980 - mae: 0.4199 - val_loss: 0.9554 - val_mae: 0.7257\n",
            "Epoch 444/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2834 - mae: 0.4146 - val_loss: 0.9766 - val_mae: 0.7207\n",
            "Epoch 445/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2873 - mae: 0.4169 - val_loss: 0.9602 - val_mae: 0.7112\n",
            "Epoch 446/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2625 - mae: 0.3950 - val_loss: 0.9675 - val_mae: 0.7210\n",
            "Epoch 447/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2901 - mae: 0.4148 - val_loss: 0.9489 - val_mae: 0.6966\n",
            "Epoch 448/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2578 - mae: 0.3873 - val_loss: 0.9981 - val_mae: 0.7228\n",
            "Epoch 449/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2597 - mae: 0.3957 - val_loss: 1.0452 - val_mae: 0.7374\n",
            "Epoch 450/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2613 - mae: 0.3963 - val_loss: 0.9626 - val_mae: 0.6993\n",
            "Epoch 451/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2500 - mae: 0.3839 - val_loss: 0.9578 - val_mae: 0.7125\n",
            "Epoch 452/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2783 - mae: 0.4057 - val_loss: 0.9297 - val_mae: 0.6974\n",
            "Epoch 453/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3066 - mae: 0.4293 - val_loss: 0.9580 - val_mae: 0.7152\n",
            "Epoch 454/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.3240 - mae: 0.4466 - val_loss: 0.9865 - val_mae: 0.7223\n",
            "Epoch 455/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2655 - mae: 0.4000 - val_loss: 1.0137 - val_mae: 0.7190\n",
            "Epoch 456/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2627 - mae: 0.3999 - val_loss: 0.9635 - val_mae: 0.7174\n",
            "Epoch 457/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2676 - mae: 0.4011 - val_loss: 0.9749 - val_mae: 0.7114\n",
            "Epoch 458/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2544 - mae: 0.3865 - val_loss: 0.9408 - val_mae: 0.7068\n",
            "Epoch 459/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2531 - mae: 0.3918 - val_loss: 0.9815 - val_mae: 0.7208\n",
            "Epoch 460/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2715 - mae: 0.4026 - val_loss: 0.9422 - val_mae: 0.6879\n",
            "Epoch 461/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2531 - mae: 0.3917 - val_loss: 0.9513 - val_mae: 0.6995\n",
            "Epoch 462/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2597 - mae: 0.3950 - val_loss: 0.9476 - val_mae: 0.7049\n",
            "Epoch 463/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2529 - mae: 0.3903 - val_loss: 0.9485 - val_mae: 0.7047\n",
            "Epoch 464/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2413 - mae: 0.3772 - val_loss: 1.0390 - val_mae: 0.7655\n",
            "Epoch 465/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2585 - mae: 0.3946 - val_loss: 0.9593 - val_mae: 0.7064\n",
            "Epoch 466/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2456 - mae: 0.3840 - val_loss: 0.9758 - val_mae: 0.7197\n",
            "Epoch 467/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2576 - mae: 0.3923 - val_loss: 0.9817 - val_mae: 0.7180\n",
            "Epoch 468/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2454 - mae: 0.3849 - val_loss: 0.9989 - val_mae: 0.7121\n",
            "Epoch 469/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2386 - mae: 0.3762 - val_loss: 0.9598 - val_mae: 0.7117\n",
            "Epoch 470/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2497 - mae: 0.3844 - val_loss: 0.9731 - val_mae: 0.7154\n",
            "Epoch 471/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2418 - mae: 0.3805 - val_loss: 0.9833 - val_mae: 0.7091\n",
            "Epoch 472/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2545 - mae: 0.3843 - val_loss: 1.0201 - val_mae: 0.7396\n",
            "Epoch 473/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2640 - mae: 0.3948 - val_loss: 0.9490 - val_mae: 0.6961\n",
            "Epoch 474/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2453 - mae: 0.3818 - val_loss: 0.9667 - val_mae: 0.7064\n",
            "Epoch 475/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2344 - mae: 0.3729 - val_loss: 1.0172 - val_mae: 0.7225\n",
            "Epoch 476/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2547 - mae: 0.3925 - val_loss: 0.9816 - val_mae: 0.7302\n",
            "Epoch 477/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2541 - mae: 0.3891 - val_loss: 0.9611 - val_mae: 0.7083\n",
            "Epoch 478/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2482 - mae: 0.3856 - val_loss: 1.0165 - val_mae: 0.7170\n",
            "Epoch 479/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2394 - mae: 0.3790 - val_loss: 0.9447 - val_mae: 0.6989\n",
            "Epoch 480/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2398 - mae: 0.3777 - val_loss: 0.9390 - val_mae: 0.6974\n",
            "Epoch 481/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2348 - mae: 0.3720 - val_loss: 0.9633 - val_mae: 0.6981\n",
            "Epoch 482/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2547 - mae: 0.3946 - val_loss: 0.9708 - val_mae: 0.7196\n",
            "Epoch 483/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2458 - mae: 0.3802 - val_loss: 1.0072 - val_mae: 0.7407\n",
            "Epoch 484/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2447 - mae: 0.3845 - val_loss: 0.9375 - val_mae: 0.6976\n",
            "Epoch 485/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2401 - mae: 0.3795 - val_loss: 0.9402 - val_mae: 0.7030\n",
            "Epoch 486/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2244 - mae: 0.3661 - val_loss: 0.9542 - val_mae: 0.7022\n",
            "Epoch 487/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2337 - mae: 0.3782 - val_loss: 1.0232 - val_mae: 0.7216\n",
            "Epoch 488/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2283 - mae: 0.3666 - val_loss: 0.9702 - val_mae: 0.7147\n",
            "Epoch 489/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2369 - mae: 0.3720 - val_loss: 0.9426 - val_mae: 0.7082\n",
            "Epoch 490/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2378 - mae: 0.3779 - val_loss: 1.0684 - val_mae: 0.7700\n",
            "Epoch 491/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2669 - mae: 0.4016 - val_loss: 0.9993 - val_mae: 0.7252\n",
            "Epoch 492/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2298 - mae: 0.3700 - val_loss: 0.9277 - val_mae: 0.6973\n",
            "Epoch 493/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2557 - mae: 0.3892 - val_loss: 0.9568 - val_mae: 0.7118\n",
            "Epoch 494/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2359 - mae: 0.3772 - val_loss: 0.9929 - val_mae: 0.7302\n",
            "Epoch 495/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2104 - mae: 0.3526 - val_loss: 0.9131 - val_mae: 0.6869\n",
            "Epoch 496/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2113 - mae: 0.3564 - val_loss: 0.9608 - val_mae: 0.6962\n",
            "Epoch 497/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2071 - mae: 0.3498 - val_loss: 0.9732 - val_mae: 0.7015\n",
            "Epoch 498/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2129 - mae: 0.3571 - val_loss: 0.9525 - val_mae: 0.7049\n",
            "Epoch 499/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2098 - mae: 0.3493 - val_loss: 0.9808 - val_mae: 0.7274\n",
            "Epoch 500/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2096 - mae: 0.3523 - val_loss: 0.9744 - val_mae: 0.7118\n",
            "Epoch 501/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2208 - mae: 0.3635 - val_loss: 0.9808 - val_mae: 0.7154\n",
            "Epoch 502/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2256 - mae: 0.3668 - val_loss: 0.9798 - val_mae: 0.7131\n",
            "Epoch 503/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2160 - mae: 0.3600 - val_loss: 0.9581 - val_mae: 0.7032\n",
            "Epoch 504/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2067 - mae: 0.3530 - val_loss: 0.9457 - val_mae: 0.6957\n",
            "Epoch 505/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2166 - mae: 0.3593 - val_loss: 0.9977 - val_mae: 0.7216\n",
            "Epoch 506/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2041 - mae: 0.3480 - val_loss: 0.9280 - val_mae: 0.6821\n",
            "Epoch 507/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1991 - mae: 0.3392 - val_loss: 0.9495 - val_mae: 0.7074\n",
            "Epoch 508/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2116 - mae: 0.3569 - val_loss: 0.9858 - val_mae: 0.7312\n",
            "Epoch 509/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2213 - mae: 0.3644 - val_loss: 0.9521 - val_mae: 0.6919\n",
            "Epoch 510/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1962 - mae: 0.3366 - val_loss: 0.9580 - val_mae: 0.7060\n",
            "Epoch 511/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2006 - mae: 0.3467 - val_loss: 0.9365 - val_mae: 0.6883\n",
            "Epoch 512/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1902 - mae: 0.3319 - val_loss: 0.9844 - val_mae: 0.7324\n",
            "Epoch 513/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2245 - mae: 0.3644 - val_loss: 0.9652 - val_mae: 0.7087\n",
            "Epoch 514/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2171 - mae: 0.3608 - val_loss: 0.9228 - val_mae: 0.6925\n",
            "Epoch 515/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2115 - mae: 0.3511 - val_loss: 0.9939 - val_mae: 0.7146\n",
            "Epoch 516/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2040 - mae: 0.3479 - val_loss: 0.9709 - val_mae: 0.7184\n",
            "Epoch 517/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2108 - mae: 0.3562 - val_loss: 0.9182 - val_mae: 0.6882\n",
            "Epoch 518/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1993 - mae: 0.3472 - val_loss: 0.9745 - val_mae: 0.7036\n",
            "Epoch 519/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2013 - mae: 0.3418 - val_loss: 0.9887 - val_mae: 0.7237\n",
            "Epoch 520/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2223 - mae: 0.3627 - val_loss: 0.9592 - val_mae: 0.7017\n",
            "Epoch 521/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2133 - mae: 0.3571 - val_loss: 0.9688 - val_mae: 0.7165\n",
            "Epoch 522/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1952 - mae: 0.3376 - val_loss: 0.9884 - val_mae: 0.7204\n",
            "Epoch 523/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2237 - mae: 0.3665 - val_loss: 1.0050 - val_mae: 0.7281\n",
            "Epoch 524/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2116 - mae: 0.3547 - val_loss: 0.9504 - val_mae: 0.6903\n",
            "Epoch 525/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1831 - mae: 0.3260 - val_loss: 0.9303 - val_mae: 0.6845\n",
            "Epoch 526/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1951 - mae: 0.3375 - val_loss: 0.9639 - val_mae: 0.7032\n",
            "Epoch 527/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1957 - mae: 0.3387 - val_loss: 0.9632 - val_mae: 0.7058\n",
            "Epoch 528/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2049 - mae: 0.3499 - val_loss: 0.9642 - val_mae: 0.7023\n",
            "Epoch 529/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1985 - mae: 0.3454 - val_loss: 0.9624 - val_mae: 0.7071\n",
            "Epoch 530/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1964 - mae: 0.3416 - val_loss: 0.9822 - val_mae: 0.7219\n",
            "Epoch 531/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1926 - mae: 0.3394 - val_loss: 0.9715 - val_mae: 0.7137\n",
            "Epoch 532/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1829 - mae: 0.3319 - val_loss: 0.9550 - val_mae: 0.7066\n",
            "Epoch 533/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1940 - mae: 0.3396 - val_loss: 0.9542 - val_mae: 0.6975\n",
            "Epoch 534/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1843 - mae: 0.3282 - val_loss: 0.9812 - val_mae: 0.7197\n",
            "Epoch 535/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1807 - mae: 0.3286 - val_loss: 0.9801 - val_mae: 0.7166\n",
            "Epoch 536/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1893 - mae: 0.3341 - val_loss: 0.9968 - val_mae: 0.7396\n",
            "Epoch 537/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1979 - mae: 0.3437 - val_loss: 0.9608 - val_mae: 0.7046\n",
            "Epoch 538/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1787 - mae: 0.3222 - val_loss: 0.9574 - val_mae: 0.6983\n",
            "Epoch 539/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1830 - mae: 0.3270 - val_loss: 0.9940 - val_mae: 0.7314\n",
            "Epoch 540/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1869 - mae: 0.3283 - val_loss: 0.9908 - val_mae: 0.7075\n",
            "Epoch 541/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1799 - mae: 0.3300 - val_loss: 0.9846 - val_mae: 0.7167\n",
            "Epoch 542/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1710 - mae: 0.3158 - val_loss: 0.9684 - val_mae: 0.7084\n",
            "Epoch 543/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1698 - mae: 0.3115 - val_loss: 0.9465 - val_mae: 0.7038\n",
            "Epoch 544/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.2066 - mae: 0.3512 - val_loss: 1.0032 - val_mae: 0.7121\n",
            "Epoch 545/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1810 - mae: 0.3272 - val_loss: 0.9603 - val_mae: 0.7078\n",
            "Epoch 546/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1811 - mae: 0.3258 - val_loss: 0.9967 - val_mae: 0.7123\n",
            "Epoch 547/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1836 - mae: 0.3294 - val_loss: 0.9419 - val_mae: 0.7067\n",
            "Epoch 548/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1696 - mae: 0.3138 - val_loss: 1.0279 - val_mae: 0.7502\n",
            "Epoch 549/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1806 - mae: 0.3285 - val_loss: 1.0152 - val_mae: 0.7403\n",
            "Epoch 550/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1739 - mae: 0.3219 - val_loss: 1.0422 - val_mae: 0.7599\n",
            "Epoch 551/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2292 - mae: 0.3712 - val_loss: 0.9572 - val_mae: 0.7036\n",
            "Epoch 552/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1668 - mae: 0.3112 - val_loss: 0.9818 - val_mae: 0.7200\n",
            "Epoch 553/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1660 - mae: 0.3144 - val_loss: 0.9911 - val_mae: 0.7132\n",
            "Epoch 554/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1668 - mae: 0.3120 - val_loss: 0.9733 - val_mae: 0.7108\n",
            "Epoch 555/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1833 - mae: 0.3312 - val_loss: 0.9462 - val_mae: 0.6964\n",
            "Epoch 556/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1678 - mae: 0.3145 - val_loss: 1.0783 - val_mae: 0.7511\n",
            "Epoch 557/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1686 - mae: 0.3117 - val_loss: 0.9620 - val_mae: 0.7034\n",
            "Epoch 558/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1563 - mae: 0.3042 - val_loss: 0.9720 - val_mae: 0.7013\n",
            "Epoch 559/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1557 - mae: 0.3024 - val_loss: 0.9794 - val_mae: 0.6991\n",
            "Epoch 560/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1940 - mae: 0.3388 - val_loss: 1.0568 - val_mae: 0.7459\n",
            "Epoch 561/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1760 - mae: 0.3236 - val_loss: 0.9737 - val_mae: 0.7038\n",
            "Epoch 562/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1591 - mae: 0.3065 - val_loss: 0.9474 - val_mae: 0.6937\n",
            "Epoch 563/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1567 - mae: 0.3011 - val_loss: 0.9862 - val_mae: 0.7014\n",
            "Epoch 564/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1667 - mae: 0.3120 - val_loss: 1.0055 - val_mae: 0.7315\n",
            "Epoch 565/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1572 - mae: 0.3042 - val_loss: 0.9847 - val_mae: 0.7051\n",
            "Epoch 566/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1725 - mae: 0.3208 - val_loss: 1.0086 - val_mae: 0.7188\n",
            "Epoch 567/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1677 - mae: 0.3159 - val_loss: 0.9405 - val_mae: 0.6964\n",
            "Epoch 568/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1662 - mae: 0.3111 - val_loss: 0.9538 - val_mae: 0.7041\n",
            "Epoch 569/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1501 - mae: 0.2959 - val_loss: 0.9664 - val_mae: 0.7005\n",
            "Epoch 570/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1413 - mae: 0.2852 - val_loss: 0.9926 - val_mae: 0.7259\n",
            "Epoch 571/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1699 - mae: 0.3167 - val_loss: 0.9806 - val_mae: 0.7086\n",
            "Epoch 572/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1508 - mae: 0.2958 - val_loss: 1.0002 - val_mae: 0.7187\n",
            "Epoch 573/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1536 - mae: 0.3029 - val_loss: 1.0030 - val_mae: 0.7161\n",
            "Epoch 574/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1588 - mae: 0.3057 - val_loss: 0.9870 - val_mae: 0.7024\n",
            "Epoch 575/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1758 - mae: 0.3239 - val_loss: 0.9739 - val_mae: 0.6955\n",
            "Epoch 576/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1612 - mae: 0.3087 - val_loss: 0.9869 - val_mae: 0.7071\n",
            "Epoch 577/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1457 - mae: 0.2931 - val_loss: 0.9801 - val_mae: 0.7012\n",
            "Epoch 578/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1557 - mae: 0.3050 - val_loss: 0.9708 - val_mae: 0.7056\n",
            "Epoch 579/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1437 - mae: 0.2890 - val_loss: 0.9802 - val_mae: 0.7128\n",
            "Epoch 580/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1501 - mae: 0.2995 - val_loss: 0.9850 - val_mae: 0.7097\n",
            "Epoch 581/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1559 - mae: 0.3000 - val_loss: 0.9799 - val_mae: 0.6987\n",
            "Epoch 582/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1415 - mae: 0.2866 - val_loss: 0.9813 - val_mae: 0.7166\n",
            "Epoch 583/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1513 - mae: 0.2971 - val_loss: 0.9839 - val_mae: 0.7119\n",
            "Epoch 584/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1462 - mae: 0.2899 - val_loss: 0.9970 - val_mae: 0.7229\n",
            "Epoch 585/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1516 - mae: 0.2972 - val_loss: 1.0631 - val_mae: 0.7578\n",
            "Epoch 586/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1692 - mae: 0.3173 - val_loss: 0.9664 - val_mae: 0.7078\n",
            "Epoch 587/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1672 - mae: 0.3171 - val_loss: 1.0239 - val_mae: 0.7242\n",
            "Epoch 588/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1480 - mae: 0.2943 - val_loss: 1.0012 - val_mae: 0.7141\n",
            "Epoch 589/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1480 - mae: 0.2919 - val_loss: 1.0168 - val_mae: 0.7191\n",
            "Epoch 590/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1731 - mae: 0.3187 - val_loss: 0.9863 - val_mae: 0.6992\n",
            "Epoch 591/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1443 - mae: 0.2916 - val_loss: 0.9742 - val_mae: 0.6997\n",
            "Epoch 592/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1355 - mae: 0.2772 - val_loss: 1.0065 - val_mae: 0.7092\n",
            "Epoch 593/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1342 - mae: 0.2774 - val_loss: 0.9641 - val_mae: 0.6982\n",
            "Epoch 594/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1325 - mae: 0.2789 - val_loss: 0.9573 - val_mae: 0.6959\n",
            "Epoch 595/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1311 - mae: 0.2745 - val_loss: 0.9655 - val_mae: 0.6965\n",
            "Epoch 596/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1679 - mae: 0.3136 - val_loss: 0.9763 - val_mae: 0.7017\n",
            "Epoch 597/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1411 - mae: 0.2841 - val_loss: 0.9618 - val_mae: 0.7072\n",
            "Epoch 598/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1468 - mae: 0.2932 - val_loss: 0.9437 - val_mae: 0.6969\n",
            "Epoch 599/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1356 - mae: 0.2822 - val_loss: 1.0059 - val_mae: 0.7151\n",
            "Epoch 600/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1395 - mae: 0.2828 - val_loss: 0.9808 - val_mae: 0.7168\n",
            "Epoch 601/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1301 - mae: 0.2748 - val_loss: 0.9606 - val_mae: 0.6927\n",
            "Epoch 602/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1305 - mae: 0.2746 - val_loss: 1.0184 - val_mae: 0.7173\n",
            "Epoch 603/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1355 - mae: 0.2793 - val_loss: 0.9673 - val_mae: 0.6979\n",
            "Epoch 604/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1352 - mae: 0.2794 - val_loss: 1.0442 - val_mae: 0.7364\n",
            "Epoch 605/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1408 - mae: 0.2859 - val_loss: 0.9979 - val_mae: 0.7154\n",
            "Epoch 606/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1454 - mae: 0.2943 - val_loss: 0.9806 - val_mae: 0.7178\n",
            "Epoch 607/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1628 - mae: 0.3124 - val_loss: 1.0091 - val_mae: 0.7185\n",
            "Epoch 608/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1454 - mae: 0.2930 - val_loss: 0.9720 - val_mae: 0.6995\n",
            "Epoch 609/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1334 - mae: 0.2776 - val_loss: 1.0151 - val_mae: 0.7176\n",
            "Epoch 610/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1386 - mae: 0.2862 - val_loss: 1.0548 - val_mae: 0.7347\n",
            "Epoch 611/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1437 - mae: 0.2881 - val_loss: 0.9915 - val_mae: 0.7030\n",
            "Epoch 612/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1247 - mae: 0.2686 - val_loss: 0.9750 - val_mae: 0.7037\n",
            "Epoch 613/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1283 - mae: 0.2747 - val_loss: 0.9841 - val_mae: 0.7002\n",
            "Epoch 614/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1277 - mae: 0.2731 - val_loss: 1.0183 - val_mae: 0.7373\n",
            "Epoch 615/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1540 - mae: 0.3046 - val_loss: 1.0415 - val_mae: 0.7320\n",
            "Epoch 616/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1270 - mae: 0.2742 - val_loss: 0.9780 - val_mae: 0.7031\n",
            "Epoch 617/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1261 - mae: 0.2666 - val_loss: 1.0004 - val_mae: 0.7144\n",
            "Epoch 618/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1232 - mae: 0.2650 - val_loss: 0.9730 - val_mae: 0.7011\n",
            "Epoch 619/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1276 - mae: 0.2739 - val_loss: 1.0120 - val_mae: 0.7233\n",
            "Epoch 620/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1182 - mae: 0.2626 - val_loss: 1.0151 - val_mae: 0.7081\n",
            "Epoch 621/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1251 - mae: 0.2705 - val_loss: 0.9813 - val_mae: 0.6997\n",
            "Epoch 622/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1337 - mae: 0.2794 - val_loss: 1.0167 - val_mae: 0.7222\n",
            "Epoch 623/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1255 - mae: 0.2706 - val_loss: 0.9951 - val_mae: 0.7187\n",
            "Epoch 624/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1396 - mae: 0.2855 - val_loss: 1.0043 - val_mae: 0.7323\n",
            "Epoch 625/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1354 - mae: 0.2823 - val_loss: 0.9828 - val_mae: 0.7180\n",
            "Epoch 626/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1287 - mae: 0.2732 - val_loss: 0.9757 - val_mae: 0.7025\n",
            "Epoch 627/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1180 - mae: 0.2598 - val_loss: 1.0005 - val_mae: 0.7085\n",
            "Epoch 628/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1149 - mae: 0.2561 - val_loss: 0.9820 - val_mae: 0.7027\n",
            "Epoch 629/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1231 - mae: 0.2658 - val_loss: 0.9881 - val_mae: 0.7025\n",
            "Epoch 630/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1199 - mae: 0.2616 - val_loss: 0.9829 - val_mae: 0.7059\n",
            "Epoch 631/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1210 - mae: 0.2645 - val_loss: 0.9748 - val_mae: 0.6953\n",
            "Epoch 632/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1211 - mae: 0.2654 - val_loss: 1.0003 - val_mae: 0.7206\n",
            "Epoch 633/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1124 - mae: 0.2533 - val_loss: 0.9703 - val_mae: 0.7022\n",
            "Epoch 634/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1071 - mae: 0.2443 - val_loss: 0.9901 - val_mae: 0.7062\n",
            "Epoch 635/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1294 - mae: 0.2739 - val_loss: 0.9939 - val_mae: 0.7156\n",
            "Epoch 636/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1173 - mae: 0.2604 - val_loss: 0.9876 - val_mae: 0.7071\n",
            "Epoch 637/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1148 - mae: 0.2556 - val_loss: 1.0044 - val_mae: 0.7154\n",
            "Epoch 638/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1101 - mae: 0.2487 - val_loss: 1.0029 - val_mae: 0.7089\n",
            "Epoch 639/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1289 - mae: 0.2779 - val_loss: 1.0097 - val_mae: 0.7196\n",
            "Epoch 640/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1169 - mae: 0.2618 - val_loss: 1.0087 - val_mae: 0.7077\n",
            "Epoch 641/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1160 - mae: 0.2613 - val_loss: 0.9808 - val_mae: 0.6977\n",
            "Epoch 642/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1121 - mae: 0.2544 - val_loss: 0.9696 - val_mae: 0.7102\n",
            "Epoch 643/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1140 - mae: 0.2589 - val_loss: 1.0022 - val_mae: 0.7113\n",
            "Epoch 644/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1223 - mae: 0.2687 - val_loss: 1.0166 - val_mae: 0.7179\n",
            "Epoch 645/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1312 - mae: 0.2799 - val_loss: 1.0441 - val_mae: 0.7449\n",
            "Epoch 646/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1285 - mae: 0.2764 - val_loss: 0.9912 - val_mae: 0.7131\n",
            "Epoch 647/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1064 - mae: 0.2478 - val_loss: 1.0193 - val_mae: 0.7308\n",
            "Epoch 648/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1147 - mae: 0.2584 - val_loss: 1.0318 - val_mae: 0.7289\n",
            "Epoch 649/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1288 - mae: 0.2738 - val_loss: 0.9974 - val_mae: 0.7147\n",
            "Epoch 650/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1099 - mae: 0.2515 - val_loss: 1.0006 - val_mae: 0.7072\n",
            "Epoch 651/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1092 - mae: 0.2482 - val_loss: 0.9800 - val_mae: 0.7025\n",
            "Epoch 652/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1042 - mae: 0.2418 - val_loss: 1.0045 - val_mae: 0.7175\n",
            "Epoch 653/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1187 - mae: 0.2628 - val_loss: 1.0527 - val_mae: 0.7482\n",
            "Epoch 654/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1227 - mae: 0.2697 - val_loss: 1.0166 - val_mae: 0.7145\n",
            "Epoch 655/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1170 - mae: 0.2628 - val_loss: 0.9916 - val_mae: 0.7101\n",
            "Epoch 656/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1017 - mae: 0.2395 - val_loss: 1.0131 - val_mae: 0.7113\n",
            "Epoch 657/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1022 - mae: 0.2423 - val_loss: 0.9929 - val_mae: 0.7189\n",
            "Epoch 658/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1008 - mae: 0.2389 - val_loss: 1.0354 - val_mae: 0.7168\n",
            "Epoch 659/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1174 - mae: 0.2605 - val_loss: 1.0069 - val_mae: 0.7100\n",
            "Epoch 660/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1143 - mae: 0.2599 - val_loss: 1.0168 - val_mae: 0.7325\n",
            "Epoch 661/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1068 - mae: 0.2483 - val_loss: 0.9792 - val_mae: 0.7022\n",
            "Epoch 662/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1266 - mae: 0.2718 - val_loss: 1.0303 - val_mae: 0.7287\n",
            "Epoch 663/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1148 - mae: 0.2624 - val_loss: 0.9885 - val_mae: 0.7169\n",
            "Epoch 664/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1070 - mae: 0.2500 - val_loss: 0.9808 - val_mae: 0.7111\n",
            "Epoch 665/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1094 - mae: 0.2521 - val_loss: 1.0104 - val_mae: 0.7131\n",
            "Epoch 666/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1064 - mae: 0.2487 - val_loss: 0.9760 - val_mae: 0.6943\n",
            "Epoch 667/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1011 - mae: 0.2434 - val_loss: 0.9862 - val_mae: 0.7043\n",
            "Epoch 668/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1022 - mae: 0.2443 - val_loss: 1.0196 - val_mae: 0.7218\n",
            "Epoch 669/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1232 - mae: 0.2704 - val_loss: 1.0273 - val_mae: 0.7162\n",
            "Epoch 670/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1179 - mae: 0.2641 - val_loss: 0.9963 - val_mae: 0.7086\n",
            "Epoch 671/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1002 - mae: 0.2395 - val_loss: 1.0324 - val_mae: 0.7289\n",
            "Epoch 672/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0999 - mae: 0.2382 - val_loss: 0.9985 - val_mae: 0.7099\n",
            "Epoch 673/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1008 - mae: 0.2396 - val_loss: 1.0068 - val_mae: 0.7071\n",
            "Epoch 674/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1100 - mae: 0.2553 - val_loss: 1.0039 - val_mae: 0.7036\n",
            "Epoch 675/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1191 - mae: 0.2631 - val_loss: 0.9910 - val_mae: 0.7080\n",
            "Epoch 676/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0983 - mae: 0.2368 - val_loss: 1.0048 - val_mae: 0.7178\n",
            "Epoch 677/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1093 - mae: 0.2528 - val_loss: 0.9869 - val_mae: 0.7006\n",
            "Epoch 678/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0897 - mae: 0.2242 - val_loss: 0.9913 - val_mae: 0.7079\n",
            "Epoch 679/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0930 - mae: 0.2282 - val_loss: 1.0239 - val_mae: 0.7109\n",
            "Epoch 680/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1019 - mae: 0.2433 - val_loss: 1.0208 - val_mae: 0.7183\n",
            "Epoch 681/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1014 - mae: 0.2423 - val_loss: 1.0197 - val_mae: 0.7238\n",
            "Epoch 682/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0943 - mae: 0.2320 - val_loss: 1.0116 - val_mae: 0.7144\n",
            "Epoch 683/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0979 - mae: 0.2372 - val_loss: 1.0002 - val_mae: 0.7109\n",
            "Epoch 684/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1034 - mae: 0.2442 - val_loss: 1.0121 - val_mae: 0.7223\n",
            "Epoch 685/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1138 - mae: 0.2579 - val_loss: 1.0335 - val_mae: 0.7344\n",
            "Epoch 686/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1070 - mae: 0.2523 - val_loss: 1.0145 - val_mae: 0.7194\n",
            "Epoch 687/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1042 - mae: 0.2461 - val_loss: 1.0082 - val_mae: 0.7191\n",
            "Epoch 688/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0938 - mae: 0.2325 - val_loss: 0.9744 - val_mae: 0.6922\n",
            "Epoch 689/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0897 - mae: 0.2258 - val_loss: 0.9902 - val_mae: 0.7052\n",
            "Epoch 690/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0929 - mae: 0.2305 - val_loss: 1.0150 - val_mae: 0.7201\n",
            "Epoch 691/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0911 - mae: 0.2285 - val_loss: 0.9897 - val_mae: 0.7086\n",
            "Epoch 692/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0948 - mae: 0.2351 - val_loss: 0.9958 - val_mae: 0.7069\n",
            "Epoch 693/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1176 - mae: 0.2618 - val_loss: 0.9985 - val_mae: 0.7048\n",
            "Epoch 694/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0976 - mae: 0.2377 - val_loss: 1.0026 - val_mae: 0.7115\n",
            "Epoch 695/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0874 - mae: 0.2240 - val_loss: 1.0205 - val_mae: 0.7093\n",
            "Epoch 696/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0870 - mae: 0.2217 - val_loss: 1.0117 - val_mae: 0.7171\n",
            "Epoch 697/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1004 - mae: 0.2377 - val_loss: 1.0727 - val_mae: 0.7554\n",
            "Epoch 698/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1078 - mae: 0.2531 - val_loss: 1.0538 - val_mae: 0.7253\n",
            "Epoch 699/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0888 - mae: 0.2290 - val_loss: 1.0193 - val_mae: 0.7158\n",
            "Epoch 700/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0950 - mae: 0.2309 - val_loss: 1.0205 - val_mae: 0.7109\n",
            "Epoch 701/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0943 - mae: 0.2343 - val_loss: 1.0446 - val_mae: 0.7261\n",
            "Epoch 702/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0935 - mae: 0.2320 - val_loss: 1.0530 - val_mae: 0.7372\n",
            "Epoch 703/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0942 - mae: 0.2335 - val_loss: 1.0197 - val_mae: 0.7173\n",
            "Epoch 704/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0828 - mae: 0.2145 - val_loss: 1.0343 - val_mae: 0.7213\n",
            "Epoch 705/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0928 - mae: 0.2320 - val_loss: 1.0154 - val_mae: 0.7167\n",
            "Epoch 706/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0982 - mae: 0.2375 - val_loss: 1.0318 - val_mae: 0.7275\n",
            "Epoch 707/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1105 - mae: 0.2587 - val_loss: 1.0194 - val_mae: 0.7224\n",
            "Epoch 708/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0871 - mae: 0.2258 - val_loss: 1.0441 - val_mae: 0.7242\n",
            "Epoch 709/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0927 - mae: 0.2326 - val_loss: 1.0078 - val_mae: 0.7226\n",
            "Epoch 710/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1032 - mae: 0.2435 - val_loss: 1.0412 - val_mae: 0.7250\n",
            "Epoch 711/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0912 - mae: 0.2272 - val_loss: 1.0036 - val_mae: 0.7202\n",
            "Epoch 712/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0848 - mae: 0.2174 - val_loss: 1.0090 - val_mae: 0.7186\n",
            "Epoch 713/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0868 - mae: 0.2222 - val_loss: 1.0730 - val_mae: 0.7494\n",
            "Epoch 714/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0870 - mae: 0.2224 - val_loss: 1.0156 - val_mae: 0.7272\n",
            "Epoch 715/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0895 - mae: 0.2252 - val_loss: 1.0204 - val_mae: 0.7155\n",
            "Epoch 716/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0841 - mae: 0.2217 - val_loss: 1.0350 - val_mae: 0.7210\n",
            "Epoch 717/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.2077 - val_loss: 1.0201 - val_mae: 0.7118\n",
            "Epoch 718/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0800 - mae: 0.2134 - val_loss: 1.0019 - val_mae: 0.7118\n",
            "Epoch 719/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0897 - mae: 0.2303 - val_loss: 1.0377 - val_mae: 0.7248\n",
            "Epoch 720/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0960 - mae: 0.2358 - val_loss: 1.0022 - val_mae: 0.7044\n",
            "Epoch 721/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.1211 - mae: 0.2672 - val_loss: 1.0685 - val_mae: 0.7445\n",
            "Epoch 722/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0854 - mae: 0.2191 - val_loss: 1.0180 - val_mae: 0.7176\n",
            "Epoch 723/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0718 - mae: 0.1983 - val_loss: 1.0123 - val_mae: 0.7219\n",
            "Epoch 724/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0794 - mae: 0.2106 - val_loss: 1.0478 - val_mae: 0.7174\n",
            "Epoch 725/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0742 - mae: 0.2025 - val_loss: 1.0187 - val_mae: 0.7200\n",
            "Epoch 726/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0911 - mae: 0.2266 - val_loss: 1.0381 - val_mae: 0.7255\n",
            "Epoch 727/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0765 - mae: 0.2095 - val_loss: 1.0411 - val_mae: 0.7359\n",
            "Epoch 728/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.2130 - val_loss: 1.0136 - val_mae: 0.7145\n",
            "Epoch 729/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0912 - mae: 0.2320 - val_loss: 1.0636 - val_mae: 0.7418\n",
            "Epoch 730/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0840 - mae: 0.2185 - val_loss: 1.0144 - val_mae: 0.7145\n",
            "Epoch 731/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0933 - mae: 0.2331 - val_loss: 1.0037 - val_mae: 0.7161\n",
            "Epoch 732/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0879 - mae: 0.2253 - val_loss: 1.0117 - val_mae: 0.7112\n",
            "Epoch 733/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0750 - mae: 0.2053 - val_loss: 0.9973 - val_mae: 0.7072\n",
            "Epoch 734/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0744 - mae: 0.2046 - val_loss: 1.0134 - val_mae: 0.7136\n",
            "Epoch 735/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0864 - mae: 0.2256 - val_loss: 1.0065 - val_mae: 0.7101\n",
            "Epoch 736/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0829 - mae: 0.2193 - val_loss: 1.0630 - val_mae: 0.7342\n",
            "Epoch 737/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0872 - mae: 0.2208 - val_loss: 1.0445 - val_mae: 0.7216\n",
            "Epoch 738/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0730 - mae: 0.2027 - val_loss: 1.0214 - val_mae: 0.7118\n",
            "Epoch 739/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0857 - mae: 0.2261 - val_loss: 1.0093 - val_mae: 0.7075\n",
            "Epoch 740/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0882 - mae: 0.2246 - val_loss: 1.0379 - val_mae: 0.7133\n",
            "Epoch 741/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0790 - mae: 0.2120 - val_loss: 1.0462 - val_mae: 0.7274\n",
            "Epoch 742/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0880 - mae: 0.2263 - val_loss: 1.0208 - val_mae: 0.7132\n",
            "Epoch 743/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0824 - mae: 0.2164 - val_loss: 1.0073 - val_mae: 0.7025\n",
            "Epoch 744/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0766 - mae: 0.2105 - val_loss: 1.0281 - val_mae: 0.7273\n",
            "Epoch 745/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0733 - mae: 0.2014 - val_loss: 1.0332 - val_mae: 0.7187\n",
            "Epoch 746/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0695 - mae: 0.1962 - val_loss: 1.0250 - val_mae: 0.7148\n",
            "Epoch 747/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0721 - mae: 0.1997 - val_loss: 1.0101 - val_mae: 0.7088\n",
            "Epoch 748/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0714 - mae: 0.2015 - val_loss: 1.0117 - val_mae: 0.7110\n",
            "Epoch 749/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0720 - mae: 0.2035 - val_loss: 1.0244 - val_mae: 0.7151\n",
            "Epoch 750/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0847 - mae: 0.2198 - val_loss: 1.0005 - val_mae: 0.7081\n",
            "Epoch 751/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0724 - mae: 0.2023 - val_loss: 1.0042 - val_mae: 0.7172\n",
            "Epoch 752/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0840 - mae: 0.2195 - val_loss: 1.0651 - val_mae: 0.7414\n",
            "Epoch 753/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0803 - mae: 0.2174 - val_loss: 1.0288 - val_mae: 0.7149\n",
            "Epoch 754/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0779 - mae: 0.2105 - val_loss: 1.0316 - val_mae: 0.7241\n",
            "Epoch 755/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0765 - mae: 0.2101 - val_loss: 1.0099 - val_mae: 0.7146\n",
            "Epoch 756/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0695 - mae: 0.1982 - val_loss: 1.0411 - val_mae: 0.7251\n",
            "Epoch 757/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0686 - mae: 0.1953 - val_loss: 1.0271 - val_mae: 0.7125\n",
            "Epoch 758/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0712 - mae: 0.2013 - val_loss: 1.0881 - val_mae: 0.7426\n",
            "Epoch 759/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0901 - mae: 0.2250 - val_loss: 1.0587 - val_mae: 0.7373\n",
            "Epoch 760/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0717 - mae: 0.2018 - val_loss: 1.0259 - val_mae: 0.7212\n",
            "Epoch 761/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0714 - mae: 0.1988 - val_loss: 1.0347 - val_mae: 0.7222\n",
            "Epoch 762/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0853 - mae: 0.2234 - val_loss: 1.0575 - val_mae: 0.7466\n",
            "Epoch 763/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0807 - mae: 0.2159 - val_loss: 1.0260 - val_mae: 0.7193\n",
            "Epoch 764/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0798 - mae: 0.2155 - val_loss: 1.0102 - val_mae: 0.7161\n",
            "Epoch 765/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0751 - mae: 0.2101 - val_loss: 1.0650 - val_mae: 0.7403\n",
            "Epoch 766/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0831 - mae: 0.2209 - val_loss: 1.0410 - val_mae: 0.7198\n",
            "Epoch 767/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0632 - mae: 0.1890 - val_loss: 1.0616 - val_mae: 0.7335\n",
            "Epoch 768/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0869 - mae: 0.2253 - val_loss: 1.0658 - val_mae: 0.7351\n",
            "Epoch 769/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0734 - mae: 0.2048 - val_loss: 1.0393 - val_mae: 0.7220\n",
            "Epoch 770/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0725 - mae: 0.2031 - val_loss: 1.0389 - val_mae: 0.7276\n",
            "Epoch 771/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0692 - mae: 0.1988 - val_loss: 1.0508 - val_mae: 0.7188\n",
            "Epoch 772/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0667 - mae: 0.1957 - val_loss: 1.0329 - val_mae: 0.7198\n",
            "Epoch 773/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0752 - mae: 0.2071 - val_loss: 1.0050 - val_mae: 0.7201\n",
            "Epoch 774/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0705 - mae: 0.2006 - val_loss: 1.0266 - val_mae: 0.7146\n",
            "Epoch 775/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0710 - mae: 0.2021 - val_loss: 1.0408 - val_mae: 0.7327\n",
            "Epoch 776/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0613 - mae: 0.1860 - val_loss: 1.0302 - val_mae: 0.7170\n",
            "Epoch 777/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0615 - mae: 0.1875 - val_loss: 1.0377 - val_mae: 0.7263\n",
            "Epoch 778/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0731 - mae: 0.2015 - val_loss: 1.0265 - val_mae: 0.7246\n",
            "Epoch 779/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0722 - mae: 0.2032 - val_loss: 1.0252 - val_mae: 0.7163\n",
            "Epoch 780/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0668 - mae: 0.1942 - val_loss: 1.0518 - val_mae: 0.7334\n",
            "Epoch 781/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0645 - mae: 0.1945 - val_loss: 1.0475 - val_mae: 0.7227\n",
            "Epoch 782/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0664 - mae: 0.1940 - val_loss: 1.0260 - val_mae: 0.7146\n",
            "Epoch 783/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0743 - mae: 0.2063 - val_loss: 1.0358 - val_mae: 0.7178\n",
            "Epoch 784/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0634 - mae: 0.1895 - val_loss: 1.0067 - val_mae: 0.7143\n",
            "Epoch 785/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0607 - mae: 0.1820 - val_loss: 1.0479 - val_mae: 0.7215\n",
            "Epoch 786/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0668 - mae: 0.1960 - val_loss: 1.0500 - val_mae: 0.7310\n",
            "Epoch 787/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.1857 - val_loss: 1.0431 - val_mae: 0.7284\n",
            "Epoch 788/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0625 - mae: 0.1864 - val_loss: 1.0813 - val_mae: 0.7419\n",
            "Epoch 789/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0759 - mae: 0.2084 - val_loss: 1.0446 - val_mae: 0.7337\n",
            "Epoch 790/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0676 - mae: 0.1968 - val_loss: 1.0316 - val_mae: 0.7273\n",
            "Epoch 791/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0804 - mae: 0.2174 - val_loss: 1.0393 - val_mae: 0.7218\n",
            "Epoch 792/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0638 - mae: 0.1919 - val_loss: 1.0350 - val_mae: 0.7173\n",
            "Epoch 793/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0626 - mae: 0.1869 - val_loss: 1.0366 - val_mae: 0.7298\n",
            "Epoch 794/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0766 - mae: 0.2139 - val_loss: 1.0557 - val_mae: 0.7284\n",
            "Epoch 795/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0631 - mae: 0.1889 - val_loss: 1.0621 - val_mae: 0.7251\n",
            "Epoch 796/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0627 - mae: 0.1873 - val_loss: 1.0321 - val_mae: 0.7171\n",
            "Epoch 797/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.1802 - val_loss: 1.0327 - val_mae: 0.7197\n",
            "Epoch 798/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0756 - mae: 0.2096 - val_loss: 1.1066 - val_mae: 0.7577\n",
            "Epoch 799/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0823 - mae: 0.2216 - val_loss: 1.0813 - val_mae: 0.7475\n",
            "Epoch 800/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0633 - mae: 0.1901 - val_loss: 1.0810 - val_mae: 0.7540\n",
            "Epoch 801/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0670 - mae: 0.1967 - val_loss: 1.0597 - val_mae: 0.7288\n",
            "Epoch 802/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0642 - mae: 0.1905 - val_loss: 1.0896 - val_mae: 0.7453\n",
            "Epoch 803/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0626 - mae: 0.1880 - val_loss: 1.0435 - val_mae: 0.7290\n",
            "Epoch 804/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0603 - mae: 0.1836 - val_loss: 1.0244 - val_mae: 0.7229\n",
            "Epoch 805/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0693 - mae: 0.2003 - val_loss: 1.0280 - val_mae: 0.7275\n",
            "Epoch 806/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0635 - mae: 0.1901 - val_loss: 1.0329 - val_mae: 0.7241\n",
            "Epoch 807/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0579 - mae: 0.1820 - val_loss: 1.0394 - val_mae: 0.7252\n",
            "Epoch 808/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0625 - mae: 0.1863 - val_loss: 1.1129 - val_mae: 0.7560\n",
            "Epoch 809/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0641 - mae: 0.1916 - val_loss: 1.0521 - val_mae: 0.7360\n",
            "Epoch 810/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0606 - mae: 0.1844 - val_loss: 1.1010 - val_mae: 0.7431\n",
            "Epoch 811/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0657 - mae: 0.1963 - val_loss: 1.0633 - val_mae: 0.7444\n",
            "Epoch 812/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0855 - mae: 0.2269 - val_loss: 1.0376 - val_mae: 0.7259\n",
            "Epoch 813/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0867 - mae: 0.2268 - val_loss: 1.0402 - val_mae: 0.7328\n",
            "Epoch 814/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0619 - mae: 0.1884 - val_loss: 1.0867 - val_mae: 0.7387\n",
            "Epoch 815/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0587 - mae: 0.1833 - val_loss: 1.0201 - val_mae: 0.7216\n",
            "Epoch 816/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.1706 - val_loss: 1.0751 - val_mae: 0.7328\n",
            "Epoch 817/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0535 - mae: 0.1716 - val_loss: 1.0568 - val_mae: 0.7247\n",
            "Epoch 818/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0524 - mae: 0.1708 - val_loss: 1.0356 - val_mae: 0.7238\n",
            "Epoch 819/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0526 - mae: 0.1706 - val_loss: 1.0363 - val_mae: 0.7229\n",
            "Epoch 820/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1732 - val_loss: 1.0665 - val_mae: 0.7334\n",
            "Epoch 821/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1716 - val_loss: 1.0374 - val_mae: 0.7267\n",
            "Epoch 822/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0571 - mae: 0.1768 - val_loss: 1.0577 - val_mae: 0.7416\n",
            "Epoch 823/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0706 - mae: 0.2034 - val_loss: 1.0653 - val_mae: 0.7387\n",
            "Epoch 824/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1778 - val_loss: 1.0414 - val_mae: 0.7230\n",
            "Epoch 825/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0560 - mae: 0.1784 - val_loss: 1.0671 - val_mae: 0.7386\n",
            "Epoch 826/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0566 - mae: 0.1796 - val_loss: 1.0430 - val_mae: 0.7295\n",
            "Epoch 827/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1676 - val_loss: 1.0498 - val_mae: 0.7254\n",
            "Epoch 828/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0500 - mae: 0.1637 - val_loss: 1.0569 - val_mae: 0.7398\n",
            "Epoch 829/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0696 - mae: 0.1989 - val_loss: 1.0469 - val_mae: 0.7401\n",
            "Epoch 830/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0547 - mae: 0.1765 - val_loss: 1.0579 - val_mae: 0.7284\n",
            "Epoch 831/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0639 - mae: 0.1921 - val_loss: 1.1318 - val_mae: 0.7600\n",
            "Epoch 832/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0760 - mae: 0.2130 - val_loss: 1.0552 - val_mae: 0.7296\n",
            "Epoch 833/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1745 - val_loss: 1.0509 - val_mae: 0.7262\n",
            "Epoch 834/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0622 - mae: 0.1888 - val_loss: 1.0487 - val_mae: 0.7242\n",
            "Epoch 835/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0642 - mae: 0.1938 - val_loss: 1.0716 - val_mae: 0.7344\n",
            "Epoch 836/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0551 - mae: 0.1741 - val_loss: 1.0409 - val_mae: 0.7260\n",
            "Epoch 837/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0485 - mae: 0.1629 - val_loss: 1.0455 - val_mae: 0.7256\n",
            "Epoch 838/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0570 - mae: 0.1796 - val_loss: 1.0592 - val_mae: 0.7324\n",
            "Epoch 839/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0568 - mae: 0.1787 - val_loss: 1.0417 - val_mae: 0.7267\n",
            "Epoch 840/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0554 - mae: 0.1763 - val_loss: 1.0451 - val_mae: 0.7259\n",
            "Epoch 841/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0588 - mae: 0.1841 - val_loss: 1.0533 - val_mae: 0.7411\n",
            "Epoch 842/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0590 - mae: 0.1832 - val_loss: 1.0368 - val_mae: 0.7264\n",
            "Epoch 843/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.1683 - val_loss: 1.0569 - val_mae: 0.7312\n",
            "Epoch 844/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0516 - mae: 0.1710 - val_loss: 1.0600 - val_mae: 0.7318\n",
            "Epoch 845/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0597 - mae: 0.1860 - val_loss: 1.0568 - val_mae: 0.7381\n",
            "Epoch 846/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0594 - mae: 0.1866 - val_loss: 1.0403 - val_mae: 0.7292\n",
            "Epoch 847/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0617 - mae: 0.1882 - val_loss: 1.0608 - val_mae: 0.7351\n",
            "Epoch 848/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0635 - mae: 0.1970 - val_loss: 1.0426 - val_mae: 0.7306\n",
            "Epoch 849/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0537 - mae: 0.1754 - val_loss: 1.0543 - val_mae: 0.7233\n",
            "Epoch 850/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0482 - mae: 0.1645 - val_loss: 1.0745 - val_mae: 0.7410\n",
            "Epoch 851/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0507 - mae: 0.1697 - val_loss: 1.0396 - val_mae: 0.7202\n",
            "Epoch 852/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1636 - val_loss: 1.0516 - val_mae: 0.7377\n",
            "Epoch 853/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0667 - mae: 0.1987 - val_loss: 1.0434 - val_mae: 0.7317\n",
            "Epoch 854/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0649 - mae: 0.1958 - val_loss: 1.0404 - val_mae: 0.7298\n",
            "Epoch 855/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0555 - mae: 0.1780 - val_loss: 1.0354 - val_mae: 0.7241\n",
            "Epoch 856/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0475 - mae: 0.1624 - val_loss: 1.0934 - val_mae: 0.7460\n",
            "Epoch 857/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1701 - val_loss: 1.0559 - val_mae: 0.7298\n",
            "Epoch 858/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0545 - mae: 0.1781 - val_loss: 1.0837 - val_mae: 0.7408\n",
            "Epoch 859/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0483 - mae: 0.1641 - val_loss: 1.0554 - val_mae: 0.7377\n",
            "Epoch 860/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.1723 - val_loss: 1.0574 - val_mae: 0.7393\n",
            "Epoch 861/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0491 - mae: 0.1663 - val_loss: 1.0571 - val_mae: 0.7275\n",
            "Epoch 862/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0443 - mae: 0.1590 - val_loss: 1.0518 - val_mae: 0.7262\n",
            "Epoch 863/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0505 - mae: 0.1677 - val_loss: 1.0679 - val_mae: 0.7316\n",
            "Epoch 864/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0517 - mae: 0.1697 - val_loss: 1.0688 - val_mae: 0.7438\n",
            "Epoch 865/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0446 - mae: 0.1569 - val_loss: 1.0412 - val_mae: 0.7336\n",
            "Epoch 866/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1477 - val_loss: 1.0293 - val_mae: 0.7200\n",
            "Epoch 867/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0456 - mae: 0.1601 - val_loss: 1.0677 - val_mae: 0.7379\n",
            "Epoch 868/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0449 - mae: 0.1565 - val_loss: 1.0576 - val_mae: 0.7336\n",
            "Epoch 869/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0584 - mae: 0.1792 - val_loss: 1.1134 - val_mae: 0.7637\n",
            "Epoch 870/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0606 - mae: 0.1872 - val_loss: 1.0462 - val_mae: 0.7214\n",
            "Epoch 871/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0554 - mae: 0.1791 - val_loss: 1.0751 - val_mae: 0.7282\n",
            "Epoch 872/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0568 - mae: 0.1830 - val_loss: 1.0688 - val_mae: 0.7350\n",
            "Epoch 873/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0638 - mae: 0.1935 - val_loss: 1.0647 - val_mae: 0.7339\n",
            "Epoch 874/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0616 - mae: 0.1887 - val_loss: 1.0857 - val_mae: 0.7399\n",
            "Epoch 875/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.1618 - val_loss: 1.0630 - val_mae: 0.7390\n",
            "Epoch 876/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0445 - mae: 0.1573 - val_loss: 1.1007 - val_mae: 0.7491\n",
            "Epoch 877/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0430 - mae: 0.1546 - val_loss: 1.0925 - val_mae: 0.7526\n",
            "Epoch 878/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0546 - mae: 0.1761 - val_loss: 1.0693 - val_mae: 0.7266\n",
            "Epoch 879/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1543 - val_loss: 1.0851 - val_mae: 0.7375\n",
            "Epoch 880/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.1632 - val_loss: 1.0682 - val_mae: 0.7308\n",
            "Epoch 881/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1782 - val_loss: 1.0803 - val_mae: 0.7396\n",
            "Epoch 882/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0371 - mae: 0.1413 - val_loss: 1.0536 - val_mae: 0.7321\n",
            "Epoch 883/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1508 - val_loss: 1.0966 - val_mae: 0.7415\n",
            "Epoch 884/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0472 - mae: 0.1639 - val_loss: 1.0677 - val_mae: 0.7386\n",
            "Epoch 885/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0471 - mae: 0.1651 - val_loss: 1.1162 - val_mae: 0.7663\n",
            "Epoch 886/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1792 - val_loss: 1.0460 - val_mae: 0.7328\n",
            "Epoch 887/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0492 - mae: 0.1674 - val_loss: 1.0599 - val_mae: 0.7262\n",
            "Epoch 888/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0525 - mae: 0.1742 - val_loss: 1.0594 - val_mae: 0.7264\n",
            "Epoch 889/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0541 - mae: 0.1795 - val_loss: 1.0875 - val_mae: 0.7511\n",
            "Epoch 890/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0479 - mae: 0.1625 - val_loss: 1.0545 - val_mae: 0.7436\n",
            "Epoch 891/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0455 - mae: 0.1619 - val_loss: 1.0680 - val_mae: 0.7357\n",
            "Epoch 892/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0510 - mae: 0.1723 - val_loss: 1.0765 - val_mae: 0.7330\n",
            "Epoch 893/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1685 - val_loss: 1.1099 - val_mae: 0.7474\n",
            "Epoch 894/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0577 - mae: 0.1833 - val_loss: 1.0680 - val_mae: 0.7308\n",
            "Epoch 895/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0486 - mae: 0.1670 - val_loss: 1.0826 - val_mae: 0.7341\n",
            "Epoch 896/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0451 - mae: 0.1598 - val_loss: 1.0756 - val_mae: 0.7393\n",
            "Epoch 897/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0487 - mae: 0.1675 - val_loss: 1.0604 - val_mae: 0.7322\n",
            "Epoch 898/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1488 - val_loss: 1.0813 - val_mae: 0.7434\n",
            "Epoch 899/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0489 - mae: 0.1679 - val_loss: 1.0567 - val_mae: 0.7346\n",
            "Epoch 900/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0439 - mae: 0.1582 - val_loss: 1.0747 - val_mae: 0.7409\n",
            "Epoch 901/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0460 - mae: 0.1613 - val_loss: 1.0725 - val_mae: 0.7288\n",
            "Epoch 902/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0453 - mae: 0.1627 - val_loss: 1.0873 - val_mae: 0.7450\n",
            "Epoch 903/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0552 - mae: 0.1800 - val_loss: 1.0704 - val_mae: 0.7393\n",
            "Epoch 904/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0435 - mae: 0.1582 - val_loss: 1.0826 - val_mae: 0.7379\n",
            "Epoch 905/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0508 - mae: 0.1701 - val_loss: 1.0797 - val_mae: 0.7412\n",
            "Epoch 906/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0379 - mae: 0.1466 - val_loss: 1.0878 - val_mae: 0.7383\n",
            "Epoch 907/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1622 - val_loss: 1.0983 - val_mae: 0.7534\n",
            "Epoch 908/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1571 - val_loss: 1.0555 - val_mae: 0.7388\n",
            "Epoch 909/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0390 - mae: 0.1493 - val_loss: 1.0508 - val_mae: 0.7317\n",
            "Epoch 910/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0457 - mae: 0.1625 - val_loss: 1.0480 - val_mae: 0.7262\n",
            "Epoch 911/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0385 - mae: 0.1452 - val_loss: 1.0591 - val_mae: 0.7311\n",
            "Epoch 912/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0412 - mae: 0.1518 - val_loss: 1.0693 - val_mae: 0.7358\n",
            "Epoch 913/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0373 - mae: 0.1436 - val_loss: 1.0798 - val_mae: 0.7412\n",
            "Epoch 914/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0430 - mae: 0.1555 - val_loss: 1.0949 - val_mae: 0.7466\n",
            "Epoch 915/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1463 - val_loss: 1.0579 - val_mae: 0.7293\n",
            "Epoch 916/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0396 - mae: 0.1489 - val_loss: 1.0863 - val_mae: 0.7383\n",
            "Epoch 917/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0514 - mae: 0.1735 - val_loss: 1.0650 - val_mae: 0.7325\n",
            "Epoch 918/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1482 - val_loss: 1.0759 - val_mae: 0.7430\n",
            "Epoch 919/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0467 - mae: 0.1633 - val_loss: 1.0729 - val_mae: 0.7385\n",
            "Epoch 920/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0428 - mae: 0.1547 - val_loss: 1.0556 - val_mae: 0.7366\n",
            "Epoch 921/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0640 - mae: 0.1930 - val_loss: 1.0716 - val_mae: 0.7408\n",
            "Epoch 922/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0533 - mae: 0.1774 - val_loss: 1.1194 - val_mae: 0.7464\n",
            "Epoch 923/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0406 - mae: 0.1533 - val_loss: 1.0562 - val_mae: 0.7275\n",
            "Epoch 924/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0437 - mae: 0.1601 - val_loss: 1.0544 - val_mae: 0.7315\n",
            "Epoch 925/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0380 - mae: 0.1464 - val_loss: 1.0550 - val_mae: 0.7352\n",
            "Epoch 926/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1374 - val_loss: 1.0795 - val_mae: 0.7402\n",
            "Epoch 927/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0417 - mae: 0.1540 - val_loss: 1.1080 - val_mae: 0.7441\n",
            "Epoch 928/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1575 - val_loss: 1.0720 - val_mae: 0.7375\n",
            "Epoch 929/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0458 - mae: 0.1642 - val_loss: 1.0723 - val_mae: 0.7397\n",
            "Epoch 930/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0515 - mae: 0.1715 - val_loss: 1.0757 - val_mae: 0.7485\n",
            "Epoch 931/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0526 - mae: 0.1745 - val_loss: 1.0704 - val_mae: 0.7358\n",
            "Epoch 932/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0389 - mae: 0.1490 - val_loss: 1.0593 - val_mae: 0.7308\n",
            "Epoch 933/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0402 - mae: 0.1486 - val_loss: 1.0606 - val_mae: 0.7271\n",
            "Epoch 934/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0394 - mae: 0.1492 - val_loss: 1.0952 - val_mae: 0.7471\n",
            "Epoch 935/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0413 - mae: 0.1527 - val_loss: 1.0671 - val_mae: 0.7365\n",
            "Epoch 936/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0406 - mae: 0.1527 - val_loss: 1.0908 - val_mae: 0.7391\n",
            "Epoch 937/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0573 - mae: 0.1849 - val_loss: 1.0740 - val_mae: 0.7403\n",
            "Epoch 938/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0444 - mae: 0.1574 - val_loss: 1.0694 - val_mae: 0.7360\n",
            "Epoch 939/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0357 - mae: 0.1418 - val_loss: 1.0785 - val_mae: 0.7471\n",
            "Epoch 940/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0337 - mae: 0.1353 - val_loss: 1.0407 - val_mae: 0.7251\n",
            "Epoch 941/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0350 - mae: 0.1397 - val_loss: 1.0487 - val_mae: 0.7352\n",
            "Epoch 942/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0465 - mae: 0.1592 - val_loss: 1.0997 - val_mae: 0.7573\n",
            "Epoch 943/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0585 - mae: 0.1874 - val_loss: 1.0653 - val_mae: 0.7282\n",
            "Epoch 944/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0481 - mae: 0.1677 - val_loss: 1.0790 - val_mae: 0.7405\n",
            "Epoch 945/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0348 - mae: 0.1410 - val_loss: 1.0842 - val_mae: 0.7510\n",
            "Epoch 946/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0374 - mae: 0.1454 - val_loss: 1.0804 - val_mae: 0.7378\n",
            "Epoch 947/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0378 - mae: 0.1461 - val_loss: 1.0889 - val_mae: 0.7418\n",
            "Epoch 948/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0436 - mae: 0.1586 - val_loss: 1.0644 - val_mae: 0.7366\n",
            "Epoch 949/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1463 - val_loss: 1.0662 - val_mae: 0.7434\n",
            "Epoch 950/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1467 - val_loss: 1.0512 - val_mae: 0.7357\n",
            "Epoch 951/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1491 - val_loss: 1.0562 - val_mae: 0.7345\n",
            "Epoch 952/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0362 - mae: 0.1411 - val_loss: 1.0726 - val_mae: 0.7497\n",
            "Epoch 953/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1487 - val_loss: 1.0483 - val_mae: 0.7312\n",
            "Epoch 954/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1503 - val_loss: 1.0729 - val_mae: 0.7433\n",
            "Epoch 955/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0393 - mae: 0.1493 - val_loss: 1.0596 - val_mae: 0.7378\n",
            "Epoch 956/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0376 - mae: 0.1445 - val_loss: 1.0592 - val_mae: 0.7293\n",
            "Epoch 957/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0347 - mae: 0.1374 - val_loss: 1.0800 - val_mae: 0.7398\n",
            "Epoch 958/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1438 - val_loss: 1.0872 - val_mae: 0.7502\n",
            "Epoch 959/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0388 - mae: 0.1513 - val_loss: 1.0647 - val_mae: 0.7400\n",
            "Epoch 960/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0407 - mae: 0.1530 - val_loss: 1.1215 - val_mae: 0.7673\n",
            "Epoch 961/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0414 - mae: 0.1530 - val_loss: 1.0849 - val_mae: 0.7469\n",
            "Epoch 962/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1480 - val_loss: 1.0721 - val_mae: 0.7386\n",
            "Epoch 963/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0330 - mae: 0.1367 - val_loss: 1.0751 - val_mae: 0.7419\n",
            "Epoch 964/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0361 - mae: 0.1443 - val_loss: 1.0522 - val_mae: 0.7399\n",
            "Epoch 965/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0349 - mae: 0.1396 - val_loss: 1.0651 - val_mae: 0.7400\n",
            "Epoch 966/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0550 - mae: 0.1774 - val_loss: 1.1270 - val_mae: 0.7763\n",
            "Epoch 967/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0548 - mae: 0.1793 - val_loss: 1.0889 - val_mae: 0.7410\n",
            "Epoch 968/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0427 - mae: 0.1586 - val_loss: 1.0933 - val_mae: 0.7456\n",
            "Epoch 969/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1495 - val_loss: 1.0674 - val_mae: 0.7412\n",
            "Epoch 970/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0369 - mae: 0.1450 - val_loss: 1.0854 - val_mae: 0.7475\n",
            "Epoch 971/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0370 - mae: 0.1459 - val_loss: 1.0680 - val_mae: 0.7326\n",
            "Epoch 972/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0296 - mae: 0.1285 - val_loss: 1.0702 - val_mae: 0.7446\n",
            "Epoch 973/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0470 - mae: 0.1659 - val_loss: 1.0703 - val_mae: 0.7405\n",
            "Epoch 974/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0325 - mae: 0.1347 - val_loss: 1.0753 - val_mae: 0.7452\n",
            "Epoch 975/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0289 - mae: 0.1239 - val_loss: 1.0592 - val_mae: 0.7379\n",
            "Epoch 976/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0366 - mae: 0.1425 - val_loss: 1.0605 - val_mae: 0.7331\n",
            "Epoch 977/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0408 - mae: 0.1540 - val_loss: 1.0832 - val_mae: 0.7357\n",
            "Epoch 978/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0405 - mae: 0.1548 - val_loss: 1.1039 - val_mae: 0.7589\n",
            "Epoch 979/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0416 - mae: 0.1543 - val_loss: 1.0786 - val_mae: 0.7348\n",
            "Epoch 980/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0373 - mae: 0.1479 - val_loss: 1.0749 - val_mae: 0.7339\n",
            "Epoch 981/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0377 - mae: 0.1446 - val_loss: 1.0764 - val_mae: 0.7443\n",
            "Epoch 982/1000\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0515 - mae: 0.1748 - val_loss: 1.0894 - val_mae: 0.7472\n",
            "Epoch 983/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0432 - mae: 0.1603 - val_loss: 1.1165 - val_mae: 0.7507\n",
            "Epoch 984/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0387 - mae: 0.1485 - val_loss: 1.0822 - val_mae: 0.7436\n",
            "Epoch 985/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0334 - mae: 0.1366 - val_loss: 1.0691 - val_mae: 0.7398\n",
            "Epoch 986/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0307 - mae: 0.1308 - val_loss: 1.0802 - val_mae: 0.7473\n",
            "Epoch 987/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0277 - mae: 0.1254 - val_loss: 1.0813 - val_mae: 0.7445\n",
            "Epoch 988/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0299 - mae: 0.1296 - val_loss: 1.0788 - val_mae: 0.7466\n",
            "Epoch 989/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0322 - mae: 0.1354 - val_loss: 1.0744 - val_mae: 0.7387\n",
            "Epoch 990/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1294 - val_loss: 1.0889 - val_mae: 0.7418\n",
            "Epoch 991/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0522 - mae: 0.1725 - val_loss: 1.1379 - val_mae: 0.7828\n",
            "Epoch 992/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0771 - mae: 0.2112 - val_loss: 1.1032 - val_mae: 0.7538\n",
            "Epoch 993/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0441 - mae: 0.1612 - val_loss: 1.0924 - val_mae: 0.7408\n",
            "Epoch 994/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0356 - mae: 0.1460 - val_loss: 1.0790 - val_mae: 0.7468\n",
            "Epoch 995/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0286 - mae: 0.1272 - val_loss: 1.0791 - val_mae: 0.7394\n",
            "Epoch 996/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0302 - mae: 0.1311 - val_loss: 1.0855 - val_mae: 0.7485\n",
            "Epoch 997/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0308 - mae: 0.1327 - val_loss: 1.0779 - val_mae: 0.7380\n",
            "Epoch 998/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0292 - mae: 0.1287 - val_loss: 1.0724 - val_mae: 0.7412\n",
            "Epoch 999/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0353 - mae: 0.1407 - val_loss: 1.0546 - val_mae: 0.7379\n",
            "Epoch 1000/1000\n",
            "69/69 [==============================] - 0s 3ms/step - loss: 0.0382 - mae: 0.1466 - val_loss: 1.0775 - val_mae: 0.7353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  \"Accuracy Plot\"\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# \"Loss Plot\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TlaVtTQ06VeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "2a288c1f-98c5-48d5-a2f7-bf3974195fb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict on test data\n",
        "predictions = model.predict(Xtest_scaled[:5])\n",
        "print(\"predicted values are:\", predictions)\n",
        "print(\"Real values are: \", Ytest[:5])"
      ],
      "metadata": {
        "id": "cfiu9AFoue7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a03624-6e53-4375-aa21-5b48c385f3aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "predicted values are: [[28.653324]\n",
            " [27.91221 ]\n",
            " [29.856972]\n",
            " [28.151073]\n",
            " [29.302626]]\n",
            "Real values are:  [28.169 27.563 29.515 27.428 29.993]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_neural,mae_neural = model.evaluate(Xtest_scaled,Ytest)\n",
        "print(\"Mean squared error from neural net:\", mse_neural)\n",
        "print(\"Mean absolute error from neural net \", mae_neural)"
      ],
      "metadata": {
        "id": "3v6uKT8nue-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924af579-fd09-4858-86ab-5e35094fc470"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step - loss: 1.0775 - mae: 0.7353\n",
            "Mean squared error from neural net: 1.0775281190872192\n",
            "Mean absolute error from neural net  0.7353262305259705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "yG4lkH-2ufBi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression"
      ],
      "metadata": {
        "id": "RIDdkXS8-G4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model_linear = linear_model.LinearRegression()\n",
        "lr_model_linear.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_lr = model.predict(Xtest_scaled)\n",
        "\n",
        "mse_lr = mean_squared_error(Ytest,Ypred_lr)\n",
        "mae_lr = mean_absolute_error(Ytest,Ypred_lr)\n",
        "print(\" Mean squared error from linear regression : \" , mse_lr)\n",
        "print(\" Mean absolute error from linear regression : \" , mae_lr)"
      ],
      "metadata": {
        "id": "mhtjhaKpufF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb07e49-e4f7-4b7c-cfe2-06d34f19dfa1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 0s 2ms/step\n",
            " Mean squared error from linear regression :  1.0775282051446566\n",
            " Mean absolute error from linear regression :  0.7353262297694583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "L7CWJVy1-K98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "tree.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_tree = tree.predict(Xtest_scaled)\n",
        "mse_dt = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_dt = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using decision tree : \" , mse_dt)\n",
        "print(\" Mean absolute error useing decision tree : \" , mae_dt)"
      ],
      "metadata": {
        "id": "UZv8pZbHufP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0e5b9c-632a-4c3e-9591-2b9dabe9263d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using decision tree :  3.248896801457195\n",
            " Mean absolute error useing decision tree :  1.3526885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest"
      ],
      "metadata": {
        "id": "V3Ml1OxKCFk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor(n_estimators=30, random_state=30)\n",
        "model_rf.fit(Xtrain_scaled , Ytrain)\n",
        "Ypred_rf = model_rf.predict(Xtest_scaled)\n",
        "mse_rf = mean_squared_error(Ytest,Ypred_tree)\n",
        "mae_rf = mean_absolute_error(Ytest,Ypred_tree)\n",
        "print(\" Mean squared error using Random Forest : \" , mse_rf)\n",
        "print(\" Mean absolute error using Random Forest : \" , mae_rf)"
      ],
      "metadata": {
        "id": "7rbI7HHQufS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad3632e-e3e0-4458-fbfd-ca28fd5270e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error using Random Forest :  3.248896801457195\n",
            " Mean absolute error using Random Forest :  1.3526885245901639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature randking"
      ],
      "metadata": {
        "id": "UL8F17I-FBVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now plot the feature's importance\n",
        "# according to the linear model.\n",
        "\n",
        "# Create series with feature importance.\n",
        "tmp = pd.Series(np.abs(model_rf.feature_importances_))\n",
        "\n",
        "# Let's add the variable names.\n",
        "Xtrain = pd.DataFrame(Xtrain)\n",
        "tmp.index = Xtrain.columns\n",
        "\n",
        "# Let's make a bar plot.\n",
        "tmp.plot.bar(figsize=(15, 6))\n",
        "plt.title(\"Feature importance\")\n",
        "plt.ylabel(\"Importance\")"
      ],
      "metadata": {
        "id": "gfB0T5GIufVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "146ad9a6-f3a9-4c7a-94bb-aa3427aaeac8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Importance')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure to import all of our modules\n",
        "# sklearn package\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# dataframes\n",
        "import pandas as pd\n",
        "# computation\n",
        "import numpy as np\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dataset\n",
        "# https://www.kaggle.com/datasets/ciphernine/brooklyn-real-estate-listings\n",
        "# place it in the same folder as this workbook\n",
        "#df = pd.read_csv('brooklyn_listings.csv')\n",
        "\n",
        "# for this example, we're going to estimate the price with sqft, bathroom, and bedrooms\n",
        "#df = df[['price','bathrooms','sqft']].dropna()\n",
        "\n",
        "# show some random lines from our data\n",
        "#print(df.sample(n=15)"
      ],
      "metadata": {
        "id": "9B4C-caKFHHJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our polynomial model, with whatever degree we want\n",
        "degree=2\n",
        "\n",
        "# PolynomialFeatures will create a new matrix consisting of all polynomial combinations\n",
        "# of the features with a degree less than or equal to the degree we just gave the model (2)\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "# transform out polynomial features\n",
        "poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "\n",
        "# should be in the form [1, a, b, a^2, ab, b^2]\n",
        "print(f'initial values {Xtrain_scaled[0]}\\nMapped to {poly_x_values[0]}')\n",
        "\n",
        "# [1, a=5, b=2940, a^2=25, 5*2940=14700, b^2=8643600]"
      ],
      "metadata": {
        "id": "9iKrfrOBFHJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3060b91-ff94-46e3-d60a-f4e8923098eb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial values [ 1.19511602 -1.49906108 -0.93295852 -1.20240406 -1.6638147   0.58971247\n",
            "  0.97886613  0.95910281 -2.31186148 -1.58497443 -1.57611082  0.92176546\n",
            "  0.92489579  0.55786513  0.20146035  1.06313119  0.63012796  0.95515212\n",
            "  1.27895312  1.74418194  2.24778212  0.83765488  0.90264358  0.94509406\n",
            "  0.72988846  0.23921987  0.35142359  0.9048538   1.65575797  1.78157834\n",
            "  1.19563771  1.37595614  1.69347943  1.74532185  0.76319455 -0.23190983\n",
            "  0.8161398   0.87841272  1.07563665]\n",
            "Mapped to [ 1.          1.19511602 -1.49906108 -0.93295852 -1.20240406 -1.6638147\n",
            "  0.58971247  0.97886613  0.95910281 -2.31186148 -1.58497443 -1.57611082\n",
            "  0.92176546  0.92489579  0.55786513  0.20146035  1.06313119  0.63012796\n",
            "  0.95515212  1.27895312  1.74418194  2.24778212  0.83765488  0.90264358\n",
            "  0.94509406  0.72988846  0.23921987  0.35142359  0.9048538   1.65575797\n",
            "  1.78157834  1.19563771  1.37595614  1.69347943  1.74532185  0.76319455\n",
            " -0.23190983  0.8161398   0.87841272  1.07563665  1.4283023  -1.79155191\n",
            " -1.11499367 -1.43701235 -1.9884516   0.70477482  1.16985859  1.14623913\n",
            " -2.76294269 -1.89422833 -1.88363528  1.10161667  1.10535777  0.66671355\n",
            "  0.24076849  1.27056511  0.75307602  1.1415176   1.52849736  2.08449977\n",
            "  2.68636042  1.00109477  1.0787638   1.12949705  0.87230139  0.2858955\n",
            "  0.41999197  1.08140527  1.97882287  2.12919281  1.42892578  1.64442722\n",
            "  2.02390439  2.0858621   0.91210603 -0.27715915  0.97538175  1.04980511\n",
            "  1.28551059  2.24718411  1.3985618   1.80247712  2.49415986 -0.88401502\n",
            " -1.46738011 -1.43775369  3.46562156  2.37597347  2.36268638 -1.38178273\n",
            " -1.38647527 -0.8362739  -0.30200137 -1.59369858 -0.94460031 -1.43183137\n",
            " -1.91722884 -2.61463525 -3.36956269 -1.25569583 -1.35311785 -1.41675372\n",
            " -1.09414738 -0.3586052  -0.52680543 -1.35643111 -2.48208232 -2.67069474\n",
            " -1.79233395 -2.06264229 -2.53862909 -2.61634406 -1.14407524  0.347647\n",
            " -1.22344341 -1.31679431 -1.61244503  0.87041159  1.1217931   1.5522701\n",
            " -0.55017728 -0.91324149 -0.89480313  2.15687086  1.47871539  1.47044601\n",
            " -0.85996894 -0.8628894  -0.52046502 -0.18795415 -0.9918573  -0.58788325\n",
            " -0.89111731 -1.19321021 -1.62724939 -2.09708747 -0.78149726 -0.84212901\n",
            " -0.88173355 -0.68095566 -0.22318222 -0.32786363 -0.84419105 -1.5447535\n",
            " -1.66213868 -1.11548038 -1.28371    -1.57994605 -1.62831289 -0.71202885\n",
            "  0.21636225 -0.76142458 -0.81952262 -1.00352437  1.44577552  2.00057755\n",
            " -0.70907267 -1.1769926  -1.15322911  2.77979162  1.90577968  1.89512204\n",
            " -1.10833453 -1.11209844 -0.67077929 -0.24223674 -1.27831325 -0.75766842\n",
            " -1.14847879 -1.53781842 -2.09721143 -2.70274234 -1.00719963 -1.0853423\n",
            " -1.13638493 -0.87762085 -0.28763895 -0.42255315 -1.08799987 -1.99089009\n",
            " -2.14217702 -1.43763963 -1.65445524 -2.03624653 -2.09858208 -0.91766822\n",
            "  0.27884932 -0.98132981 -1.05620701 -1.29334987  2.76827936 -0.98117229\n",
            " -1.62865185 -1.59576935  3.84650912  2.63710376  2.62235635 -1.53364693\n",
            " -1.53885521 -0.9281842  -0.33519269 -1.7688533  -1.04841617 -1.58919615\n",
            " -2.127941   -2.90199555 -3.73989294 -1.39370251 -1.50183166 -1.57246139\n",
            " -1.21439915 -0.39801754 -0.58470374 -1.50550905 -2.75487445 -2.96421623\n",
            " -1.9893196  -2.28933605 -2.81763597 -2.90389216 -1.26981431  0.38585498\n",
            " -1.35790541 -1.46151599 -1.78966007  0.3477608   0.57724957  0.56559489\n",
            " -1.36333355 -0.93467919 -0.92945221  0.54357659  0.54542258  0.32898002\n",
            "  0.11880368  0.62694172  0.37159432  0.56326512  0.75421461  1.02856585\n",
            "  1.32554516  0.49397553  0.53230018  0.55733376  0.43042433  0.14107094\n",
            "  0.20723888  0.53360357  0.97642113  1.05061897  0.70508247  0.8114185\n",
            "  0.99866594  1.02923807  0.45006535 -0.13676012  0.48128782  0.51801094\n",
            "  0.63431635  0.9581789   0.93883325 -2.2630029  -1.55147778 -1.54280149\n",
            "  0.90228499  0.90534916  0.54607528  0.19720271  1.04066311  0.61681092\n",
            "  0.93496606  1.25192389  1.70732062  2.20027778  0.81995199  0.88356722\n",
            "  0.92512056  0.71446309  0.23416423  0.34399665  0.88573073  1.62076539\n",
            "  1.74392669  1.17036925  1.34687685  1.65768965  1.70843644  0.74706529\n",
            " -0.22700868  0.79889161  0.85984845  1.05290428  0.91987819 -2.21731283\n",
            " -1.52015342 -1.51165231  0.88406784  0.88707014  0.53505001  0.19322119\n",
            "  1.01965211  0.6043575   0.91608908  1.22664753  1.67284979  2.15585414\n",
            "  0.80339715  0.86572799  0.90644237  0.70003807  0.22943645  0.33705135\n",
            "  0.86784781  1.58804211  1.70871679  1.14673948  1.31968339  1.62422087\n",
            "  1.67394309  0.73198203 -0.22242537  0.78276198  0.8424881   1.03164613\n",
            "  5.34470351  3.66424133  3.64374988 -2.13099407 -2.13823094 -1.2897069\n",
            " -0.46574842 -2.45781204 -1.45676857 -2.20817941 -2.95676245 -4.03230703\n",
            " -5.1965609  -1.93654206 -2.08678692 -2.18492656 -1.68740102 -0.55304321\n",
            " -0.81244267 -2.09189664 -3.82788306 -4.11876234 -2.76414876 -3.18101999\n",
            " -3.91508985 -4.03494236 -1.76440008  0.5361434  -1.88680218 -2.03076852\n",
            " -2.48672294  2.51214394  2.49809534 -1.46097469 -1.46593617 -0.88420196\n",
            " -0.3193095  -1.68503575 -0.99873671 -1.51389169 -2.02710799 -2.76448377\n",
            " -3.56267718 -1.32766157 -1.43066699 -1.49794992 -1.15685455 -0.37915738\n",
            " -0.55699741 -1.43417013 -2.62433404 -2.82375611 -1.8950552  -2.18085529\n",
            " -2.68412159 -2.76629051 -1.20964384  0.36757115 -1.29356072 -1.39226169\n",
            " -1.70485658  2.4841253  -1.45280452 -1.45773825 -0.87925726 -0.31752384\n",
            " -1.67561256 -0.9931515  -1.50542559 -2.01577184 -2.74902401 -3.54275371\n",
            " -1.32023692 -1.42266631 -1.48957297 -1.1503851  -0.37703703 -0.55388253\n",
            " -1.42614985 -2.60965804 -2.80796489 -1.88445752 -2.16865935 -2.66911124\n",
            " -2.75082065 -1.20287918  0.36551559 -1.28632677 -1.38447578 -1.69532256\n",
            "  0.84965157  0.85253699  0.51422081  0.18569919  0.97995761  0.5808302\n",
            "  0.88042624  1.17889482  1.60772667  2.07192793  0.77212134  0.83202568\n",
            "  0.87115507  0.67278598  0.22050462  0.32393013  0.83406298  1.52622051\n",
            "  1.64219738  1.10209755  1.26830885  1.56099085  1.60877741  0.70348638\n",
            " -0.21376647  0.75228949  0.8096905   0.99148471  0.85543221  0.5159671\n",
            "  0.18632983  0.98328555  0.5828027   0.88341617  1.18289835  1.61318652\n",
            "  2.07896421  0.77474347  0.83485124  0.87411351  0.67507076  0.22125345\n",
            "  0.3250302   0.83689546  1.53140356  1.6477743   1.10584028  1.27261603\n",
            "  1.56629198  1.61424083  0.70587542 -0.21449242  0.75484427  0.81244022\n",
            "  0.9948518   0.3112135   0.1123877   0.59308381  0.35152642  0.53284606\n",
            "  0.71348334  0.97301828  1.25395926  0.46729845  0.50355337  0.52723502\n",
            "  0.40717932  0.13345243  0.19604697  0.50478638  0.92368963  0.99388043\n",
            "  0.66700458  0.76759794  0.94473311  0.9736542   0.42575962 -0.12937441\n",
            "  0.45529594  0.49003582  0.60006018  0.04058627  0.21417878  0.1269458\n",
            "  0.19242528  0.25765834  0.3513835   0.45283897  0.16875425  0.18184689\n",
            "  0.19039898  0.14704358  0.04819332  0.07079792  0.18229216  0.33356958\n",
            "  0.3589174   0.24087359  0.2772006   0.34116896  0.35161315  0.15375344\n",
            " -0.04672064  0.16441981  0.17696533  0.21669814  1.13024792  0.66990869\n",
            "  1.01545201  1.35969495  1.85429421  2.38968728  0.89053703  0.95962854\n",
            "  1.00475897  0.77596719  0.25432211  0.37360938  0.96197829  1.76028793\n",
            "  1.8940515   1.27111974  1.46282188  1.80039079  1.85550609  0.81137593\n",
            " -0.24655057  0.86766368  0.93386795  1.14354287  0.39706125  0.60186806\n",
            "  0.80590413  1.09905781  1.41639037  0.52782977  0.56878096  0.5955302\n",
            "  0.45992313  0.15073913  0.22144183  0.57017368  1.0433394   1.12262233\n",
            "  0.75340476  0.86702844  1.06710874  1.09977611  0.48091023 -0.14613287\n",
            "  0.51427251  0.55351242  0.67778873  0.91231558  1.22159479  1.66595908\n",
            "  2.14697387  0.80008784  0.86216193  0.9027086   0.69715452  0.22849137\n",
            "  0.33566299  0.86427303  1.58150074  1.70167834  1.1420159   1.31424743\n",
            "  1.61753047  1.66704788  0.72896689 -0.22150916  0.77953767  0.83901777\n",
            "  1.02739663  1.63572108  2.23072693  2.87480795  1.07132133  1.15443882\n",
            "  1.208731    0.93349313  0.305951    0.4494543   1.15726558  2.11763682\n",
            "  2.27855518  1.52916458  1.75978339  2.16588079  2.23218483  0.97609005\n",
            " -0.2966018   1.04380455  1.12344868  1.37568885  3.04217062  3.92054097\n",
            "  1.46102252  1.57437462  1.64841599  1.27305827  0.41724298  0.61294668\n",
            "  1.57822964  2.88794313  3.10739676  2.08540969  2.39991784  2.95373622\n",
            "  3.04415885  1.33115015 -0.40449293  1.4234963   1.53211159  1.87610601\n",
            "  5.05252446  1.88286567  2.0289461   2.12436553  1.64063024  0.53771416\n",
            "  0.78992367  2.03391418  3.72178315  4.00459994  2.68753306  3.0928496\n",
            "  3.80657277  3.92310326  1.71549506 -0.52128276  1.83450446  1.97448039\n",
            "  2.41779683  0.70166571  0.7561038   0.79166266  0.61139464  0.2003837\n",
            "  0.29437169  0.7579552   1.38695375  1.4923478   1.00153177  1.15257638\n",
            "  1.41855131  1.46197737  0.63929364 -0.1942604   0.68364349  0.7358067\n",
            "  0.90101229  0.81476543  0.85308308  0.65882913  0.21593028  0.31721025\n",
            "  0.81676047  1.49455929  1.60813025  1.0792347   1.24199797  1.52860833\n",
            "  1.57540356  0.68889266 -0.20933192  0.73668335  0.7928936   0.97091651\n",
            "  0.89320278  0.68981325  0.22608528  0.33212835  0.85517195  1.56484702\n",
            "  1.68375911  1.1299901   1.30040797  1.60049735  1.64949332  0.72129064\n",
            " -0.2191766   0.77132888  0.83018264  1.01657781  0.53273717  0.17460383\n",
            "  0.25650003  0.66044235  1.20851864  1.30035347  0.87268217  1.00429451\n",
            "  1.23605109  1.27389028  0.5570469  -0.16926831  0.59569103  0.64114331\n",
            "  0.78509478  0.05722615  0.08406751  0.21645901  0.39609021  0.42618895\n",
            "  0.2860203   0.32915605  0.40511394  0.41751567  0.1825713  -0.05547744\n",
            "  0.19523686  0.21013378  0.25731366  0.12349854  0.31798697  0.58187241\n",
            "  0.62608866  0.4201753   0.48354345  0.59512863  0.61334728  0.26820457\n",
            " -0.08149859  0.28681078  0.30869495  0.3780041   0.81876039  1.49821888\n",
            "  1.61206792  1.08187732  1.24503913  1.53235129  1.5792611   0.69057948\n",
            " -0.20984449  0.7384872   0.79483508  0.9732939   2.74153444  2.94986253\n",
            "  1.97968666  2.27825033  2.80399205  2.88983056  1.26366545 -0.38398655\n",
            "  1.35132998  1.45443885  1.78099395  3.17402138  2.13012224  2.45137365\n",
            "  3.01706626  3.10942761  1.35969088 -0.41316553  1.454017    1.56496107\n",
            "  1.91633096  1.42954953  1.64514504  2.02478786  2.08677262  0.91250418\n",
            " -0.27728014  0.97580753  1.05026337  1.28607174  1.89325529  2.33015341\n",
            "  2.40148631  1.05012222 -0.31909775  1.12297257  1.20865737  1.48002885\n",
            "  2.86787257  2.95566665  1.29245427 -0.39273452  1.38211597  1.48757386\n",
            "  1.82156853  3.04614837  1.33202012 -0.40475729  1.42442664  1.53311291\n",
            "  1.87733215  0.58246592 -0.17699232  0.62287345  0.6703998   0.82092003\n",
            "  0.05378217 -0.18927084 -0.20371254 -0.24945071  0.66608418  0.71690758\n",
            "  0.87786988  0.7716089   0.94485291  1.1569942 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytrain, y_pred_poly, squared=False)"
      ],
      "metadata": {
        "id": "-TTd5rhyFHL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f854c5f6-d5a0-4fcf-d2c0-3e174212feb4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5857097029796254"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's fit the model\n",
        "\n",
        "\n",
        "poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "\n",
        "poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "# we use linear regression as a base!!! ** sometimes misunderstood **\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "regression_model.fit(poly_x_values, Ytrain)\n",
        "y_pred_poly_test = regression_model.predict(poly_model.fit_transform(Xtest_scaled))\n",
        "\n",
        "regression_model.coef_\n",
        "\n",
        "mean_squared_error(Ytest, y_pred_poly_test, squared=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rooiJ4C18YGP",
        "outputId": "6445f142-0b91-428d-b4f6-07315825eea9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.102059000773104"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "print(\" Mean absolute error from polynomial regression : \" , mae_poly)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ai089U-XXz",
        "outputId": "8dfb0eba-05d9-4004-fb7c-a2ba63e974a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from polynomial regression :  4.418652042731221\n",
            " Mean absolute error from polynomial regression :  0.9773643347588769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check our accuracy for each degree, the lower the error the better!\n",
        "number_degrees = [1,2,3,4]\n",
        "plt_mean_squared_error = []\n",
        "for degree in number_degrees:\n",
        "\n",
        "   poly_model = PolynomialFeatures(degree=degree)\n",
        "\n",
        "   poly_x_values = poly_model.fit_transform(Xtrain_scaled)\n",
        "   poly_model.fit(poly_x_values, Ytrain)\n",
        "\n",
        "   regression_model = LinearRegression()\n",
        "   regression_model.fit(poly_x_values, Ytrain)\n",
        "   y_pred_poly = regression_model.predict(poly_x_values)\n",
        "\n",
        "   plt_mean_squared_error.append(mean_squared_error(Ytrain, y_pred_poly, squared=False))\n",
        "\n",
        "   poly_Xtest_values = poly_model.fit_transform(Xtest_scaled)\n",
        "   y_pred_poly_test = regression_model.predict(poly_model.fit_transform(Xtest_scaled))\n",
        "   mse_poly = mean_squared_error(Ytest,y_pred_poly_test)\n",
        "   mae_poly = mean_absolute_error(Ytest,y_pred_poly_test)\n",
        "   print(\" Mean squared error from polynomial regression : \" , mse_poly)\n",
        "   print(\" Mean absolute error from polynomial regression : \" , mae_poly)\n",
        "\n",
        "plt.scatter(number_degrees,plt_mean_squared_error, color=\"green\")\n",
        "plt.plot(number_degrees,plt_mean_squared_error, color=\"red\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "sWrsMQs9wdbd",
        "outputId": "50f87b80-d469-444c-e1ce-00a6db1ec011"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mean squared error from polynomial regression :  1.7064336301820187\n",
            " Mean absolute error from polynomial regression :  1.0197840616891123\n",
            " Mean squared error from polynomial regression :  4.418652042731221\n",
            " Mean absolute error from polynomial regression :  0.9773643347588769\n",
            " Mean squared error from polynomial regression :  50.31737035890137\n",
            " Mean absolute error from polynomial regression :  2.1674784881193725\n",
            " Mean squared error from polynomial regression :  9502.945650975198\n",
            " Mean absolute error from polynomial regression :  6.938552946406621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7d19c8a4e620>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}